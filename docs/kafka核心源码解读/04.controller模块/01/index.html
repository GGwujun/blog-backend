<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no"
    />
    <link rel="shortcut icon" type="image/x-icon" href="/logo.png" />
    <link rel="stylesheet" href="/blog-backend/umi.3ec1f225.css" />
    <script>
      window.routerBase = "/blog-backend";
    </script>
    <script>
      //! umi version: 3.5.41
    </script>
    <script>
      !(function () {
        var e =
            navigator.cookieEnabled && void 0 !== window.localStorage
              ? localStorage.getItem("dumi:prefers-color")
              : "auto",
          o = window.matchMedia("(prefers-color-scheme: dark)").matches,
          t = ["light", "dark", "auto"];
        document.documentElement.setAttribute(
          "data-prefers-color",
          e === t[2] ? (o ? t[1] : t[0]) : t.indexOf(e) > -1 ? e : t[0]
        );
      })();
    </script>
    <title>
      11 | Controller元数据：Controller都保存有哪些东西？有几种状态？ - 大师兄
    </title>
  </head>
  <body>
    <div id="root"><div class="__dumi-default-layout" data-route="/kafka核心源码解读/04.controller模块/01" data-show-sidemenu="true" data-show-slugs="true" data-site-mode="true" data-gapless="false"><div class="__dumi-default-navbar" data-mode="site"><button class="__dumi-default-navbar-toggle"></button><a class="__dumi-default-navbar-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-backend/">大师兄</a><nav><div class="__dumi-default-search"><input type="search" class="__dumi-default-search-input" value=""/><ul></ul></div><span>后端开发<ul><li><a href="/blog-backend/go语言核心36讲">go语言核心36讲</a></li><li><a href="/blog-backend/go并发编程实战">go并发编程实战</a></li><li><a href="/blog-backend/go语言项目开发实战">go语言项目开发实战</a></li><li><a href="/blog-backend/kafka核心技术与实战">kafka核心技术与实战</a></li><li><a aria-current="page" class="active" href="/blog-backend/kafka核心源码解读">kafka核心源码解读</a></li><li><a href="/blog-backend/零基础学python">零基础学python</a></li><li><a href="/blog-backend/python核心技术与实战">python核心技术与实战</a></li><li><a href="/blog-backend/redis核心技术与实战">redis核心技术与实战</a></li><li><a href="/blog-backend/redis源码剖析与实战">redis源码剖析与实战</a></li><li><a href="/blog-backend/陈天rust编程第一课">陈天rust编程第一课</a></li><li><a href="/blog-backend/tonybaigo语言第一课">tonybaigo语言第一课</a></li><li><a href="/blog-backend/后端存储实战课">后端存储实战课</a></li><li><a href="/blog-backend/后端技术面试38讲">后端技术面试38讲</a></li><li><a href="/blog-backend/深入c语言和程序运行原理">深入c语言和程序运行原理</a></li><li><a href="/blog-backend/现代c编程实战">现代c编程实战</a></li><li><a href="/blog-backend/罗剑锋的c实战笔记">罗剑锋的c实战笔记</a></li><li><a href="/blog-backend/零基础入门spark">零基础入门spark</a></li></ul></span><span>架构师<ul><li><a href="/blog-backend/mysql实战45讲">mysql实战45讲</a></li><li><a href="/blog-backend/数据中台实战课">数据中台实战课</a></li></ul></span><div class="__dumi-default-navbar-tool"><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "></div></div></div></nav></div><div class="__dumi-default-menu" data-mode="site"><div class="__dumi-default-menu-inner"><div class="__dumi-default-menu-header"><a class="__dumi-default-menu-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-backend/"></a><h1>大师兄</h1><p></p></div><div class="__dumi-default-menu-mobile-area"><ul class="__dumi-default-menu-nav-list"><li>后端开发<ul><li><a href="/blog-backend/go语言核心36讲">go语言核心36讲</a></li><li><a href="/blog-backend/go并发编程实战">go并发编程实战</a></li><li><a href="/blog-backend/go语言项目开发实战">go语言项目开发实战</a></li><li><a href="/blog-backend/kafka核心技术与实战">kafka核心技术与实战</a></li><li><a aria-current="page" class="active" href="/blog-backend/kafka核心源码解读">kafka核心源码解读</a></li><li><a href="/blog-backend/零基础学python">零基础学python</a></li><li><a href="/blog-backend/python核心技术与实战">python核心技术与实战</a></li><li><a href="/blog-backend/redis核心技术与实战">redis核心技术与实战</a></li><li><a href="/blog-backend/redis源码剖析与实战">redis源码剖析与实战</a></li><li><a href="/blog-backend/陈天rust编程第一课">陈天rust编程第一课</a></li><li><a href="/blog-backend/tonybaigo语言第一课">tonybaigo语言第一课</a></li><li><a href="/blog-backend/后端存储实战课">后端存储实战课</a></li><li><a href="/blog-backend/后端技术面试38讲">后端技术面试38讲</a></li><li><a href="/blog-backend/深入c语言和程序运行原理">深入c语言和程序运行原理</a></li><li><a href="/blog-backend/现代c编程实战">现代c编程实战</a></li><li><a href="/blog-backend/罗剑锋的c实战笔记">罗剑锋的c实战笔记</a></li><li><a href="/blog-backend/零基础入门spark">零基础入门spark</a></li></ul></li><li>架构师<ul><li><a href="/blog-backend/mysql实战45讲">mysql实战45讲</a></li><li><a href="/blog-backend/数据中台实战课">数据中台实战课</a></li></ul></li></ul><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "><button title="Dark theme" class="__dumi-default-dark-moon "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3854" width="22" height="22"><path d="M991.816611 674.909091a69.166545 69.166545 0 0 0-51.665455-23.272727 70.795636 70.795636 0 0 0-27.438545 5.585454A415.674182 415.674182 0 0 1 754.993338 698.181818c-209.594182 0-393.472-184.785455-393.472-395.636363 0-52.363636 38.539636-119.621818 69.515637-173.614546 4.887273-8.610909 9.634909-16.756364 14.103272-24.901818A69.818182 69.818182 0 0 0 384.631156 0a70.842182 70.842182 0 0 0-27.438545 5.585455C161.678429 90.298182 14.362065 307.898182 14.362065 512c0 282.298182 238.824727 512 532.38691 512a522.286545 522.286545 0 0 0 453.957818-268.334545A69.818182 69.818182 0 0 0 991.816611 674.909091zM546.679156 954.181818c-248.785455 0-462.941091-192-462.941091-442.181818 0-186.647273 140.637091-372.829091 300.939637-442.181818-36.817455 65.629091-92.578909 151.970909-92.578909 232.727273 0 250.181818 214.109091 465.454545 462.917818 465.454545a488.331636 488.331636 0 0 0 185.181091-46.545455 453.003636 453.003636 0 0 1-393.565091 232.727273z m103.656728-669.323636l-14.266182 83.781818a34.909091 34.909091 0 0 0 50.362182 36.770909l74.775272-39.563636 74.752 39.563636a36.142545 36.142545 0 0 0 16.174546 3.956364 34.909091 34.909091 0 0 0 34.210909-40.727273l-14.289455-83.781818 60.509091-59.345455a35.025455 35.025455 0 0 0-19.223272-59.578182l-83.61891-12.101818-37.376-76.101818a34.56 34.56 0 0 0-62.254545 0l-37.376 76.101818-83.618909 12.101818a34.909091 34.909091 0 0 0-19.246546 59.578182z m70.423272-64.698182a34.280727 34.280727 0 0 0 26.135273-19.083636l14.312727-29.090909 14.336 29.090909a34.257455 34.257455 0 0 0 26.135273 19.083636l32.046546 4.887273-23.272728 22.574545a35.234909 35.234909 0 0 0-10.007272 30.952727l5.46909 32.116364-28.625454-15.127273a34.490182 34.490182 0 0 0-32.302546 0l-28.695272 15.127273 5.469091-32.116364a35.141818 35.141818 0 0 0-9.984-30.952727l-23.272728-22.574545z" p-id="3855"></path></svg></button><button title="Light theme" class="__dumi-default-dark-sun "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4026" width="22" height="22"><path d="M915.2 476.16h-43.968c-24.704 0-44.736 16-44.736 35.84s20.032 35.904 44.736 35.904H915.2c24.768 0 44.8-16.064 44.8-35.904s-20.032-35.84-44.8-35.84zM512 265.6c-136.704 0-246.464 109.824-246.464 246.4 0 136.704 109.76 246.464 246.464 246.464S758.4 648.704 758.4 512c0-136.576-109.696-246.4-246.4-246.4z m0 425.6c-99.008 0-179.2-80.128-179.2-179.2 0-98.944 80.192-179.2 179.2-179.2S691.2 413.056 691.2 512c0 99.072-80.192 179.2-179.2 179.2zM197.44 512c0-19.84-19.136-35.84-43.904-35.84H108.8c-24.768 0-44.8 16-44.8 35.84s20.032 35.904 44.8 35.904h44.736c24.768 0 43.904-16.064 43.904-35.904zM512 198.464c19.776 0 35.84-20.032 35.84-44.8v-44.8C547.84 84.032 531.84 64 512 64s-35.904 20.032-35.904 44.8v44.8c0 24.768 16.128 44.864 35.904 44.864z m0 627.136c-19.776 0-35.904 20.032-35.904 44.8v44.736C476.096 940.032 492.16 960 512 960s35.84-20.032 35.84-44.8v-44.736c0-24.768-16.064-44.864-35.84-44.864z m329.92-592.832c17.472-17.536 20.288-43.072 6.4-57.024-14.016-14.016-39.488-11.2-57.024 6.336-4.736 4.864-26.496 26.496-31.36 31.36-17.472 17.472-20.288 43.008-6.336 57.024 13.952 14.016 39.488 11.2 57.024-6.336 4.8-4.864 26.496-26.56 31.296-31.36zM213.376 759.936c-4.864 4.8-26.56 26.624-31.36 31.36-17.472 17.472-20.288 42.944-6.4 56.96 14.016 13.952 39.552 11.2 57.024-6.336 4.8-4.736 26.56-26.496 31.36-31.36 17.472-17.472 20.288-43.008 6.336-56.96-14.016-13.952-39.552-11.072-56.96 6.336z m19.328-577.92c-17.536-17.536-43.008-20.352-57.024-6.336-14.08 14.016-11.136 39.488 6.336 57.024 4.864 4.864 26.496 26.56 31.36 31.424 17.536 17.408 43.008 20.288 56.96 6.336 14.016-14.016 11.264-39.488-6.336-57.024-4.736-4.864-26.496-26.56-31.296-31.424z m527.168 628.608c4.864 4.864 26.624 26.624 31.36 31.424 17.536 17.408 43.072 20.224 57.088 6.336 13.952-14.016 11.072-39.552-6.4-57.024-4.864-4.8-26.56-26.496-31.36-31.36-17.472-17.408-43.072-20.288-57.024-6.336-13.952 14.016-11.008 39.488 6.336 56.96z" p-id="4027"></path></svg></button><button title="Default to system" class="__dumi-default-dark-auto "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="11002" width="22" height="22"><path d="M127.658667 492.885333c0-51.882667 10.24-101.717333 30.378666-149.162666s47.786667-88.064 81.92-122.538667 75.093333-61.781333 122.538667-81.92 96.938667-30.378667 149.162667-30.378667 101.717333 10.24 149.162666 30.378667 88.405333 47.786667 122.88 81.92 61.781333 75.093333 81.92 122.538667 30.378667 96.938667 30.378667 149.162666-10.24 101.717333-30.378667 149.162667-47.786667 88.405333-81.92 122.88-75.093333 61.781333-122.88 81.92-97.28 30.378667-149.162666 30.378667-101.717333-10.24-149.162667-30.378667-88.064-47.786667-122.538667-81.92-61.781333-75.093333-81.92-122.88-30.378667-96.938667-30.378666-149.162667z m329.045333 0c0 130.048 13.994667 244.394667 41.984 343.381334h12.970667c46.762667 0 91.136-9.216 133.461333-27.306667s78.848-42.666667 109.568-73.386667 54.954667-67.242667 73.386667-109.568 27.306667-86.698667 27.306666-133.461333c0-46.421333-9.216-90.794667-27.306666-133.12s-42.666667-78.848-73.386667-109.568-67.242667-54.954667-109.568-73.386667-86.698667-27.306667-133.461333-27.306666h-11.605334c-28.672 123.562667-43.349333 237.909333-43.349333 343.722666z" p-id="11003"></path></svg></button></div></div></div><ul class="__dumi-default-menu-list"><li><a href="/blog-backend/kafka核心源码解读">kafka核心源码解读</a></li><li><a href="/blog-backend/kafka核心源码解读/01.课前必学">01.课前必学</a><ul><li><a href="/blog-backend/kafka核心源码解读/01.课前必学/01"><span>开篇词 |  阅读源码，逐渐成了职业进阶道路上的“必选项”</span></a></li><li><a href="/blog-backend/kafka核心源码解读/01.课前必学/02"><span>导读 | 构建Kafka工程和源码阅读环境、Scala语言热身</span></a></li><li><a href="/blog-backend/kafka核心源码解读/01.课前必学/03"><span>重磅加餐 | 带你快速入门Scala语言</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/02.日志模块">02.日志模块</a><ul><li><a href="/blog-backend/kafka核心源码解读/02.日志模块/01"><span>01 | 日志段：保存消息文件的对象是怎么实现的？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/02.日志模块/02"><span>02 | 日志（上）：日志究竟是如何加载日志段的？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/02.日志模块/03"><span>03 | 日志（下）：彻底搞懂Log对象的常见操作</span></a></li><li><a href="/blog-backend/kafka核心源码解读/02.日志模块/04"><span>04 | 索引（上）：改进的二分查找算法在Kafka索引的应用</span></a></li><li><a href="/blog-backend/kafka核心源码解读/02.日志模块/05"><span>05 | 索引（下）：位移索引和时间戳索引的区别是什么？</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/03.请求处理模块">03.请求处理模块</a><ul><li><a href="/blog-backend/kafka核心源码解读/03.请求处理模块/01"><span>06 | 请求通道：如何实现Kafka请求队列？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/03.请求处理模块/02"><span>07 | SocketServer（上）：Kafka到底是怎么应用NIO实现网络通信的？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/03.请求处理模块/03"><span>08 | SocketServer（中）：请求还要区分优先级？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/03.请求处理模块/04"><span>09 | SocketServer（下）：请求处理全流程源码分析</span></a></li><li><a href="/blog-backend/kafka核心源码解读/03.请求处理模块/05"><span>10 | KafkaApis：Kafka最重要的源码入口，没有之一</span></a></li></ul></li><li><a aria-current="page" class="active" href="/blog-backend/kafka核心源码解读/04.controller模块">04.Controller模块</a><ul><li><a aria-current="page" class="active" href="/blog-backend/kafka核心源码解读/04.controller模块/01"><span>11 | Controller元数据：Controller都保存有哪些东西？有几种状态？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/04.controller模块/02"><span>12 | ControllerChannelManager：Controller如何管理请求发送？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/04.controller模块/03"><span>13 | ControllerEventManager：变身单线程后的Controller如何处理事件？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/04.controller模块/04"><span>14 | Controller选举是怎么实现的？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/04.controller模块/05"><span>15 | 如何理解Controller在Kafka集群中的作用？</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/05.状态机模块">05.状态机模块</a><ul><li><a href="/blog-backend/kafka核心源码解读/05.状态机模块/01"><span>16 | TopicDeletionManager： Topic是怎么被删除的？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/05.状态机模块/02"><span>17 | ReplicaStateMachine：揭秘副本状态机实现原理</span></a></li><li><a href="/blog-backend/kafka核心源码解读/05.状态机模块/03"><span>18 | PartitionStateMachine：分区状态转换如何实现？</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/06.延迟操作模块">06.延迟操作模块</a><ul><li><a href="/blog-backend/kafka核心源码解读/06.延迟操作模块/01"><span>19 | TimingWheel：探究Kafka定时器背后的高效时间轮算法</span></a></li><li><a href="/blog-backend/kafka核心源码解读/06.延迟操作模块/02"><span>20 | DelayedOperation：Broker是怎么延时处理请求的？</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/07.副本管理模块">07.副本管理模块</a><ul><li><a href="/blog-backend/kafka核心源码解读/07.副本管理模块/01"><span>21 | AbstractFetcherThread：拉取消息分几步？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/07.副本管理模块/02"><span>22 | ReplicaFetcherThread：Follower如何拉取Leader消息？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/07.副本管理模块/03"><span>23 | ReplicaManager（上）：必须要掌握的副本管理类定义和核心字段</span></a></li><li><a href="/blog-backend/kafka核心源码解读/07.副本管理模块/04"><span>24 | ReplicaManager（中）：副本管理器是如何读写副本的？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/07.副本管理模块/05"><span>25 | ReplicaManager（下）：副本管理器是如何管理副本的？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/07.副本管理模块/06"><span>26 | MetadataCache：Broker是怎么异步更新元数据缓存的？</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块">08.消费者组管理模块</a><ul><li><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/01"><span>27 | 消费者组元数据（上）：消费者组都有哪些元数据？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/02"><span>28 | 消费者组元数据（下）：Kafka如何管理这些元数据？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/03"><span>29 | GroupMetadataManager：组元数据管理器是个什么东西？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/04"><span>30 | GroupMetadataManager：位移主题保存的只是位移吗？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/05"><span>31 | GroupMetadataManager：查询位移时，不用读取位移主题？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/06"><span>32 | GroupCoordinator：在Rebalance中，Coordinator如何处理成员入组？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/07"><span>33 | GroupCoordinator：在Rebalance中，如何进行组同步？</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/09.特别放送">09.特别放送</a><ul><li><a href="/blog-backend/kafka核心源码解读/09.特别放送/01"><span>特别放送（一）| 经典的Kafka学习资料有哪些？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/09.特别放送/02"><span>特别放送（二）| 一篇文章带你了解参与开源社区的全部流程</span></a></li><li><a href="/blog-backend/kafka核心源码解读/09.特别放送/03"><span>特别放送（三）| 我是怎么度过日常一天的？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/09.特别放送/04"><span>特别放送（四）| 20道经典的Kafka面试题详解</span></a></li><li><a href="/blog-backend/kafka核心源码解读/09.特别放送/05"><span>特别放送（五） | Kafka 社区的重磅功能：移除 ZooKeeper 依赖</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/10.测试题">10.测试题</a><ul><li><a href="/blog-backend/kafka核心源码解读/10.测试题/01"><span>期中测试 | 这些源码知识，你都掌握了吗？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/10.测试题/02"><span>期末测试 | 一套习题，测试你的掌握程度</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/11.结束语">11.结束语</a><ul><li><a href="/blog-backend/kafka核心源码解读/11.结束语/01"><span>结束语 | 源码学习，我们才刚上路呢</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/summary">kafka核心源码解读</a></li></ul></div></div><ul role="slug-list" class="__dumi-default-layout-toc"><li title="案例分享" data-depth="2"><a href="/blog-backend/kafka核心源码解读/04.controller模块/01#案例分享"><span>案例分享</span></a></li><li title="集群元数据" data-depth="2"><a href="/blog-backend/kafka核心源码解读/04.controller模块/01#集群元数据"><span>集群元数据</span></a></li><li title="ControllerContext" data-depth="2"><a href="/blog-backend/kafka核心源码解读/04.controller模块/01#controllercontext"><span>ControllerContext</span></a></li><li title="ControllerStats" data-depth="3"><a href="/blog-backend/kafka核心源码解读/04.controller模块/01#controllerstats"><span>ControllerStats</span></a></li><li title="offlinePartitionCount" data-depth="3"><a href="/blog-backend/kafka核心源码解读/04.controller模块/01#offlinepartitioncount"><span>offlinePartitionCount</span></a></li><li title="shuttingDownBrokerIds" data-depth="3"><a href="/blog-backend/kafka核心源码解读/04.controller模块/01#shuttingdownbrokerids"><span>shuttingDownBrokerIds</span></a></li><li title="liveBrokers" data-depth="3"><a href="/blog-backend/kafka核心源码解读/04.controller模块/01#livebrokers"><span>liveBrokers</span></a></li><li title="liveBrokerEpochs" data-depth="3"><a href="/blog-backend/kafka核心源码解读/04.controller模块/01#livebrokerepochs"><span>liveBrokerEpochs</span></a></li><li title="epoch &amp; epochZkVersion" data-depth="3"><a href="/blog-backend/kafka核心源码解读/04.controller模块/01#epoch--epochzkversion"><span>epoch &amp; epochZkVersion</span></a></li><li title="allTopics" data-depth="3"><a href="/blog-backend/kafka核心源码解读/04.controller模块/01#alltopics"><span>allTopics</span></a></li><li title="partitionAssignments" data-depth="3"><a href="/blog-backend/kafka核心源码解读/04.controller模块/01#partitionassignments"><span>partitionAssignments</span></a></li><li title="总结" data-depth="2"><a href="/blog-backend/kafka核心源码解读/04.controller模块/01#总结"><span>总结</span></a></li><li title="课后讨论" data-depth="2"><a href="/blog-backend/kafka核心源码解读/04.controller模块/01#课后讨论"><span>课后讨论</span></a></li></ul><div class="__dumi-default-layout-content"><div class="markdown"><h1 id="11--controller元数据controller都保存有哪些东西有几种状态"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/04.controller模块/01#11--controller元数据controller都保存有哪些东西有几种状态"><span class="icon icon-link"></span></a>11 | Controller元数据：Controller都保存有哪些东西？有几种状态？</h1><p>你好，我是胡夕。从今天开始，我们正式进入到第三大模块的学习：控制器（Controller）模块 。</p><p>提起Kafka中的Controller组件，我相信你一定不陌生。从某种意义上说，它是Kafka最核心的组件。一方面，它要为集群中的所有主题分区选举领导者副本；另一方面，它还承载着集群的全部元数据信息，并负责将这些元数据信息同步到其他Broker上。既然我们是Kafka源码解读课，那就绝对不能错过这么重量级的组件。</p><p>我画了一张图片，希望借助它帮你建立起对这个模块的整体认知。今天，我们先学习下Controller元数据。</p><p><img src="/blog-backend/static/httpsstatic001geekbangorgresourceimage135f13c0d8b3f52c295c70c71a154dae185f.5ea18f39.jpg" alt=""/></p><h2 id="案例分享"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/04.controller模块/01#案例分享"><span class="icon icon-link"></span></a>案例分享</h2><p>在正式学习源码之前，我想向你分享一个真实的案例。</p><p>在我们公司的Kafka集群环境上，曾经出现了一个比较“诡异”的问题：某些核心业务的主题分区一直处于“不可用”状态。</p><p>通过使用“kafka-topics”命令查询，我们发现，这些分区的Leader显示是-1。之前，这些Leader所在的Broker机器因为负载高宕机了，当Broker重启回来后，Controller竟然无法成功地为这些分区选举Leader，因此，它们一直处于“不可用”状态。</p><p>由于是生产环境，我们的当务之急是马上恢复受损分区，然后才能调研问题的原因。有人提出，重启这些分区旧Leader所在的所有Broker机器——这很容易想到，毕竟“重启大法”一直很好用。但是，这一次竟然没有任何作用。</p><p>之后，有人建议升级重启大法，即重启集群的所有Broker——这在当时是不能接受的。且不说有很多业务依然在运行着，单是重启Kafka集群本身，就是一件非常缺乏计划性的事情。毕竟，生产环境怎么能随意重启呢？！</p><p>后来，我突然想到了Controller组件中重新选举Controller的代码。一旦Controller被选举出来，它就会向所有Broker更新集群元数据，也就是说，会“重刷”这些分区的状态。</p><p>那么问题来了，我们如何在避免重启集群的情况下，干掉已有Controller并执行新的Controller选举呢？答案就在源码中的<strong>ControllerZNode.path</strong>上，也就是ZooKeeper的/controller节点。倘若我们手动删除了/controller节点，Kafka集群就会触发Controller选举。于是，我们马上实施了这个方案，效果出奇得好：之前的受损分区全部恢复正常，业务数据得以正常生产和消费。</p><p>当然，给你分享这个案例的目的，并不是让你记住可以随意干掉/controller节点——这个操作其实是有一点危险的。事实上，我只是想通过这个真实的例子，向你说明，很多打开“精通Kafka之门”的钥匙是隐藏在源码中的。那么，接下来，我们就开始找“钥匙”吧。</p><h2 id="集群元数据"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/04.controller模块/01#集群元数据"><span class="icon icon-link"></span></a>集群元数据</h2><p>想要完整地了解Controller的工作原理，我们首先就要学习它管理了哪些数据。毕竟，Controller的很多代码仅仅是做数据的管理操作而已。今天，我们就来重点学习Kafka集群元数据都有哪些。</p><p>如果说ZooKeeper是整个Kafka集群元数据的“真理之源（Source of Truth）”，那么Controller可以说是集群元数据的“真理之源副本（Backup Source of Truth）”。好吧，后面这个词是我自己发明的。你只需要理解，Controller承载了ZooKeeper上的所有元数据即可。</p><p>事实上，集群Broker是不会与ZooKeeper直接交互去获取元数据的。相反地，它们总是与Controller进行通信，获取和更新最新的集群数据。而且社区已经打算把ZooKeeper“干掉”了（我会在之后的“特别放送”里具体给你解释社区干掉ZooKeeper的操作），以后Controller将成为新的“真理之源”。</p><p>我们总说元数据，那么，到底什么是集群的元数据，或者说，Kafka集群的元数据都定义了哪些内容呢？我用一张图给你完整地展示一下，当前Kafka定义的所有集群元数据信息。</p><p><img src="/blog-backend/static/httpsstatic001geekbangorgresourceimagef154f146aceb78a5da31d887618303b5ff54.54b9040f.jpg" alt=""/></p><p>可以看到，目前，Controller定义的元数据有17项之多。不过，并非所有的元数据都同等重要，你也不用完整地记住它们，我们只需要重点关注那些最重要的元数据，并结合源代码来了解下这些元数据都是用来做什么的。</p><p>在了解具体的元数据之前，我要先介绍下ControllerContext类。刚刚我们提到的这些元数据信息全部封装在这个类里。应该这么说，<strong>这个类是Controller组件的数据容器类</strong>。</p><h2 id="controllercontext"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/04.controller模块/01#controllercontext"><span class="icon icon-link"></span></a>ControllerContext</h2><p>Controller组件的源代码位于core包的src/main/scala/kafka/controller路径下，这里面有很多Scala源文件，<strong>ControllerContext类就位于这个路径下的ControllerContext.scala文件中。</strong></p><p>该文件只有几百行代码，其中，最重要的数据结构就是ControllerContext类。前面说过，<strong>它定义了前面提到的所有元数据信息，以及许多实用的工具方法</strong>。比如，获取集群上所有主题分区对象的allPartitions方法、获取某主题分区副本列表的partitionReplicaAssignment方法，等等。</p><p>首先，我们来看下ControllerContext类的定义，如下所示：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">class ControllerContext {</span></div><div class="token-line"><span class="token plain">      val stats = new ControllerStats // Controller统计信息类 </span></div><div class="token-line"><span class="token plain">      var offlinePartitionCount = 0   // 离线分区计数器</span></div><div class="token-line"><span class="token plain">      val shuttingDownBrokerIds = mutable.Set.empty[Int]  // 关闭中Broker的Id列表</span></div><div class="token-line"><span class="token plain">      private val liveBrokers = mutable.Set.empty[Broker] // 当前运行中Broker对象列表</span></div><div class="token-line"><span class="token plain">      private val liveBrokerEpochs = mutable.Map.empty[Int, Long] 	// 运行中Broker Epoch列表</span></div><div class="token-line"><span class="token plain">      var epoch: Int = KafkaController.InitialControllerEpoch   // Controller当前Epoch值</span></div><div class="token-line"><span class="token plain">      var epochZkVersion: Int = KafkaController.InitialControllerEpochZkVersion	// Controller对应ZooKeeper节点的Epoch值</span></div><div class="token-line"><span class="token plain">      val allTopics = mutable.Set.empty[String]	// 集群主题列表</span></div><div class="token-line"><span class="token plain">      val partitionAssignments = mutable.Map.empty[String, mutable.Map[Int, ReplicaAssignment]]	// 主题分区的副本列表</span></div><div class="token-line"><span class="token plain">      val partitionLeadershipInfo = mutable.Map.empty[TopicPartition, LeaderIsrAndControllerEpoch]	// 主题分区的Leader/ISR副本信息</span></div><div class="token-line"><span class="token plain">      val partitionsBeingReassigned = mutable.Set.empty[TopicPartition]	// 正处于副本重分配过程的主题分区列表</span></div><div class="token-line"><span class="token plain">      val partitionStates = mutable.Map.empty[TopicPartition, PartitionState] // 主题分区状态列表 </span></div><div class="token-line"><span class="token plain">      val replicaStates = mutable.Map.empty[PartitionAndReplica, ReplicaState]	// 主题分区的副本状态列表</span></div><div class="token-line"><span class="token plain">      val replicasOnOfflineDirs = mutable.Map.empty[Int, Set[TopicPartition]]	// 不可用磁盘路径上的副本列表</span></div><div class="token-line"><span class="token plain">      val topicsToBeDeleted = mutable.Set.empty[String]	// 待删除主题列表</span></div><div class="token-line"><span class="token plain">      val topicsWithDeletionStarted = mutable.Set.empty[String]	// 已开启删除的主题列表</span></div><div class="token-line"><span class="token plain">      val topicsIneligibleForDeletion = mutable.Set.empty[String]	// 暂时无法执行删除的主题列表</span></div><div class="token-line"><span class="token plain">      ......</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>不多不少，这段代码中定义的字段正好17个，它们一一对应着上图中的那些元数据信息。下面，我选取一些重要的元数据，来详细解释下它们的含义。</p><p>这些元数据理解起来还是比较简单的，掌握了它们之后，你在理解MetadataCache，也就是元数据缓存的时候，就容易得多了。比如，接下来我要讲到的liveBrokers信息，就是Controller通过UpdateMetadataRequest请求同步给其他Broker的MetadataCache的。</p><h3 id="controllerstats"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/04.controller模块/01#controllerstats"><span class="icon icon-link"></span></a>ControllerStats</h3><p>第一个是ControllerStats类的变量。它的完整代码如下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">private[controller] class ControllerStats extends KafkaMetricsGroup {</span></div><div class="token-line"><span class="token plain">      // 统计每秒发生的Unclean Leader选举次数</span></div><div class="token-line"><span class="token plain">      val uncleanLeaderElectionRate = newMeter(&quot;UncleanLeaderElectionsPerSec&quot;, &quot;elections&quot;, TimeUnit.SECONDS)</span></div><div class="token-line"><span class="token plain">      // Controller事件通用的统计速率指标的方法</span></div><div class="token-line"><span class="token plain">      val rateAndTimeMetrics: Map[ControllerState, KafkaTimer] = ControllerState.values.flatMap { state =&gt;</span></div><div class="token-line"><span class="token plain">        state.rateAndTimeMetricName.map { metricName =&gt;</span></div><div class="token-line"><span class="token plain">          state -&gt; new KafkaTimer(newTimer(metricName, TimeUnit.MILLISECONDS, TimeUnit.SECONDS))</span></div><div class="token-line"><span class="token plain">        }</span></div><div class="token-line"><span class="token plain">      }.toMap</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>顾名思义，它表征的是Controller的一些统计信息。目前，源码中定义了两大类统计指标：<strong>UncleanLeaderElectionsPerSec和所有Controller事件状态的执行速率与时间</strong>。</p><p>其中，<strong>前者是计算Controller每秒执行的Unclean Leader选举数量，通常情况下，执行Unclean Leader选举可能造成数据丢失，一般不建议开启它</strong>。一旦开启，你就需要时刻关注这个监控指标的值，确保Unclean Leader选举的速率维持在一个很低的水平，否则会出现很多数据丢失的情况。</p><p><strong>后者是统计所有Controller状态的速率和时间信息</strong>，单位是毫秒。当前，Controller定义了很多事件，比如，TopicDeletion是执行主题删除的Controller事件、ControllerChange是执行Controller重选举的事件。ControllerStats的这个指标通过在每个事件名后拼接字符串RateAndTimeMs的方式，为每类Controller事件都创建了对应的速率监控指标。</p><p>由于Controller事件有很多种，对应的速率监控指标也有很多，有一些Controller事件是需要你额外关注的。</p><p>举个例子，IsrChangeNotification事件是标志ISR列表变更的事件，如果这个事件经常出现，说明副本的ISR列表经常发生变化，而这通常被认为是非正常情况，因此，你最好关注下这个事件的速率监控指标。</p><h3 id="offlinepartitioncount"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/04.controller模块/01#offlinepartitioncount"><span class="icon icon-link"></span></a>offlinePartitionCount</h3><p><strong>该字段统计集群中所有离线或处于不可用状态的主题分区数量</strong>。所谓的不可用状态，就是我最开始举的例子中“Leader=-1”的情况。</p><p>ControllerContext中的updatePartitionStateMetrics方法根据<strong>给定主题分区的当前状态和目标状态</strong>，来判断该分区是否是离线状态的分区。如果是，则累加offlinePartitionCount字段的值，否则递减该值。方法代码如下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">// 更新offlinePartitionCount元数据</span></div><div class="token-line"><span class="token plain">    private def updatePartitionStateMetrics(</span></div><div class="token-line"><span class="token plain">      partition: TopicPartition, </span></div><div class="token-line"><span class="token plain">      currentState: PartitionState,</span></div><div class="token-line"><span class="token plain">      targetState: PartitionState): Unit = {</span></div><div class="token-line"><span class="token plain">      // 如果该主题当前并未处于删除中状态</span></div><div class="token-line"><span class="token plain">      if (!isTopicDeletionInProgress(partition.topic)) {</span></div><div class="token-line"><span class="token plain">        // targetState表示该分区要变更到的状态</span></div><div class="token-line"><span class="token plain">        // 如果当前状态不是OfflinePartition，即离线状态并且目标状态是离线状态</span></div><div class="token-line"><span class="token plain">        // 这个if语句判断是否要将该主题分区状态转换到离线状态</span></div><div class="token-line"><span class="token plain">        if (currentState != OfflinePartition &amp;&amp; targetState == OfflinePartition) {</span></div><div class="token-line"><span class="token plain">          offlinePartitionCount = offlinePartitionCount + 1</span></div><div class="token-line"><span class="token plain">        // 如果当前状态已经是离线状态，但targetState不是</span></div><div class="token-line"><span class="token plain">        // 这个else if语句判断是否要将该主题分区状态转换到非离线状态</span></div><div class="token-line"><span class="token plain">        } else if (currentState == OfflinePartition &amp;&amp; targetState != OfflinePartition) {</span></div><div class="token-line"><span class="token plain">          offlinePartitionCount = offlinePartitionCount - 1</span></div><div class="token-line"><span class="token plain">        }</span></div><div class="token-line"><span class="token plain">      }</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>该方法首先要判断，此分区所属的主题当前是否处于删除操作的过程中。如果是的话，Kafka就不能修改这个分区的状态，那么代码什么都不做，直接返回。否则，代码会判断该分区是否要转换到离线状态。如果targetState是OfflinePartition，那么就将offlinePartitionCount值加1，毕竟多了一个离线状态的分区。相反地，如果currentState是offlinePartition，而targetState反而不是，那么就将offlinePartitionCount值减1。</p><h3 id="shuttingdownbrokerids"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/04.controller模块/01#shuttingdownbrokerids"><span class="icon icon-link"></span></a>shuttingDownBrokerIds</h3><p>顾名思义，<strong>该字段保存所有正在关闭中的Broker ID列表</strong>。当Controller在管理集群Broker时，它要依靠这个字段来甄别Broker当前是否已关闭，因为处于关闭状态的Broker是不适合执行某些操作的，如分区重分配（Reassignment）以及主题删除等。</p><p>另外，Kafka必须要为这些关闭中的Broker执行很多清扫工作，Controller定义了一个onBrokerFailure方法，它就是用来做这个的。代码如下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">private def onBrokerFailure(deadBrokers: Seq[Int]): Unit = {</span></div><div class="token-line"><span class="token plain">      info(s&quot;Broker failure callback for ${deadBrokers.mkString(&quot;,&quot;)}&quot;)</span></div><div class="token-line"><span class="token plain">      // deadBrokers：给定的一组已终止运行的Broker Id列表</span></div><div class="token-line"><span class="token plain">      // 更新Controller元数据信息，将给定Broker从元数据的replicasOnOfflineDirs中移除</span></div><div class="token-line"><span class="token plain">      deadBrokers.foreach(controllerContext.replicasOnOfflineDirs.remove)</span></div><div class="token-line"><span class="token plain">      // 找出这些Broker上的所有副本对象</span></div><div class="token-line"><span class="token plain">      val deadBrokersThatWereShuttingDown =</span></div><div class="token-line"><span class="token plain">        deadBrokers.filter(id =&gt; controllerContext.shuttingDownBrokerIds.remove(id))</span></div><div class="token-line"><span class="token plain">      if (deadBrokersThatWereShuttingDown.nonEmpty)</span></div><div class="token-line"><span class="token plain">        info(s&quot;Removed ${deadBrokersThatWereShuttingDown.mkString(&quot;,&quot;)} from list of shutting down brokers.&quot;)</span></div><div class="token-line"><span class="token plain">      // 执行副本清扫工作</span></div><div class="token-line"><span class="token plain">      val allReplicasOnDeadBrokers = controllerContext.replicasOnBrokers(deadBrokers.toSet)</span></div><div class="token-line"><span class="token plain">      onReplicasBecomeOffline(allReplicasOnDeadBrokers)</span></div><div class="token-line"><span class="token plain">      // 取消这些Broker上注册的ZooKeeper监听器</span></div><div class="token-line"><span class="token plain">      unregisterBrokerModificationsHandler(deadBrokers)</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>该方法接收一组已终止运行的Broker ID列表，首先是更新Controller元数据信息，将给定Broker从元数据的replicasOnOfflineDirs和shuttingDownBrokerIds中移除，然后为这组Broker执行必要的副本清扫工作，也就是onReplicasBecomeOffline方法做的事情。</p><p>该方法主要依赖于分区状态机和副本状态机来完成对应的工作。在后面的课程中，我们会专门讨论副本状态机和分区状态机，这里你只要简单了解下它要做的事情就行了。后面等我们学完了这两个状态机之后，你可以再看下这个方法的具体实现原理。</p><p>这个方法的主要目的是把给定的副本标记成Offline状态，即不可用状态。具体分为以下这几个步骤：</p><ol><li>利用分区状态机将给定副本所在的分区标记为Offline状态；</li><li>将集群上所有新分区和Offline分区状态变更为Online状态；</li><li>将相应的副本对象状态变更为Offline。</li></ol><h3 id="livebrokers"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/04.controller模块/01#livebrokers"><span class="icon icon-link"></span></a>liveBrokers</h3><p><strong>该字段保存当前所有运行中的Broker对象</strong>。每个Broker对象就是一个&lt;Id，EndPoint，机架信息&gt;的三元组。ControllerContext中定义了很多方法来管理该字段，如addLiveBrokersAndEpochs、removeLiveBrokers和updateBrokerMetadata等。我拿updateBrokerMetadata方法进行说明，以下是源码：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">def updateBrokerMetadata(oldMetadata: Broker, newMetadata: Broker): Unit = {</span></div><div class="token-line"><span class="token plain">        liveBrokers -= oldMetadata</span></div><div class="token-line"><span class="token plain">        liveBrokers += newMetadata</span></div><div class="token-line"><span class="token plain">      }</span></div></pre></div><p>每当新增或移除已有Broker时，ZooKeeper就会更新其保存的Broker数据，从而引发Controller修改元数据，也就是会调用updateBrokerMetadata方法来增减Broker列表中的对象。怎么样，超简单吧？！</p><h3 id="livebrokerepochs"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/04.controller模块/01#livebrokerepochs"><span class="icon icon-link"></span></a>liveBrokerEpochs</h3><p><strong>该字段保存所有运行中Broker的Epoch信息</strong>。Kafka使用Epoch数据防止Zombie Broker，即一个非常老的Broker被选举成为Controller。</p><p>另外，源码大多使用这个字段来获取所有运行中Broker的ID序号，如下面这个方法定义的那样：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">def liveBrokerIds: Set[Int] = liveBrokerEpochs.keySet -- shuttingDownBrokerIds</span></div></pre></div><p>liveBrokerEpochs的keySet方法返回Broker序号列表，然后从中移除关闭中的Broker序号，剩下的自然就是处于运行中的Broker序号列表了。</p><h3 id="epoch--epochzkversion"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/04.controller模块/01#epoch--epochzkversion"><span class="icon icon-link"></span></a>epoch &amp; epochZkVersion</h3><p>这两个字段一起说，因为它们都有“epoch”字眼，放在一起说，可以帮助你更好地理解两者的区别。epoch实际上就是ZooKeeper中/controller_epoch节点的值，你可以认为它就是Controller在整个Kafka集群的版本号，而epochZkVersion实际上是/controller_epoch节点的dataVersion值。</p><p>Kafka使用epochZkVersion来判断和防止Zombie Controller。这也就是说，原先在老Controller任期内的Controller操作在新Controller不能成功执行，因为新Controller的epochZkVersion要比老Controller的大。</p><p>另外，你可能会问：“这里的两个Epoch和上面的liveBrokerEpochs有啥区别呢？”实际上，这里的两个Epoch值都是属于Controller侧的数据，而liveBrokerEpochs是每个Broker自己的Epoch值。</p><h3 id="alltopics"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/04.controller模块/01#alltopics"><span class="icon icon-link"></span></a>allTopics</h3><p><strong>该字段保存集群上所有的主题名称</strong>。每当有主题的增减，Controller就要更新该字段的值。</p><p>比如Controller有个processTopicChange方法，从名字上来看，它就是处理主题变更的。我们来看下它的代码实现，我把主要逻辑以注释的方式标注了出来：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">private def processTopicChange(): Unit = {</span></div><div class="token-line"><span class="token plain">        if (!isActive) return // 如果Contorller已经关闭，直接返回</span></div><div class="token-line"><span class="token plain">        val topics = zkClient.getAllTopicsInCluster(true) // 从ZooKeeper中获取当前所有主题列表</span></div><div class="token-line"><span class="token plain">        val newTopics = topics -- controllerContext.allTopics // 找出当前元数据中不存在、ZooKeeper中存在的主题，视为新增主题</span></div><div class="token-line"><span class="token plain">        val deletedTopics = controllerContext.allTopics -- topics // 找出当前元数据中存在、ZooKeeper中不存在的主题，视为已删除主题</span></div><div class="token-line"><span class="token plain">        controllerContext.allTopics = topics // 更新Controller元数据</span></div><div class="token-line"><span class="token plain">        // 为新增主题和已删除主题执行后续处理操作</span></div><div class="token-line"><span class="token plain">        registerPartitionModificationsHandlers(newTopics.toSeq)</span></div><div class="token-line"><span class="token plain">        val addedPartitionReplicaAssignment = zkClient.getFullReplicaAssignmentForTopics(newTopics)</span></div><div class="token-line"><span class="token plain">        deletedTopics.foreach(controllerContext.removeTopic)</span></div><div class="token-line"><span class="token plain">        addedPartitionReplicaAssignment.foreach {</span></div><div class="token-line"><span class="token plain">          case (topicAndPartition, newReplicaAssignment) =&gt; controllerContext.updatePartitionFullReplicaAssignment(topicAndPartition, newReplicaAssignment)</span></div><div class="token-line"><span class="token plain">        }</span></div><div class="token-line"><span class="token plain">        info(s&quot;New topics: [$newTopics], deleted topics: [$deletedTopics], new partition replica assignment &quot; +</span></div><div class="token-line"><span class="token plain">          s&quot;[$addedPartitionReplicaAssignment]&quot;)</span></div><div class="token-line"><span class="token plain">        if (addedPartitionReplicaAssignment.nonEmpty)</span></div><div class="token-line"><span class="token plain">          onNewPartitionCreation(addedPartitionReplicaAssignment.keySet)</span></div><div class="token-line"><span class="token plain">      }</span></div></pre></div><h3 id="partitionassignments"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/04.controller模块/01#partitionassignments"><span class="icon icon-link"></span></a>partitionAssignments</h3><p><strong>该字段保存所有主题分区的副本分配情况</strong>。在我看来，<strong>这是Controller最重要的元数据了</strong>。事实上，你可以从这个字段衍生、定义很多实用的方法，来帮助Kafka从各种维度获取数据。</p><p>比如，如果Kafka要获取某个Broker上的所有分区，那么，它可以这样定义：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">partitionAssignments.flatMap {</span></div><div class="token-line"><span class="token plain">          case (topic, topicReplicaAssignment) =&gt; topicReplicaAssignment.filter {</span></div><div class="token-line"><span class="token plain">            case (_, partitionAssignment) =&gt; partitionAssignment.replicas.contains(brokerId)</span></div><div class="token-line"><span class="token plain">          }.map {</span></div><div class="token-line"><span class="token plain">            case (partition, _) =&gt; new TopicPartition(topic, partition)</span></div><div class="token-line"><span class="token plain">          }</span></div><div class="token-line"><span class="token plain">        }.toSet</span></div></pre></div><p>再比如，如果Kafka要获取某个主题的所有分区对象，代码可以这样写：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">partitionAssignments.getOrElse(topic, mutable.Map.empty).map {</span></div><div class="token-line"><span class="token plain">          case (partition, _) =&gt; new TopicPartition(topic, partition)</span></div><div class="token-line"><span class="token plain">        }.toSet</span></div></pre></div><p>实际上，这两段代码分别是ControllerContext.scala中partitionsOnBroker方法和partitionsForTopic两个方法的主体实现代码。</p><p>讲到这里，9个重要的元数据字段我就介绍完了。前面说过，ControllerContext中一共定义了17个元数据字段，你可以结合这9个字段，把其余8个的定义也过一遍，做到心中有数。<strong>你对Controller元数据掌握得越好，就越能清晰地理解Controller在集群中发挥的作用</strong>。</p><p>值得注意的是，在学习每个元数据字段时，除了它的定义之外，我建议你去搜索一下，与之相关的工具方法都是如何实现的。如果后面你想要新增获取或更新元数据的方法，你要对操作它们的代码有很强的把控力才行。</p><h2 id="总结"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/04.controller模块/01#总结"><span class="icon icon-link"></span></a>总结</h2><p>今天，我们揭开了Kafka重要组件Controller的学习大幕。我给出了Controller模块的学习路线，还介绍了Controller的重要元数据。</p><ul><li>Controller元数据：Controller当前定义了17种元数据，涵盖Kafka集群数据的方方面面。</li><li>ControllerContext：定义元数据以及操作它们的类。</li><li>关键元数据字段：最重要的元数据包括offlinePartitionCount、liveBrokers、partitionAssignments等。</li><li>ControllerContext工具方法：ControllerContext 类定义了很多实用方法来管理这些元数据信息。</li></ul><p>下节课，我们将学习Controller是如何给Broker发送请求的。Controller与Broker进行交互与通信，是Controller奠定王者地位的重要一环，我会向你详细解释它是如何做到这一点的。</p><h2 id="课后讨论"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/04.controller模块/01#课后讨论"><span class="icon icon-link"></span></a>课后讨论</h2><p>我今天并未给出所有的元数据说明，请你自行结合代码分析一下，partitionLeadershipInfo里面保存的是什么数据？</p><p>欢迎你在留言区写下你的思考和答案，跟我交流讨论，也欢迎你把今天的内容分享给你的朋友。</p></div><div class="__dumi-default-layout-footer-meta"><a target="_blank" rel="noopener noreferrer" href="https://github.com/GGwujun/blog/edit/master/ssrc/kafka核心源码解读/04.Controller模块/01.md">在 GitHub 上编辑此页<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a><span data-updated-text="最后更新时间：">2023/9/27 11:15:40</span></div></div></div></div>
	<script>
  window.g_useSSR = true;
  window.g_initialProps = {};
	</script>

    <script>
      (function () {
        if (!location.port) {
          (function (i, s, o, g, r, a, m) {
            i["GoogleAnalyticsObject"] = r;
            (i[r] =
              i[r] ||
              function () {
                (i[r].q = i[r].q || []).push(arguments);
              }),
              (i[r].l = 1 * new Date());
            (a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m);
          })(
            window,
            document,
            "script",
            "//www.google-analytics.com/analytics.js",
            "ga"
          );
          ga("create", "UA-149864185-1", "auto");
          ga("send", "pageview");
        }
      })();
    </script>
    <script src="/blog-backend/umi.e14e5a14.js"></script>
  </body>
</html>
