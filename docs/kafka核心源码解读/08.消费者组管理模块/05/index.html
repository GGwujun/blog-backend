<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no"
    />
    <link rel="shortcut icon" type="image/x-icon" href="/logo.png" />
    <link rel="stylesheet" href="/blog-backend/umi.3ec1f225.css" />
    <script>
      window.routerBase = "/blog-backend";
    </script>
    <script>
      //! umi version: 3.5.41
    </script>
    <script>
      !(function () {
        var e =
            navigator.cookieEnabled && void 0 !== window.localStorage
              ? localStorage.getItem("dumi:prefers-color")
              : "auto",
          o = window.matchMedia("(prefers-color-scheme: dark)").matches,
          t = ["light", "dark", "auto"];
        document.documentElement.setAttribute(
          "data-prefers-color",
          e === t[2] ? (o ? t[1] : t[0]) : t.indexOf(e) > -1 ? e : t[0]
        );
      })();
    </script>
    <title>
      31 | GroupMetadataManager：查询位移时，不用读取位移主题？ - 大师兄
    </title>
  </head>
  <body>
    <div id="root"><div class="__dumi-default-layout" data-route="/kafka核心源码解读/08.消费者组管理模块/05" data-show-sidemenu="true" data-show-slugs="true" data-site-mode="true" data-gapless="false"><div class="__dumi-default-navbar" data-mode="site"><button class="__dumi-default-navbar-toggle"></button><a class="__dumi-default-navbar-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-backend/">大师兄</a><nav><div class="__dumi-default-search"><input type="search" class="__dumi-default-search-input" value=""/><ul></ul></div><span>后端开发<ul><li><a href="/blog-backend/go语言核心36讲">go语言核心36讲</a></li><li><a href="/blog-backend/go并发编程实战">go并发编程实战</a></li><li><a href="/blog-backend/go语言项目开发实战">go语言项目开发实战</a></li><li><a href="/blog-backend/kafka核心技术与实战">kafka核心技术与实战</a></li><li><a aria-current="page" class="active" href="/blog-backend/kafka核心源码解读">kafka核心源码解读</a></li><li><a href="/blog-backend/零基础学python">零基础学python</a></li><li><a href="/blog-backend/python核心技术与实战">python核心技术与实战</a></li><li><a href="/blog-backend/redis核心技术与实战">redis核心技术与实战</a></li><li><a href="/blog-backend/redis源码剖析与实战">redis源码剖析与实战</a></li><li><a href="/blog-backend/陈天rust编程第一课">陈天rust编程第一课</a></li><li><a href="/blog-backend/tonybaigo语言第一课">tonybaigo语言第一课</a></li><li><a href="/blog-backend/后端存储实战课">后端存储实战课</a></li><li><a href="/blog-backend/后端技术面试38讲">后端技术面试38讲</a></li><li><a href="/blog-backend/深入c语言和程序运行原理">深入c语言和程序运行原理</a></li><li><a href="/blog-backend/现代c编程实战">现代c编程实战</a></li><li><a href="/blog-backend/罗剑锋的c实战笔记">罗剑锋的c实战笔记</a></li><li><a href="/blog-backend/零基础入门spark">零基础入门spark</a></li></ul></span><span>架构师<ul><li><a href="/blog-backend/mysql实战45讲">mysql实战45讲</a></li><li><a href="/blog-backend/数据中台实战课">数据中台实战课</a></li></ul></span><div class="__dumi-default-navbar-tool"><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "></div></div></div></nav></div><div class="__dumi-default-menu" data-mode="site"><div class="__dumi-default-menu-inner"><div class="__dumi-default-menu-header"><a class="__dumi-default-menu-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-backend/"></a><h1>大师兄</h1><p></p></div><div class="__dumi-default-menu-mobile-area"><ul class="__dumi-default-menu-nav-list"><li>后端开发<ul><li><a href="/blog-backend/go语言核心36讲">go语言核心36讲</a></li><li><a href="/blog-backend/go并发编程实战">go并发编程实战</a></li><li><a href="/blog-backend/go语言项目开发实战">go语言项目开发实战</a></li><li><a href="/blog-backend/kafka核心技术与实战">kafka核心技术与实战</a></li><li><a aria-current="page" class="active" href="/blog-backend/kafka核心源码解读">kafka核心源码解读</a></li><li><a href="/blog-backend/零基础学python">零基础学python</a></li><li><a href="/blog-backend/python核心技术与实战">python核心技术与实战</a></li><li><a href="/blog-backend/redis核心技术与实战">redis核心技术与实战</a></li><li><a href="/blog-backend/redis源码剖析与实战">redis源码剖析与实战</a></li><li><a href="/blog-backend/陈天rust编程第一课">陈天rust编程第一课</a></li><li><a href="/blog-backend/tonybaigo语言第一课">tonybaigo语言第一课</a></li><li><a href="/blog-backend/后端存储实战课">后端存储实战课</a></li><li><a href="/blog-backend/后端技术面试38讲">后端技术面试38讲</a></li><li><a href="/blog-backend/深入c语言和程序运行原理">深入c语言和程序运行原理</a></li><li><a href="/blog-backend/现代c编程实战">现代c编程实战</a></li><li><a href="/blog-backend/罗剑锋的c实战笔记">罗剑锋的c实战笔记</a></li><li><a href="/blog-backend/零基础入门spark">零基础入门spark</a></li></ul></li><li>架构师<ul><li><a href="/blog-backend/mysql实战45讲">mysql实战45讲</a></li><li><a href="/blog-backend/数据中台实战课">数据中台实战课</a></li></ul></li></ul><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "><button title="Dark theme" class="__dumi-default-dark-moon "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3854" width="22" height="22"><path d="M991.816611 674.909091a69.166545 69.166545 0 0 0-51.665455-23.272727 70.795636 70.795636 0 0 0-27.438545 5.585454A415.674182 415.674182 0 0 1 754.993338 698.181818c-209.594182 0-393.472-184.785455-393.472-395.636363 0-52.363636 38.539636-119.621818 69.515637-173.614546 4.887273-8.610909 9.634909-16.756364 14.103272-24.901818A69.818182 69.818182 0 0 0 384.631156 0a70.842182 70.842182 0 0 0-27.438545 5.585455C161.678429 90.298182 14.362065 307.898182 14.362065 512c0 282.298182 238.824727 512 532.38691 512a522.286545 522.286545 0 0 0 453.957818-268.334545A69.818182 69.818182 0 0 0 991.816611 674.909091zM546.679156 954.181818c-248.785455 0-462.941091-192-462.941091-442.181818 0-186.647273 140.637091-372.829091 300.939637-442.181818-36.817455 65.629091-92.578909 151.970909-92.578909 232.727273 0 250.181818 214.109091 465.454545 462.917818 465.454545a488.331636 488.331636 0 0 0 185.181091-46.545455 453.003636 453.003636 0 0 1-393.565091 232.727273z m103.656728-669.323636l-14.266182 83.781818a34.909091 34.909091 0 0 0 50.362182 36.770909l74.775272-39.563636 74.752 39.563636a36.142545 36.142545 0 0 0 16.174546 3.956364 34.909091 34.909091 0 0 0 34.210909-40.727273l-14.289455-83.781818 60.509091-59.345455a35.025455 35.025455 0 0 0-19.223272-59.578182l-83.61891-12.101818-37.376-76.101818a34.56 34.56 0 0 0-62.254545 0l-37.376 76.101818-83.618909 12.101818a34.909091 34.909091 0 0 0-19.246546 59.578182z m70.423272-64.698182a34.280727 34.280727 0 0 0 26.135273-19.083636l14.312727-29.090909 14.336 29.090909a34.257455 34.257455 0 0 0 26.135273 19.083636l32.046546 4.887273-23.272728 22.574545a35.234909 35.234909 0 0 0-10.007272 30.952727l5.46909 32.116364-28.625454-15.127273a34.490182 34.490182 0 0 0-32.302546 0l-28.695272 15.127273 5.469091-32.116364a35.141818 35.141818 0 0 0-9.984-30.952727l-23.272728-22.574545z" p-id="3855"></path></svg></button><button title="Light theme" class="__dumi-default-dark-sun "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4026" width="22" height="22"><path d="M915.2 476.16h-43.968c-24.704 0-44.736 16-44.736 35.84s20.032 35.904 44.736 35.904H915.2c24.768 0 44.8-16.064 44.8-35.904s-20.032-35.84-44.8-35.84zM512 265.6c-136.704 0-246.464 109.824-246.464 246.4 0 136.704 109.76 246.464 246.464 246.464S758.4 648.704 758.4 512c0-136.576-109.696-246.4-246.4-246.4z m0 425.6c-99.008 0-179.2-80.128-179.2-179.2 0-98.944 80.192-179.2 179.2-179.2S691.2 413.056 691.2 512c0 99.072-80.192 179.2-179.2 179.2zM197.44 512c0-19.84-19.136-35.84-43.904-35.84H108.8c-24.768 0-44.8 16-44.8 35.84s20.032 35.904 44.8 35.904h44.736c24.768 0 43.904-16.064 43.904-35.904zM512 198.464c19.776 0 35.84-20.032 35.84-44.8v-44.8C547.84 84.032 531.84 64 512 64s-35.904 20.032-35.904 44.8v44.8c0 24.768 16.128 44.864 35.904 44.864z m0 627.136c-19.776 0-35.904 20.032-35.904 44.8v44.736C476.096 940.032 492.16 960 512 960s35.84-20.032 35.84-44.8v-44.736c0-24.768-16.064-44.864-35.84-44.864z m329.92-592.832c17.472-17.536 20.288-43.072 6.4-57.024-14.016-14.016-39.488-11.2-57.024 6.336-4.736 4.864-26.496 26.496-31.36 31.36-17.472 17.472-20.288 43.008-6.336 57.024 13.952 14.016 39.488 11.2 57.024-6.336 4.8-4.864 26.496-26.56 31.296-31.36zM213.376 759.936c-4.864 4.8-26.56 26.624-31.36 31.36-17.472 17.472-20.288 42.944-6.4 56.96 14.016 13.952 39.552 11.2 57.024-6.336 4.8-4.736 26.56-26.496 31.36-31.36 17.472-17.472 20.288-43.008 6.336-56.96-14.016-13.952-39.552-11.072-56.96 6.336z m19.328-577.92c-17.536-17.536-43.008-20.352-57.024-6.336-14.08 14.016-11.136 39.488 6.336 57.024 4.864 4.864 26.496 26.56 31.36 31.424 17.536 17.408 43.008 20.288 56.96 6.336 14.016-14.016 11.264-39.488-6.336-57.024-4.736-4.864-26.496-26.56-31.296-31.424z m527.168 628.608c4.864 4.864 26.624 26.624 31.36 31.424 17.536 17.408 43.072 20.224 57.088 6.336 13.952-14.016 11.072-39.552-6.4-57.024-4.864-4.8-26.56-26.496-31.36-31.36-17.472-17.408-43.072-20.288-57.024-6.336-13.952 14.016-11.008 39.488 6.336 56.96z" p-id="4027"></path></svg></button><button title="Default to system" class="__dumi-default-dark-auto "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="11002" width="22" height="22"><path d="M127.658667 492.885333c0-51.882667 10.24-101.717333 30.378666-149.162666s47.786667-88.064 81.92-122.538667 75.093333-61.781333 122.538667-81.92 96.938667-30.378667 149.162667-30.378667 101.717333 10.24 149.162666 30.378667 88.405333 47.786667 122.88 81.92 61.781333 75.093333 81.92 122.538667 30.378667 96.938667 30.378667 149.162666-10.24 101.717333-30.378667 149.162667-47.786667 88.405333-81.92 122.88-75.093333 61.781333-122.88 81.92-97.28 30.378667-149.162666 30.378667-101.717333-10.24-149.162667-30.378667-88.064-47.786667-122.538667-81.92-61.781333-75.093333-81.92-122.88-30.378667-96.938667-30.378666-149.162667z m329.045333 0c0 130.048 13.994667 244.394667 41.984 343.381334h12.970667c46.762667 0 91.136-9.216 133.461333-27.306667s78.848-42.666667 109.568-73.386667 54.954667-67.242667 73.386667-109.568 27.306667-86.698667 27.306666-133.461333c0-46.421333-9.216-90.794667-27.306666-133.12s-42.666667-78.848-73.386667-109.568-67.242667-54.954667-109.568-73.386667-86.698667-27.306667-133.461333-27.306666h-11.605334c-28.672 123.562667-43.349333 237.909333-43.349333 343.722666z" p-id="11003"></path></svg></button></div></div></div><ul class="__dumi-default-menu-list"><li><a href="/blog-backend/kafka核心源码解读">kafka核心源码解读</a></li><li><a href="/blog-backend/kafka核心源码解读/01.课前必学">01.课前必学</a><ul><li><a href="/blog-backend/kafka核心源码解读/01.课前必学/01"><span>开篇词 |  阅读源码，逐渐成了职业进阶道路上的“必选项”</span></a></li><li><a href="/blog-backend/kafka核心源码解读/01.课前必学/02"><span>导读 | 构建Kafka工程和源码阅读环境、Scala语言热身</span></a></li><li><a href="/blog-backend/kafka核心源码解读/01.课前必学/03"><span>重磅加餐 | 带你快速入门Scala语言</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/02.日志模块">02.日志模块</a><ul><li><a href="/blog-backend/kafka核心源码解读/02.日志模块/01"><span>01 | 日志段：保存消息文件的对象是怎么实现的？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/02.日志模块/02"><span>02 | 日志（上）：日志究竟是如何加载日志段的？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/02.日志模块/03"><span>03 | 日志（下）：彻底搞懂Log对象的常见操作</span></a></li><li><a href="/blog-backend/kafka核心源码解读/02.日志模块/04"><span>04 | 索引（上）：改进的二分查找算法在Kafka索引的应用</span></a></li><li><a href="/blog-backend/kafka核心源码解读/02.日志模块/05"><span>05 | 索引（下）：位移索引和时间戳索引的区别是什么？</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/03.请求处理模块">03.请求处理模块</a><ul><li><a href="/blog-backend/kafka核心源码解读/03.请求处理模块/01"><span>06 | 请求通道：如何实现Kafka请求队列？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/03.请求处理模块/02"><span>07 | SocketServer（上）：Kafka到底是怎么应用NIO实现网络通信的？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/03.请求处理模块/03"><span>08 | SocketServer（中）：请求还要区分优先级？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/03.请求处理模块/04"><span>09 | SocketServer（下）：请求处理全流程源码分析</span></a></li><li><a href="/blog-backend/kafka核心源码解读/03.请求处理模块/05"><span>10 | KafkaApis：Kafka最重要的源码入口，没有之一</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/04.controller模块">04.Controller模块</a><ul><li><a href="/blog-backend/kafka核心源码解读/04.controller模块/01"><span>11 | Controller元数据：Controller都保存有哪些东西？有几种状态？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/04.controller模块/02"><span>12 | ControllerChannelManager：Controller如何管理请求发送？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/04.controller模块/03"><span>13 | ControllerEventManager：变身单线程后的Controller如何处理事件？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/04.controller模块/04"><span>14 | Controller选举是怎么实现的？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/04.controller模块/05"><span>15 | 如何理解Controller在Kafka集群中的作用？</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/05.状态机模块">05.状态机模块</a><ul><li><a href="/blog-backend/kafka核心源码解读/05.状态机模块/01"><span>16 | TopicDeletionManager： Topic是怎么被删除的？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/05.状态机模块/02"><span>17 | ReplicaStateMachine：揭秘副本状态机实现原理</span></a></li><li><a href="/blog-backend/kafka核心源码解读/05.状态机模块/03"><span>18 | PartitionStateMachine：分区状态转换如何实现？</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/06.延迟操作模块">06.延迟操作模块</a><ul><li><a href="/blog-backend/kafka核心源码解读/06.延迟操作模块/01"><span>19 | TimingWheel：探究Kafka定时器背后的高效时间轮算法</span></a></li><li><a href="/blog-backend/kafka核心源码解读/06.延迟操作模块/02"><span>20 | DelayedOperation：Broker是怎么延时处理请求的？</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/07.副本管理模块">07.副本管理模块</a><ul><li><a href="/blog-backend/kafka核心源码解读/07.副本管理模块/01"><span>21 | AbstractFetcherThread：拉取消息分几步？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/07.副本管理模块/02"><span>22 | ReplicaFetcherThread：Follower如何拉取Leader消息？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/07.副本管理模块/03"><span>23 | ReplicaManager（上）：必须要掌握的副本管理类定义和核心字段</span></a></li><li><a href="/blog-backend/kafka核心源码解读/07.副本管理模块/04"><span>24 | ReplicaManager（中）：副本管理器是如何读写副本的？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/07.副本管理模块/05"><span>25 | ReplicaManager（下）：副本管理器是如何管理副本的？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/07.副本管理模块/06"><span>26 | MetadataCache：Broker是怎么异步更新元数据缓存的？</span></a></li></ul></li><li><a aria-current="page" class="active" href="/blog-backend/kafka核心源码解读/08.消费者组管理模块">08.消费者组管理模块</a><ul><li><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/01"><span>27 | 消费者组元数据（上）：消费者组都有哪些元数据？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/02"><span>28 | 消费者组元数据（下）：Kafka如何管理这些元数据？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/03"><span>29 | GroupMetadataManager：组元数据管理器是个什么东西？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/04"><span>30 | GroupMetadataManager：位移主题保存的只是位移吗？</span></a></li><li><a aria-current="page" class="active" href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/05"><span>31 | GroupMetadataManager：查询位移时，不用读取位移主题？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/06"><span>32 | GroupCoordinator：在Rebalance中，Coordinator如何处理成员入组？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/07"><span>33 | GroupCoordinator：在Rebalance中，如何进行组同步？</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/09.特别放送">09.特别放送</a><ul><li><a href="/blog-backend/kafka核心源码解读/09.特别放送/01"><span>特别放送（一）| 经典的Kafka学习资料有哪些？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/09.特别放送/02"><span>特别放送（二）| 一篇文章带你了解参与开源社区的全部流程</span></a></li><li><a href="/blog-backend/kafka核心源码解读/09.特别放送/03"><span>特别放送（三）| 我是怎么度过日常一天的？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/09.特别放送/04"><span>特别放送（四）| 20道经典的Kafka面试题详解</span></a></li><li><a href="/blog-backend/kafka核心源码解读/09.特别放送/05"><span>特别放送（五） | Kafka 社区的重磅功能：移除 ZooKeeper 依赖</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/10.测试题">10.测试题</a><ul><li><a href="/blog-backend/kafka核心源码解读/10.测试题/01"><span>期中测试 | 这些源码知识，你都掌握了吗？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/10.测试题/02"><span>期末测试 | 一套习题，测试你的掌握程度</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/11.结束语">11.结束语</a><ul><li><a href="/blog-backend/kafka核心源码解读/11.结束语/01"><span>结束语 | 源码学习，我们才刚上路呢</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/summary">kafka核心源码解读</a></li></ul></div></div><ul role="slug-list" class="__dumi-default-layout-toc"><li title="写入位移主题" data-depth="2"><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/05#写入位移主题"><span>写入位移主题</span></a></li><li title="读取位移主题" data-depth="2"><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/05#读取位移主题"><span>读取位移主题</span></a></li><li title="第1部分" data-depth="3"><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/05#第1部分"><span>第1部分</span></a></li><li title="第2部分" data-depth="3"><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/05#第2部分"><span>第2部分</span></a></li><li title="第3部分" data-depth="3"><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/05#第3部分"><span>第3部分</span></a></li><li title="总结" data-depth="2"><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/05#总结"><span>总结</span></a></li><li title="课后讨论" data-depth="2"><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/05#课后讨论"><span>课后讨论</span></a></li></ul><div class="__dumi-default-layout-content"><div class="markdown"><h1 id="31--groupmetadatamanager查询位移时不用读取位移主题"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/05#31--groupmetadatamanager查询位移时不用读取位移主题"><span class="icon icon-link"></span></a>31 | GroupMetadataManager：查询位移时，不用读取位移主题？</h1><p>你好，我是胡夕。</p><p>上节课，我们学习了位移主题中的两类消息：<strong>消费者组注册消息</strong>和<strong>消费者组已提交位移消息</strong>。今天，我们接着学习位移主题，重点是掌握写入位移主题和读取位移主题。</p><p>我们总说，位移主题是个神秘的主题，除了它并非我们亲自创建之外，它的神秘之处还体现在，它的读写也不由我们控制。默认情况下，我们没法向这个主题写入消息，而且直接读取该主题的消息时，看到的更是一堆乱码。因此，今天我们学习一下读写位移主题，这正是去除它神秘感的重要一步。</p><h2 id="写入位移主题"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/05#写入位移主题"><span class="icon icon-link"></span></a>写入位移主题</h2><p>我们先来学习一下位移主题的写入。在<a target="_blank" rel="noopener noreferrer" href="https://time.geekbang.org/column/article/257053">第29讲<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>学习storeOffsets方法时，我们已经学过了appendForGroup方法。Kafka定义的两类消息类型都是由它写入的。在源码中，storeGroup方法调用它写入消费者组注册消息，storeOffsets方法调用它写入已提交位移消息。</p><p>首先，我们需要知道storeGroup方法，它的作用是<strong>向Coordinator注册消费者组</strong>。我们看下它的代码实现：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">def storeGroup(group: GroupMetadata,</span></div><div class="token-line"><span class="token plain">                   groupAssignment: Map[String, Array[Byte]],</span></div><div class="token-line"><span class="token plain">                   responseCallback: Errors =&gt; Unit): Unit = {</span></div><div class="token-line"><span class="token plain">      // 判断当前Broker是否是该消费者组的Coordinator</span></div><div class="token-line"><span class="token plain">      getMagic(partitionFor(group.groupId)) match {</span></div><div class="token-line"><span class="token plain">        // 如果当前Broker不是Coordinator</span></div><div class="token-line"><span class="token plain">        case Some(magicValue) =&gt;</span></div><div class="token-line"><span class="token plain">          val timestampType = TimestampType.CREATE_TIME</span></div><div class="token-line"><span class="token plain">          val timestamp = time.milliseconds()</span></div><div class="token-line"><span class="token plain">          // 构建注册消息的Key</span></div><div class="token-line"><span class="token plain">          val key = GroupMetadataManager.groupMetadataKey(group.groupId)</span></div><div class="token-line"><span class="token plain">          // 构建注册消息的Value</span></div><div class="token-line"><span class="token plain">          val value = GroupMetadataManager.groupMetadataValue(group, groupAssignment, interBrokerProtocolVersion)</span></div><div class="token-line"><span class="token plain">          // 使用Key和Value构建待写入消息集合</span></div><div class="token-line"><span class="token plain">          val records = {</span></div><div class="token-line"><span class="token plain">            val buffer = ByteBuffer.allocate(AbstractRecords.estimateSizeInBytes(magicValue, compressionType,</span></div><div class="token-line"><span class="token plain">              Seq(new SimpleRecord(timestamp, key, value)).asJava))</span></div><div class="token-line"><span class="token plain">            val builder = MemoryRecords.builder(buffer, magicValue, compressionType, timestampType, 0L)</span></div><div class="token-line"><span class="token plain">            builder.append(timestamp, key, value)</span></div><div class="token-line"><span class="token plain">            builder.build()</span></div><div class="token-line"><span class="token plain">          }</span></div><div class="token-line"><span class="token plain">          // 计算要写入的目标分区</span></div><div class="token-line"><span class="token plain">          val groupMetadataPartition = new TopicPartition(Topic.GROUP_METADATA_TOPIC_NAME, partitionFor(group.groupId))</span></div><div class="token-line"><span class="token plain">          val groupMetadataRecords = Map(groupMetadataPartition -&gt; records)</span></div><div class="token-line"><span class="token plain">          val generationId = group.generationId</span></div><div class="token-line"><span class="token plain">          // putCacheCallback方法，填充Cache</span></div><div class="token-line"><span class="token plain">          ......</span></div><div class="token-line"><span class="token plain">          // 向位移主题写入消息</span></div><div class="token-line"><span class="token plain">          appendForGroup(group, groupMetadataRecords, putCacheCallback)</span></div><div class="token-line"><span class="token plain">        // 如果当前Broker不是Coordinator</span></div><div class="token-line"><span class="token plain">        case None =&gt;</span></div><div class="token-line"><span class="token plain">          // 返回NOT_COORDINATOR异常</span></div><div class="token-line"><span class="token plain">          responseCallback(Errors.NOT_COORDINATOR)</span></div><div class="token-line"><span class="token plain">          None</span></div><div class="token-line"><span class="token plain">      }</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>为了方便你理解，我画一张图来展示一下storeGroup方法的逻辑。</p><p><img src="/blog-backend/static/httpsstatic001geekbangorgresourceimagea647a6248981bc588722c09e38d6f1294447.085abe3f.jpg" alt=""/></p><p>storeGroup方法的第1步是调用getMagic方法，来判断当前Broker是否是该消费者组的Coordinator组件。判断的依据，是尝试去获取位移主题目标分区的底层日志对象。如果能够获取到，就说明当前Broker是Coordinator，程序进入到下一步；反之，则表明当前Broker不是Coordinator，就构造一个NOT_COORDINATOR异常返回。</p><p>第2步，调用我们上节课学习的groupMetadataKey和groupMetadataValue方法，去构造注册消息的Key和Value字段。</p><p>第3步，使用Key和Value构建待写入消息集合。这里的消息集合类是MemoryRecords。</p><p>当前，建模Kafka消息集合的类有两个。</p><ul><li>MemoryRecords：表示内存中的消息集合；</li><li>FileRecords：表示磁盘文件中的消息集合。</li></ul><p>这两个类的源码不是我们学习的重点，你只需要知道它们的含义就行了。不过，我推荐你课下阅读一下它们的源码，它们在clients工程中，这可以进一步帮助你理解Kafka如何在内存和磁盘上保存消息。</p><p>第4步，调用partitionFor方法，计算要写入的位移主题目标分区。</p><p>第5步，调用appendForGroup方法，将待写入消息插入到位移主题的目标分区下。至此，方法返回。</p><p>需要提一下的是，在上面的代码中，我省略了putCacheCallback方法的源码，我们在第29讲已经详细地学习过它了。它的作用就是当消息被写入到位移主题后，填充Cache。</p><p>可以看到，写入位移主题和写入其它的普通主题并无差别。Coordinator会构造符合规定格式的消息数据，并把它们传给storeOffsets和storeGroup方法，由它们执行写入操作。因此，我们可以认为，Coordinator相当于位移主题的消息生产者。</p><h2 id="读取位移主题"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/05#读取位移主题"><span class="icon icon-link"></span></a>读取位移主题</h2><p>其实，除了生产者这个角色以外，Coordinator还扮演了消费者的角色，也就是读取位移主题。跟写入相比，读取操作的逻辑更加复杂一些，不光体现在代码长度上，更体现在消息读取之后的处理上。</p><p>首先，我们要知道，什么时候需要读取位移主题。</p><p>你可能会觉得，当消费者组查询位移时，会读取该主题下的数据。其实不然。查询位移时，Coordinator只会从GroupMetadata元数据缓存中查找对应的位移值，而不会读取位移主题。真正需要读取位移主题的时机，<strong>是在当前Broker当选Coordinator</strong>，也就是Broker成为了位移主题某分区的Leader副本时。</p><p>一旦当前Broker当选为位移主题某分区的Leader副本，它就需要将它内存中的元数据缓存填充起来，因此需要读取位移主题。在代码中，这是由<strong>scheduleLoadGroupAndOffsets</strong>方法完成的。该方法会创建一个异步任务，来读取位移主题消息，并填充缓存。这个异步任务要执行的逻辑，就是loadGroupsAndOffsets方法。</p><p>如果你翻开loadGroupsAndOffsets方法的源码，就可以看到，它本质上是调用doLoadGroupsAndOffsets方法实现的位移主题读取。下面，我们就重点学习下这个方法。</p><p>这个方法的代码很长，为了让你能够更加清晰地理解它，我先带你了解下它的方法签名，然后再给你介绍具体的实现逻辑。</p><p>首先，我们来看它的方法签名以及内置的一个子方法logEndOffset。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">private def doLoadGroupsAndOffsets(topicPartition: TopicPartition, onGroupLoaded: GroupMetadata =&gt; Unit): Unit = {</span></div><div class="token-line"><span class="token plain">      // 获取位移主题指定分区的LEO值</span></div><div class="token-line"><span class="token plain">      // 如果当前Broker不是该分区的Leader副本，则返回-1</span></div><div class="token-line"><span class="token plain">      def logEndOffset: Long = replicaManager.getLogEndOffset(topicPartition).getOrElse(-1L)</span></div><div class="token-line"><span class="token plain">      ......</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>doLoadGroupsAndOffsets方法，顾名思义，它要做两件事请：加载消费者组；加载消费者组的位移。再强调一遍，所谓的加载，就是指读取位移主题下的消息，并将这些信息填充到缓存中。</p><p>该方法接收两个参数，第一个参数topicPartition是位移主题目标分区；第二个参数onGroupLoaded是加载完成后要执行的逻辑，这个逻辑是在上层组件中指定的，我们不需要掌握它的实现，这不会影响我们学习位移主题的读取。</p><p>doLoadGroupsAndOffsets还定义了一个内置子方法logEndOffset。它的目的很简单，就是<strong>获取位移主题指定分区的LEO值，如果当前Broker不是该分区的Leader副本，就返回-1</strong>。</p><p>这是一个特别重要的事实，因为Kafka依靠它来判断分区的Leader副本是否发生变更。一旦发生变更，那么，在当前Broker执行logEndOffset方法的返回值，就是-1，此时，Broker就不再是Leader副本了。</p><p>doLoadGroupsAndOffsets方法会<strong>读取位移主题目标分区的日志对象</strong>，并执行核心的逻辑动作，代码如下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">......</span></div><div class="token-line"><span class="token plain">    replicaManager.getLog(topicPartition) match {</span></div><div class="token-line"><span class="token plain">      // 如果无法获取到日志对象</span></div><div class="token-line"><span class="token plain">      case None =&gt;</span></div><div class="token-line"><span class="token plain">        warn(s&quot;Attempted to load offsets and group metadata from $topicPartition, but found no log&quot;)</span></div><div class="token-line"><span class="token plain">      case Some(log) =&gt;</span></div><div class="token-line"><span class="token plain">         // 核心逻辑......</span></div></pre></div><p>我把核心的逻辑分成3个部分来介绍。</p><ul><li>第1部分：初始化4个列表+读取位移主题；</li><li>第2部分：处理读到的数据，并填充4个列表；</li><li>第3部分：分别处理这4个列表。</li></ul><p>在具体讲解这个方法所做的事情之前，我先画一张流程图，从宏观层面展示一下这个流程。</p><p><img src="/blog-backend/static/httpsstatic001geekbangorgresourceimaged0fbd03d553361f14695917f6b62528008fb.10c41013.jpg" alt=""/></p><h3 id="第1部分"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/05#第1部分"><span class="icon icon-link"></span></a>第1部分</h3><p>首先，我们来学习一下第一部分的代码，完成了对位移主题的读取操作。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">// 已完成位移值加载的分区列表</span></div><div class="token-line"><span class="token plain">    val loadedOffsets = mutable.Map[GroupTopicPartition, CommitRecordMetadataAndOffset]()</span></div><div class="token-line"><span class="token plain">    // 处于位移加载中的分区列表，只用于Kafka事务</span></div><div class="token-line"><span class="token plain">    val pendingOffsets = mutable.Map[Long, mutable.Map[GroupTopicPartition, CommitRecordMetadataAndOffset]]()</span></div><div class="token-line"><span class="token plain">    // 已完成组信息加载的消费者组列表</span></div><div class="token-line"><span class="token plain">    val loadedGroups = mutable.Map[String, GroupMetadata]()</span></div><div class="token-line"><span class="token plain">    // 待移除的消费者组列表</span></div><div class="token-line"><span class="token plain">    val removedGroups = mutable.Set[String]()</span></div><div class="token-line"><span class="token plain">    // 保存消息集合的ByteBuffer缓冲区</span></div><div class="token-line"><span class="token plain">    var buffer = ByteBuffer.allocate(0)</span></div><div class="token-line"><span class="token plain">    // 位移主题目标分区日志起始位移值</span></div><div class="token-line"><span class="token plain">    var currOffset = log.logStartOffset</span></div><div class="token-line"><span class="token plain">    // 至少要求读取一条消息</span></div><div class="token-line"><span class="token plain">    var readAtLeastOneRecord = true</span></div><div class="token-line"><span class="token plain">    // 当前读取位移&lt;LEO，且至少要求读取一条消息，且GroupMetadataManager未关闭</span></div><div class="token-line"><span class="token plain">    while (currOffset &lt; logEndOffset &amp;&amp; readAtLeastOneRecord &amp;&amp; !shuttingDown.get()) {</span></div><div class="token-line"><span class="token plain">      // 读取位移主题指定分区</span></div><div class="token-line"><span class="token plain">      val fetchDataInfo = log.read(currOffset,</span></div><div class="token-line"><span class="token plain">        maxLength = config.loadBufferSize,</span></div><div class="token-line"><span class="token plain">        isolation = FetchLogEnd,</span></div><div class="token-line"><span class="token plain">        minOneMessage = true)</span></div><div class="token-line"><span class="token plain">      // 如果无消息可读，则不再要求至少读取一条消息</span></div><div class="token-line"><span class="token plain">      readAtLeastOneRecord = fetchDataInfo.records.sizeInBytes &gt; 0</span></div><div class="token-line"><span class="token plain">      // 创建消息集合</span></div><div class="token-line"><span class="token plain">      val memRecords = fetchDataInfo.records match {</span></div><div class="token-line"><span class="token plain">        case records: MemoryRecords =&gt; records</span></div><div class="token-line"><span class="token plain">        case fileRecords: FileRecords =&gt;</span></div><div class="token-line"><span class="token plain">          val sizeInBytes = fileRecords.sizeInBytes</span></div><div class="token-line"><span class="token plain">          val bytesNeeded = Math.max(config.loadBufferSize, sizeInBytes)</span></div><div class="token-line"><span class="token plain">          if (buffer.capacity &lt; bytesNeeded) {</span></div><div class="token-line"><span class="token plain">            if (config.loadBufferSize &lt; bytesNeeded)</span></div><div class="token-line"><span class="token plain">              warn(s&quot;Loaded offsets and group metadata from $topicPartition with buffer larger ($bytesNeeded bytes) than &quot; +</span></div><div class="token-line"><span class="token plain">                s&quot;configured offsets.load.buffer.size (${config.loadBufferSize} bytes)&quot;)</span></div><div class="token-line"><span class="token plain">            buffer = ByteBuffer.allocate(bytesNeeded)</span></div><div class="token-line"><span class="token plain">          } else {</span></div><div class="token-line"><span class="token plain">            buffer.clear()</span></div><div class="token-line"><span class="token plain">          }</span></div><div class="token-line"><span class="token plain">          fileRecords.readInto(buffer, 0)</span></div><div class="token-line"><span class="token plain">          MemoryRecords.readableRecords(buffer)</span></div><div class="token-line"><span class="token plain">      }</span></div><div class="token-line"><span class="token plain">      ......</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p><strong>首先</strong>，这部分代码创建了4个列表。</p><ul><li>loadedOffsets：已完成位移值加载的分区列表；</li><li>pendingOffsets：位移值加载中的分区列表；</li><li>loadedGroups：已完成组信息加载的消费者组列表；</li><li>removedGroups：待移除的消费者组列表。</li></ul><p><strong>之后</strong>，代码又创建了一个ByteBuffer缓冲区，用于保存消息集合。<strong>接下来</strong>，计算位移主题目标分区的日志起始位移值，这是要读取的起始位置。<strong>再之后</strong>，代码定义了一个布尔类型的变量，该变量表示本次至少要读取一条消息。</p><p>这些初始化工作都做完之后，代码进入到while循环中。循环的条件有3个，而且需要同时满足：</p><ul><li>读取位移值小于日志LEO值；</li><li>布尔变量值是True；</li><li>GroupMetadataManager未关闭。</li></ul><p>只要满足这3个条件，代码就会一直执行while循环下的语句逻辑。整个while下的逻辑被分成了3个步骤，我们现在学习的第1部分代码，包含了前两步。最后一步在第3部分中实现，即处理上面的这4个列表。我们先看前两步。</p><p>第1步是<strong>读取位移主题目标分区的日志对象</strong>，从日志中取出真实的消息数据。读取日志这个操作，是使用我们在<a target="_blank" rel="noopener noreferrer" href="https://time.geekbang.org/column/article/225993">第3讲<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>中学过的Log.read方法完成的。当读取到完整的日志之后，doLoadGroupsAndOffsets方法会查看返回的消息集合，如果一条消息都没有返回，则取消“至少要求读取一条消息”的限制，即把刚才的布尔变量值设置为False。</p><p>第2步是根据上一步获取到的消息数据，创建保存在内存中的消息集合对象，也就是MemoryRecords对象。</p><p>由于doLoadGroupsAndOffsets方法要将读取的消息填充到缓存中，因此，这里必须做出MemoryRecords类型的消息集合。这就是第二路case分支要将FileRecords转换成MemoryRecords类型的原因。</p><p>至此，第1部分逻辑完成。这一部分的产物就是成功地从位移主题目标分区读取到消息，然后转换成MemoryRecords对象，等待后续处理。</p><h3 id="第2部分"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/05#第2部分"><span class="icon icon-link"></span></a>第2部分</h3><p>现在，代码进入到第2部分：<strong>处理消息集合</strong>。</p><p>值得注意的是，这部分代码依然在while循环下，我们看下它是如何实现的：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">// 遍历消息集合的每个消息批次(RecordBatch)</span></div><div class="token-line"><span class="token plain">    memRecords.batches.forEach { batch =&gt;</span></div><div class="token-line"><span class="token plain">      val isTxnOffsetCommit = batch.isTransactional</span></div><div class="token-line"><span class="token plain">      // 如果是控制类消息批次</span></div><div class="token-line"><span class="token plain">      // 控制类消息批次属于Kafka事务范畴，这里不展开讲</span></div><div class="token-line"><span class="token plain">      if (batch.isControlBatch) {</span></div><div class="token-line"><span class="token plain">        ......</span></div><div class="token-line"><span class="token plain">      } else {</span></div><div class="token-line"><span class="token plain">        // 保存消息批次第一条消息的位移值</span></div><div class="token-line"><span class="token plain">        var batchBaseOffset: Option[Long] = None</span></div><div class="token-line"><span class="token plain">        // 遍历消息批次下的所有消息</span></div><div class="token-line"><span class="token plain">        for (record &lt;- batch.asScala) {</span></div><div class="token-line"><span class="token plain">          // 确保消息必须有Key，否则抛出异常</span></div><div class="token-line"><span class="token plain">          require(record.hasKey, &quot;Group metadata/offset entry key should not be null&quot;)</span></div><div class="token-line"><span class="token plain">          // 记录消息批次第一条消息的位移值</span></div><div class="token-line"><span class="token plain">          if (batchBaseOffset.isEmpty)</span></div><div class="token-line"><span class="token plain">            batchBaseOffset = Some(record.offset)</span></div><div class="token-line"><span class="token plain">          // 读取消息Key</span></div><div class="token-line"><span class="token plain">          GroupMetadataManager.readMessageKey(record.key) match {</span></div><div class="token-line"><span class="token plain">            // 如果是OffsetKey，说明是提交位移消息</span></div><div class="token-line"><span class="token plain">            case offsetKey: OffsetKey =&gt;</span></div><div class="token-line"><span class="token plain">              ......</span></div><div class="token-line"><span class="token plain">              val groupTopicPartition = offsetKey.key</span></div><div class="token-line"><span class="token plain">              // 如果该消息没有Value</span></div><div class="token-line"><span class="token plain">              if (!record.hasValue) {</span></div><div class="token-line"><span class="token plain">                if (isTxnOffsetCommit)                </span></div><div class="token-line"><span class="token plain">                  pendingOffsets(batch.producerId)</span></div><div class="token-line"><span class="token plain">                    .remove(groupTopicPartition)</span></div><div class="token-line"><span class="token plain">                else</span></div><div class="token-line"><span class="token plain">                  // 将目标分区从已完成位移值加载的分区列表中移除</span></div><div class="token-line"><span class="token plain">                  loadedOffsets.remove(groupTopicPartition)</span></div><div class="token-line"><span class="token plain">              } else {</span></div><div class="token-line"><span class="token plain">                val offsetAndMetadata = GroupMetadataManager.readOffsetMessageValue(record.value)</span></div><div class="token-line"><span class="token plain">                if (isTxnOffsetCommit)</span></div><div class="token-line"><span class="token plain">                 pendingOffsets(batch.producerId).put(groupTopicPartition, CommitRecordMetadataAndOffset(batchBaseOffset, offsetAndMetadata))</span></div><div class="token-line"><span class="token plain">                else</span></div><div class="token-line"><span class="token plain">                  // 将目标分区加入到已完成位移值加载的分区列表</span></div><div class="token-line"><span class="token plain">                  loadedOffsets.put(groupTopicPartition, CommitRecordMetadataAndOffset(batchBaseOffset, offsetAndMetadata))</span></div><div class="token-line"><span class="token plain">              }</span></div><div class="token-line"><span class="token plain">            // 如果是GroupMetadataKey，说明是注册消息</span></div><div class="token-line"><span class="token plain">            case groupMetadataKey: GroupMetadataKey =&gt;</span></div><div class="token-line"><span class="token plain">              val groupId = groupMetadataKey.key</span></div><div class="token-line"><span class="token plain">              val groupMetadata = GroupMetadataManager.readGroupMessageValue(groupId, record.value, time)</span></div><div class="token-line"><span class="token plain">              // 如果消息Value不为空</span></div><div class="token-line"><span class="token plain">              if (groupMetadata != null) {</span></div><div class="token-line"><span class="token plain">                // 把该消费者组从待移除消费者组列表中移除</span></div><div class="token-line"><span class="token plain">                removedGroups.remove(groupId)</span></div><div class="token-line"><span class="token plain">                // 将消费者组加入到已完成加载的消费组列表</span></div><div class="token-line"><span class="token plain">                loadedGroups.put(groupId, groupMetadata)</span></div><div class="token-line"><span class="token plain">              // 如果消息Value为空，说明是Tombstone消息</span></div><div class="token-line"><span class="token plain">              } else {</span></div><div class="token-line"><span class="token plain">                // 把该消费者组从已完成加载的组列表中移除</span></div><div class="token-line"><span class="token plain">                loadedGroups.remove(groupId)</span></div><div class="token-line"><span class="token plain">                // 将消费者组加入到待移除消费组列表</span></div><div class="token-line"><span class="token plain">                removedGroups.add(groupId)</span></div><div class="token-line"><span class="token plain">              }</span></div><div class="token-line"><span class="token plain">            // 如果是未知类型的Key，抛出异常</span></div><div class="token-line"><span class="token plain">            case unknownKey =&gt;</span></div><div class="token-line"><span class="token plain">              throw new IllegalStateException(s&quot;Unexpected message key $unknownKey while loading offsets and group metadata&quot;)</span></div><div class="token-line"><span class="token plain">          }</span></div><div class="token-line"><span class="token plain">        }</span></div><div class="token-line"><span class="token plain">      }</span></div><div class="token-line"><span class="token plain">      // 更新读取位置到消息批次最后一条消息的位移值+1，等待下次while循环</span></div><div class="token-line"><span class="token plain">      currOffset = batch.nextOffset</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>这一部分的主要目的，是处理上一步获取到的消息集合，然后把相应数据添加到刚刚说到的4个列表中，具体逻辑是代码遍历消息集合的每个消息批次（Record Batch）。我来解释一下这个流程。</p><p><strong>首先</strong>，判断该批次是否是控制类消息批次，如果是，就执行Kafka事务专属的一些逻辑。由于我们不讨论Kafka事务，因此，这里我就不详细展开了。如果不是，就进入到下一步。</p><p><strong>其次</strong>，遍历该消息批次下的所有消息，并依次执行下面的步骤。</p><p>第1步，记录消息批次中第一条消息的位移值。</p><p>第2步，读取消息Key，并判断Key的类型，判断的依据如下：</p><ul><li>如果是提交位移消息，就判断消息有无Value。如果没有，那么，方法将目标分区从已完成位移值加载的分区列表中移除；如果有，则将目标分区加入到已完成位移值加载的分区列表中。</li><li>如果是注册消息，依然是判断消息有无Value。如果存在Value，就把该消费者组从待移除消费者组列表中移除，并加入到已完成加载的消费组列表；如果不存在Value，就说明，这是一条Tombstone消息，那么，代码把该消费者组从已完成加载的组列表中移除，并加入到待移除消费组列表。</li><li>如果是未知类型的Key，就直接抛出异常。</li></ul><p>最后，更新读取位置，等待下次while循环，这个位置就是整个消息批次中最后一条消息的位移值+1。</p><p>至此，这部分代码宣告结束，它的主要产物就是被填充了的4个列表。那么，第3部分，就要开始处理这4个列表了。</p><h3 id="第3部分"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/05#第3部分"><span class="icon icon-link"></span></a>第3部分</h3><p>最后一部分的完整代码如下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">// 处理loadedOffsets</span></div><div class="token-line"><span class="token plain">    val (groupOffsets, emptyGroupOffsets) = loadedOffsets</span></div><div class="token-line"><span class="token plain">      .groupBy(_._1.group)</span></div><div class="token-line"><span class="token plain">      .map { case (k, v) =&gt;</span></div><div class="token-line"><span class="token plain">        // 提取出&lt;组名，主题名，分区号&gt;与位移值对</span></div><div class="token-line"><span class="token plain">        k -&gt; v.map { case (groupTopicPartition, offset) =&gt; (groupTopicPartition.topicPartition, offset) }</span></div><div class="token-line"><span class="token plain">      }.partition { case (group, _) =&gt; loadedGroups.contains(group) }</span></div><div class="token-line"><span class="token plain">    ......</span></div><div class="token-line"><span class="token plain">    // 处理loadedGroups</span></div><div class="token-line"><span class="token plain">    loadedGroups.values.foreach { group =&gt;</span></div><div class="token-line"><span class="token plain">      // 提取消费者组的已提交位移</span></div><div class="token-line"><span class="token plain">      val offsets = groupOffsets.getOrElse(group.groupId, Map.empty[TopicPartition, CommitRecordMetadataAndOffset])</span></div><div class="token-line"><span class="token plain">      val pendingOffsets = pendingGroupOffsets.getOrElse(group.groupId, Map.empty[Long, mutable.Map[TopicPartition, CommitRecordMetadataAndOffset]])</span></div><div class="token-line"><span class="token plain">      debug(s&quot;Loaded group metadata $group with offsets $offsets and pending offsets $pendingOffsets&quot;)</span></div><div class="token-line"><span class="token plain">      // 为已完成加载的组执行加载组操作</span></div><div class="token-line"><span class="token plain">      loadGroup(group, offsets, pendingOffsets)</span></div><div class="token-line"><span class="token plain">      // 为已完成加载的组执行加载组操作之后的逻辑</span></div><div class="token-line"><span class="token plain">      onGroupLoaded(group)</span></div><div class="token-line"><span class="token plain">    }</span></div><div class="token-line"><span class="token plain">    (emptyGroupOffsets.keySet ++ pendingEmptyGroupOffsets.keySet).foreach { groupId =&gt;</span></div><div class="token-line"><span class="token plain">      val group = new GroupMetadata(groupId, Empty, time)</span></div><div class="token-line"><span class="token plain">      val offsets = emptyGroupOffsets.getOrElse(groupId, Map.empty[TopicPartition, CommitRecordMetadataAndOffset])</span></div><div class="token-line"><span class="token plain">      val pendingOffsets = pendingEmptyGroupOffsets.getOrElse(groupId, Map.empty[Long, mutable.Map[TopicPartition, CommitRecordMetadataAndOffset]])</span></div><div class="token-line"><span class="token plain">      debug(s&quot;Loaded group metadata $group with offsets $offsets and pending offsets $pendingOffsets&quot;)</span></div><div class="token-line"><span class="token plain">      // 为空的消费者组执行加载组操作</span></div><div class="token-line"><span class="token plain">      loadGroup(group, offsets, pendingOffsets)</span></div><div class="token-line"><span class="token plain">      // 为空的消费者执行加载组操作之后的逻辑</span></div><div class="token-line"><span class="token plain">      onGroupLoaded(group)</span></div><div class="token-line"><span class="token plain">    }</span></div><div class="token-line"><span class="token plain">    // 处理removedGroups</span></div><div class="token-line"><span class="token plain">    removedGroups.foreach { groupId =&gt;</span></div><div class="token-line"><span class="token plain">      if (groupMetadataCache.contains(groupId) &amp;&amp; !emptyGroupOffsets.contains(groupId))</span></div><div class="token-line"><span class="token plain">        throw new IllegalStateException(s&quot;Unexpected unload of active group $groupId while &quot; +</span></div><div class="token-line"><span class="token plain">          s&quot;loading partition $topicPartition&quot;)</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p><strong>首先</strong>，代码对loadedOffsets进行分组，将那些已经完成组加载的消费者组位移值分到一组，保存在字段groupOffsets中；将那些有位移值，但没有对应组信息的分成另外一组，也就是字段emptyGroupOffsets保存的数据。</p><p><strong>其次</strong>，代码为loadedGroups中的所有消费者组执行加载组操作，以及加载之后的操作onGroupLoaded。还记得吧，loadedGroups中保存的都是已完成组加载的消费者组。这里的onGroupLoaded是上层调用组件Coordinator传入的。它主要的作用是处理消费者组下所有成员的心跳超时设置，并指定下一次心跳的超时时间。</p><p><strong>再次</strong>，代码为emptyGroupOffsets的所有消费者组，创建空的消费者组元数据，然后执行和上一步相同的组加载逻辑以及加载后的逻辑。</p><p><strong>最后</strong>，代码检查removedGroups中的所有消费者组，确保它们不能出现在消费者组元数据缓存中，否则将抛出异常。</p><p>至此，doLoadGroupsAndOffsets方法的逻辑全部完成。经过调用该方法后，Coordinator成功地读取了位移主题目标分区下的数据，并把它们填充到了消费者组元数据缓存中。</p><h2 id="总结"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/05#总结"><span class="icon icon-link"></span></a>总结</h2><p>今天，我们重点学习了GroupMetadataManager类中读写位移主题的方法代码。Coordinator会使用这些方法对位移主题进行操作，实现对消费者组的管理。写入操作比较简单，它和一般的消息写入并无太大区别，而读取操作相对复杂一些。更重要的是，和我们的直观理解可能相悖的是，Kafka在查询消费者组已提交位移时，是不会读取位移主题的，而是直接从内存中的消费者组元数据缓存中查询。这一点你一定要重点关注。</p><p>我们来简单回顾一下这节课的重点。</p><ul><li>读写方法：appendForGroup方法负责写入位移主题，doLoadGroupsAndOffsets负责读取位移主题，并加载组信息和位移值。</li><li>查询消费者组位移：查询位移时不读取位移主题，而是读取消费者组元数据缓存。</li></ul><p><img src="/blog-backend/static/httpsstatic001geekbangorgresourceimage193b19304a381e75783fd584dyye5cc0733b.084ef410.jpg" alt=""/></p><p>至此，GroupMetadataManager类的重要源码，我们就学完了。作为一个有着将近1000行代码，而且集这么多功能于一身的大文件，这个类的代码绝对值得你多读几遍。</p><p>除了我们集中介绍的这些功能之外，GroupMetadataManager类其实还是连接GroupMetadata和Coordinator的重要纽带，Coordinator利用GroupMetadataManager类实现操作GroupMetadata的目的。</p><p>我刚开始学习这部分源码的时候，居然不清楚GroupMetadata和GroupMetadataManager的区别是什么。现在，经过这3节课的内容，相信你已经知道，GroupMetadata建模的是元数据信息，而GroupMetadataManager类建模的是管理元数据的方法，也是管理内部位移主题的唯一组件。以后碰到任何有关位移主题的问题，你都可以直接到这个类中去寻找答案。</p><h2 id="课后讨论"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/05#课后讨论"><span class="icon icon-link"></span></a>课后讨论</h2><p>其实，除了读写位移主题之外，GroupMetadataManager还提供了清除位移主题数据的方法。代码中的cleanGroupMetadata就是做这个事儿的。请你结合源码，分析一下cleanGroupMetadata方法的流程。</p><p>欢迎在留言区写下你的思考和答案，跟我交流讨论，也欢迎你把今天的内容分享给你的朋友。</p></div><div class="__dumi-default-layout-footer-meta"><a target="_blank" rel="noopener noreferrer" href="https://github.com/GGwujun/blog/edit/master/ssrc/kafka核心源码解读/08.消费者组管理模块/05.md">在 GitHub 上编辑此页<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a><span data-updated-text="最后更新时间：">2023/9/27 11:15:40</span></div></div></div></div>
	<script>
  window.g_useSSR = true;
  window.g_initialProps = {};
	</script>

    <script>
      (function () {
        if (!location.port) {
          (function (i, s, o, g, r, a, m) {
            i["GoogleAnalyticsObject"] = r;
            (i[r] =
              i[r] ||
              function () {
                (i[r].q = i[r].q || []).push(arguments);
              }),
              (i[r].l = 1 * new Date());
            (a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m);
          })(
            window,
            document,
            "script",
            "//www.google-analytics.com/analytics.js",
            "ga"
          );
          ga("create", "UA-149864185-1", "auto");
          ga("send", "pageview");
        }
      })();
    </script>
    <script src="/blog-backend/umi.e14e5a14.js"></script>
  </body>
</html>
