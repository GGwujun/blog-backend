<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no"
    />
    <link rel="shortcut icon" type="image/x-icon" href="/logo.png" />
    <link rel="stylesheet" href="/blog-backend/umi.3ec1f225.css" />
    <script>
      window.routerBase = "/blog-backend";
    </script>
    <script>
      //! umi version: 3.5.41
    </script>
    <script>
      !(function () {
        var e =
            navigator.cookieEnabled && void 0 !== window.localStorage
              ? localStorage.getItem("dumi:prefers-color")
              : "auto",
          o = window.matchMedia("(prefers-color-scheme: dark)").matches,
          t = ["light", "dark", "auto"];
        document.documentElement.setAttribute(
          "data-prefers-color",
          e === t[2] ? (o ? t[1] : t[0]) : t.indexOf(e) > -1 ? e : t[0]
        );
      })();
    </script>
    <title>10 | KafkaApis：Kafka最重要的源码入口，没有之一 - 大师兄</title>
  </head>
  <body>
    <div id="root"><div class="__dumi-default-layout" data-route="/kafka核心源码解读/03.请求处理模块/05" data-show-sidemenu="true" data-show-slugs="true" data-site-mode="true" data-gapless="false"><div class="__dumi-default-navbar" data-mode="site"><button class="__dumi-default-navbar-toggle"></button><a class="__dumi-default-navbar-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-backend/">大师兄</a><nav><div class="__dumi-default-search"><input type="search" class="__dumi-default-search-input" value=""/><ul></ul></div><span>后端开发<ul><li><a href="/blog-backend/go语言核心36讲">go语言核心36讲</a></li><li><a href="/blog-backend/go并发编程实战">go并发编程实战</a></li><li><a href="/blog-backend/go语言项目开发实战">go语言项目开发实战</a></li><li><a href="/blog-backend/kafka核心技术与实战">kafka核心技术与实战</a></li><li><a aria-current="page" class="active" href="/blog-backend/kafka核心源码解读">kafka核心源码解读</a></li><li><a href="/blog-backend/零基础学python">零基础学python</a></li><li><a href="/blog-backend/python核心技术与实战">python核心技术与实战</a></li><li><a href="/blog-backend/redis核心技术与实战">redis核心技术与实战</a></li><li><a href="/blog-backend/redis源码剖析与实战">redis源码剖析与实战</a></li><li><a href="/blog-backend/陈天rust编程第一课">陈天rust编程第一课</a></li><li><a href="/blog-backend/tonybaigo语言第一课">tonybaigo语言第一课</a></li><li><a href="/blog-backend/后端存储实战课">后端存储实战课</a></li><li><a href="/blog-backend/后端技术面试38讲">后端技术面试38讲</a></li><li><a href="/blog-backend/深入c语言和程序运行原理">深入c语言和程序运行原理</a></li><li><a href="/blog-backend/现代c编程实战">现代c编程实战</a></li><li><a href="/blog-backend/罗剑锋的c实战笔记">罗剑锋的c实战笔记</a></li><li><a href="/blog-backend/零基础入门spark">零基础入门spark</a></li></ul></span><span>架构师<ul><li><a href="/blog-backend/mysql实战45讲">mysql实战45讲</a></li><li><a href="/blog-backend/数据中台实战课">数据中台实战课</a></li></ul></span><div class="__dumi-default-navbar-tool"><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "></div></div></div></nav></div><div class="__dumi-default-menu" data-mode="site"><div class="__dumi-default-menu-inner"><div class="__dumi-default-menu-header"><a class="__dumi-default-menu-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-backend/"></a><h1>大师兄</h1><p></p></div><div class="__dumi-default-menu-mobile-area"><ul class="__dumi-default-menu-nav-list"><li>后端开发<ul><li><a href="/blog-backend/go语言核心36讲">go语言核心36讲</a></li><li><a href="/blog-backend/go并发编程实战">go并发编程实战</a></li><li><a href="/blog-backend/go语言项目开发实战">go语言项目开发实战</a></li><li><a href="/blog-backend/kafka核心技术与实战">kafka核心技术与实战</a></li><li><a aria-current="page" class="active" href="/blog-backend/kafka核心源码解读">kafka核心源码解读</a></li><li><a href="/blog-backend/零基础学python">零基础学python</a></li><li><a href="/blog-backend/python核心技术与实战">python核心技术与实战</a></li><li><a href="/blog-backend/redis核心技术与实战">redis核心技术与实战</a></li><li><a href="/blog-backend/redis源码剖析与实战">redis源码剖析与实战</a></li><li><a href="/blog-backend/陈天rust编程第一课">陈天rust编程第一课</a></li><li><a href="/blog-backend/tonybaigo语言第一课">tonybaigo语言第一课</a></li><li><a href="/blog-backend/后端存储实战课">后端存储实战课</a></li><li><a href="/blog-backend/后端技术面试38讲">后端技术面试38讲</a></li><li><a href="/blog-backend/深入c语言和程序运行原理">深入c语言和程序运行原理</a></li><li><a href="/blog-backend/现代c编程实战">现代c编程实战</a></li><li><a href="/blog-backend/罗剑锋的c实战笔记">罗剑锋的c实战笔记</a></li><li><a href="/blog-backend/零基础入门spark">零基础入门spark</a></li></ul></li><li>架构师<ul><li><a href="/blog-backend/mysql实战45讲">mysql实战45讲</a></li><li><a href="/blog-backend/数据中台实战课">数据中台实战课</a></li></ul></li></ul><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "><button title="Dark theme" class="__dumi-default-dark-moon "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3854" width="22" height="22"><path d="M991.816611 674.909091a69.166545 69.166545 0 0 0-51.665455-23.272727 70.795636 70.795636 0 0 0-27.438545 5.585454A415.674182 415.674182 0 0 1 754.993338 698.181818c-209.594182 0-393.472-184.785455-393.472-395.636363 0-52.363636 38.539636-119.621818 69.515637-173.614546 4.887273-8.610909 9.634909-16.756364 14.103272-24.901818A69.818182 69.818182 0 0 0 384.631156 0a70.842182 70.842182 0 0 0-27.438545 5.585455C161.678429 90.298182 14.362065 307.898182 14.362065 512c0 282.298182 238.824727 512 532.38691 512a522.286545 522.286545 0 0 0 453.957818-268.334545A69.818182 69.818182 0 0 0 991.816611 674.909091zM546.679156 954.181818c-248.785455 0-462.941091-192-462.941091-442.181818 0-186.647273 140.637091-372.829091 300.939637-442.181818-36.817455 65.629091-92.578909 151.970909-92.578909 232.727273 0 250.181818 214.109091 465.454545 462.917818 465.454545a488.331636 488.331636 0 0 0 185.181091-46.545455 453.003636 453.003636 0 0 1-393.565091 232.727273z m103.656728-669.323636l-14.266182 83.781818a34.909091 34.909091 0 0 0 50.362182 36.770909l74.775272-39.563636 74.752 39.563636a36.142545 36.142545 0 0 0 16.174546 3.956364 34.909091 34.909091 0 0 0 34.210909-40.727273l-14.289455-83.781818 60.509091-59.345455a35.025455 35.025455 0 0 0-19.223272-59.578182l-83.61891-12.101818-37.376-76.101818a34.56 34.56 0 0 0-62.254545 0l-37.376 76.101818-83.618909 12.101818a34.909091 34.909091 0 0 0-19.246546 59.578182z m70.423272-64.698182a34.280727 34.280727 0 0 0 26.135273-19.083636l14.312727-29.090909 14.336 29.090909a34.257455 34.257455 0 0 0 26.135273 19.083636l32.046546 4.887273-23.272728 22.574545a35.234909 35.234909 0 0 0-10.007272 30.952727l5.46909 32.116364-28.625454-15.127273a34.490182 34.490182 0 0 0-32.302546 0l-28.695272 15.127273 5.469091-32.116364a35.141818 35.141818 0 0 0-9.984-30.952727l-23.272728-22.574545z" p-id="3855"></path></svg></button><button title="Light theme" class="__dumi-default-dark-sun "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4026" width="22" height="22"><path d="M915.2 476.16h-43.968c-24.704 0-44.736 16-44.736 35.84s20.032 35.904 44.736 35.904H915.2c24.768 0 44.8-16.064 44.8-35.904s-20.032-35.84-44.8-35.84zM512 265.6c-136.704 0-246.464 109.824-246.464 246.4 0 136.704 109.76 246.464 246.464 246.464S758.4 648.704 758.4 512c0-136.576-109.696-246.4-246.4-246.4z m0 425.6c-99.008 0-179.2-80.128-179.2-179.2 0-98.944 80.192-179.2 179.2-179.2S691.2 413.056 691.2 512c0 99.072-80.192 179.2-179.2 179.2zM197.44 512c0-19.84-19.136-35.84-43.904-35.84H108.8c-24.768 0-44.8 16-44.8 35.84s20.032 35.904 44.8 35.904h44.736c24.768 0 43.904-16.064 43.904-35.904zM512 198.464c19.776 0 35.84-20.032 35.84-44.8v-44.8C547.84 84.032 531.84 64 512 64s-35.904 20.032-35.904 44.8v44.8c0 24.768 16.128 44.864 35.904 44.864z m0 627.136c-19.776 0-35.904 20.032-35.904 44.8v44.736C476.096 940.032 492.16 960 512 960s35.84-20.032 35.84-44.8v-44.736c0-24.768-16.064-44.864-35.84-44.864z m329.92-592.832c17.472-17.536 20.288-43.072 6.4-57.024-14.016-14.016-39.488-11.2-57.024 6.336-4.736 4.864-26.496 26.496-31.36 31.36-17.472 17.472-20.288 43.008-6.336 57.024 13.952 14.016 39.488 11.2 57.024-6.336 4.8-4.864 26.496-26.56 31.296-31.36zM213.376 759.936c-4.864 4.8-26.56 26.624-31.36 31.36-17.472 17.472-20.288 42.944-6.4 56.96 14.016 13.952 39.552 11.2 57.024-6.336 4.8-4.736 26.56-26.496 31.36-31.36 17.472-17.472 20.288-43.008 6.336-56.96-14.016-13.952-39.552-11.072-56.96 6.336z m19.328-577.92c-17.536-17.536-43.008-20.352-57.024-6.336-14.08 14.016-11.136 39.488 6.336 57.024 4.864 4.864 26.496 26.56 31.36 31.424 17.536 17.408 43.008 20.288 56.96 6.336 14.016-14.016 11.264-39.488-6.336-57.024-4.736-4.864-26.496-26.56-31.296-31.424z m527.168 628.608c4.864 4.864 26.624 26.624 31.36 31.424 17.536 17.408 43.072 20.224 57.088 6.336 13.952-14.016 11.072-39.552-6.4-57.024-4.864-4.8-26.56-26.496-31.36-31.36-17.472-17.408-43.072-20.288-57.024-6.336-13.952 14.016-11.008 39.488 6.336 56.96z" p-id="4027"></path></svg></button><button title="Default to system" class="__dumi-default-dark-auto "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="11002" width="22" height="22"><path d="M127.658667 492.885333c0-51.882667 10.24-101.717333 30.378666-149.162666s47.786667-88.064 81.92-122.538667 75.093333-61.781333 122.538667-81.92 96.938667-30.378667 149.162667-30.378667 101.717333 10.24 149.162666 30.378667 88.405333 47.786667 122.88 81.92 61.781333 75.093333 81.92 122.538667 30.378667 96.938667 30.378667 149.162666-10.24 101.717333-30.378667 149.162667-47.786667 88.405333-81.92 122.88-75.093333 61.781333-122.88 81.92-97.28 30.378667-149.162666 30.378667-101.717333-10.24-149.162667-30.378667-88.064-47.786667-122.538667-81.92-61.781333-75.093333-81.92-122.88-30.378667-96.938667-30.378666-149.162667z m329.045333 0c0 130.048 13.994667 244.394667 41.984 343.381334h12.970667c46.762667 0 91.136-9.216 133.461333-27.306667s78.848-42.666667 109.568-73.386667 54.954667-67.242667 73.386667-109.568 27.306667-86.698667 27.306666-133.461333c0-46.421333-9.216-90.794667-27.306666-133.12s-42.666667-78.848-73.386667-109.568-67.242667-54.954667-109.568-73.386667-86.698667-27.306667-133.461333-27.306666h-11.605334c-28.672 123.562667-43.349333 237.909333-43.349333 343.722666z" p-id="11003"></path></svg></button></div></div></div><ul class="__dumi-default-menu-list"><li><a href="/blog-backend/kafka核心源码解读">kafka核心源码解读</a></li><li><a href="/blog-backend/kafka核心源码解读/01.课前必学">01.课前必学</a><ul><li><a href="/blog-backend/kafka核心源码解读/01.课前必学/01"><span>开篇词 |  阅读源码，逐渐成了职业进阶道路上的“必选项”</span></a></li><li><a href="/blog-backend/kafka核心源码解读/01.课前必学/02"><span>导读 | 构建Kafka工程和源码阅读环境、Scala语言热身</span></a></li><li><a href="/blog-backend/kafka核心源码解读/01.课前必学/03"><span>重磅加餐 | 带你快速入门Scala语言</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/02.日志模块">02.日志模块</a><ul><li><a href="/blog-backend/kafka核心源码解读/02.日志模块/01"><span>01 | 日志段：保存消息文件的对象是怎么实现的？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/02.日志模块/02"><span>02 | 日志（上）：日志究竟是如何加载日志段的？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/02.日志模块/03"><span>03 | 日志（下）：彻底搞懂Log对象的常见操作</span></a></li><li><a href="/blog-backend/kafka核心源码解读/02.日志模块/04"><span>04 | 索引（上）：改进的二分查找算法在Kafka索引的应用</span></a></li><li><a href="/blog-backend/kafka核心源码解读/02.日志模块/05"><span>05 | 索引（下）：位移索引和时间戳索引的区别是什么？</span></a></li></ul></li><li><a aria-current="page" class="active" href="/blog-backend/kafka核心源码解读/03.请求处理模块">03.请求处理模块</a><ul><li><a href="/blog-backend/kafka核心源码解读/03.请求处理模块/01"><span>06 | 请求通道：如何实现Kafka请求队列？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/03.请求处理模块/02"><span>07 | SocketServer（上）：Kafka到底是怎么应用NIO实现网络通信的？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/03.请求处理模块/03"><span>08 | SocketServer（中）：请求还要区分优先级？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/03.请求处理模块/04"><span>09 | SocketServer（下）：请求处理全流程源码分析</span></a></li><li><a aria-current="page" class="active" href="/blog-backend/kafka核心源码解读/03.请求处理模块/05"><span>10 | KafkaApis：Kafka最重要的源码入口，没有之一</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/04.controller模块">04.Controller模块</a><ul><li><a href="/blog-backend/kafka核心源码解读/04.controller模块/01"><span>11 | Controller元数据：Controller都保存有哪些东西？有几种状态？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/04.controller模块/02"><span>12 | ControllerChannelManager：Controller如何管理请求发送？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/04.controller模块/03"><span>13 | ControllerEventManager：变身单线程后的Controller如何处理事件？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/04.controller模块/04"><span>14 | Controller选举是怎么实现的？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/04.controller模块/05"><span>15 | 如何理解Controller在Kafka集群中的作用？</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/05.状态机模块">05.状态机模块</a><ul><li><a href="/blog-backend/kafka核心源码解读/05.状态机模块/01"><span>16 | TopicDeletionManager： Topic是怎么被删除的？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/05.状态机模块/02"><span>17 | ReplicaStateMachine：揭秘副本状态机实现原理</span></a></li><li><a href="/blog-backend/kafka核心源码解读/05.状态机模块/03"><span>18 | PartitionStateMachine：分区状态转换如何实现？</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/06.延迟操作模块">06.延迟操作模块</a><ul><li><a href="/blog-backend/kafka核心源码解读/06.延迟操作模块/01"><span>19 | TimingWheel：探究Kafka定时器背后的高效时间轮算法</span></a></li><li><a href="/blog-backend/kafka核心源码解读/06.延迟操作模块/02"><span>20 | DelayedOperation：Broker是怎么延时处理请求的？</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/07.副本管理模块">07.副本管理模块</a><ul><li><a href="/blog-backend/kafka核心源码解读/07.副本管理模块/01"><span>21 | AbstractFetcherThread：拉取消息分几步？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/07.副本管理模块/02"><span>22 | ReplicaFetcherThread：Follower如何拉取Leader消息？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/07.副本管理模块/03"><span>23 | ReplicaManager（上）：必须要掌握的副本管理类定义和核心字段</span></a></li><li><a href="/blog-backend/kafka核心源码解读/07.副本管理模块/04"><span>24 | ReplicaManager（中）：副本管理器是如何读写副本的？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/07.副本管理模块/05"><span>25 | ReplicaManager（下）：副本管理器是如何管理副本的？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/07.副本管理模块/06"><span>26 | MetadataCache：Broker是怎么异步更新元数据缓存的？</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块">08.消费者组管理模块</a><ul><li><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/01"><span>27 | 消费者组元数据（上）：消费者组都有哪些元数据？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/02"><span>28 | 消费者组元数据（下）：Kafka如何管理这些元数据？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/03"><span>29 | GroupMetadataManager：组元数据管理器是个什么东西？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/04"><span>30 | GroupMetadataManager：位移主题保存的只是位移吗？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/05"><span>31 | GroupMetadataManager：查询位移时，不用读取位移主题？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/06"><span>32 | GroupCoordinator：在Rebalance中，Coordinator如何处理成员入组？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/07"><span>33 | GroupCoordinator：在Rebalance中，如何进行组同步？</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/09.特别放送">09.特别放送</a><ul><li><a href="/blog-backend/kafka核心源码解读/09.特别放送/01"><span>特别放送（一）| 经典的Kafka学习资料有哪些？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/09.特别放送/02"><span>特别放送（二）| 一篇文章带你了解参与开源社区的全部流程</span></a></li><li><a href="/blog-backend/kafka核心源码解读/09.特别放送/03"><span>特别放送（三）| 我是怎么度过日常一天的？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/09.特别放送/04"><span>特别放送（四）| 20道经典的Kafka面试题详解</span></a></li><li><a href="/blog-backend/kafka核心源码解读/09.特别放送/05"><span>特别放送（五） | Kafka 社区的重磅功能：移除 ZooKeeper 依赖</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/10.测试题">10.测试题</a><ul><li><a href="/blog-backend/kafka核心源码解读/10.测试题/01"><span>期中测试 | 这些源码知识，你都掌握了吗？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/10.测试题/02"><span>期末测试 | 一套习题，测试你的掌握程度</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/11.结束语">11.结束语</a><ul><li><a href="/blog-backend/kafka核心源码解读/11.结束语/01"><span>结束语 | 源码学习，我们才刚上路呢</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/summary">kafka核心源码解读</a></li></ul></div></div><ul role="slug-list" class="__dumi-default-layout-toc"><li title="KafkaApis类定义" data-depth="2"><a href="/blog-backend/kafka核心源码解读/03.请求处理模块/05#kafkaapis类定义"><span>KafkaApis类定义</span></a></li><li title="KafkaApis方法入口" data-depth="2"><a href="/blog-backend/kafka核心源码解读/03.请求处理模块/05#kafkaapis方法入口"><span>KafkaApis方法入口</span></a></li><li title="其他重要方法" data-depth="2"><a href="/blog-backend/kafka核心源码解读/03.请求处理模块/05#其他重要方法"><span>其他重要方法</span></a></li><li title="KafkaApis请求处理实例解析" data-depth="2"><a href="/blog-backend/kafka核心源码解读/03.请求处理模块/05#kafkaapis请求处理实例解析"><span>KafkaApis请求处理实例解析</span></a></li><li title="总结" data-depth="2"><a href="/blog-backend/kafka核心源码解读/03.请求处理模块/05#总结"><span>总结</span></a></li><li title="课后讨论" data-depth="2"><a href="/blog-backend/kafka核心源码解读/03.请求处理模块/05#课后讨论"><span>课后讨论</span></a></li></ul><div class="__dumi-default-layout-content"><div class="markdown"><h1 id="10--kafkaapiskafka最重要的源码入口没有之一"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/03.请求处理模块/05#10--kafkaapiskafka最重要的源码入口没有之一"><span class="icon icon-link"></span></a>10 | KafkaApis：Kafka最重要的源码入口，没有之一</h1><p>你好，我是胡夕。今天，我们来收尾Kafka请求处理模块的源码学习。讲到这里，关于整个模块，我们还有最后一个知识点尚未掌握，那就是KafkaApis类。</p><p>在上节课中，我提到过，请求的实际处理逻辑是封装在KafkaApis类中的。你一定很想知道，这个类到底是做什么的吧。</p><p>实际上，我一直认为，KafkaApis是Kafka最重要的源码入口。因为，每次要查找Kafka某个功能的实现代码时，我们几乎总要从这个KafkaApis.scala文件开始找起，然后一层一层向下钻取，直到定位到实现功能的代码处为止。比如，如果你想知道创建Topic的流程，你只需要查看KafkaApis的handleCreateTopicsRequest方法；如果你想弄懂Consumer提交位移是怎么实现的，查询handleOffsetCommitRequest方法就行了。</p><p>除此之外，在这一遍遍的钻取过程中，我们还会慢慢地<strong>掌握Kafka实现各种功能的代码路径和源码分布，从而建立起对整个Kafka源码工程的完整认识</strong>。</p><p>如果这些还不足以吸引你阅读这部分源码，那么，我再给你分享一个真实的案例。</p><p>之前，在使用Kafka时，我发现，Producer程序一旦向一个不存在的主题发送消息，在创建主题之后，Producer端会抛出一个警告：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">Error while fetching metadata with correlation id 3 : {test-topic=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)</span></div></pre></div><p>我一直很好奇，这里的LEADER_NOT_AVAILABLE异常是在哪里抛出来的。直到有一天，我在浏览KafkaApis代码时，突然发现了createTopics方法的这两行代码：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">private def createTopic(topic: String,</span></div><div class="token-line"><span class="token plain">      numPartitions: Int, replicationFactor: Int,</span></div><div class="token-line"><span class="token plain">      properties: util.Properties = new util.Properties()): MetadataResponseTopic = {</span></div><div class="token-line"><span class="token plain">      try {</span></div><div class="token-line"><span class="token plain">        adminZkClient.createTopic(topic, numPartitions, replicationFactor, properties, RackAwareMode.Safe)</span></div><div class="token-line"><span class="token plain">        ......</span></div><div class="token-line"><span class="token plain">        // 显式封装一个LEADER_NOT_AVAILABLE Response</span></div><div class="token-line"><span class="token plain">        metadataResponseTopic(Errors.LEADER_NOT_AVAILABLE, topic, isInternal(topic), util.Collections.emptyList())</span></div><div class="token-line"><span class="token plain">      } catch {</span></div><div class="token-line"><span class="token plain">        ......</span></div><div class="token-line"><span class="token plain">      }</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>这时，我才恍然大悟，原来，Broker端创建完主题后，会显式地通知Clients端LEADER_NOT_AVAILABLE异常。Clients端接收到该异常后，会主动更新元数据，去获取新创建主题的信息。你看，如果不是亲自查看源代码，我们是无法解释这种现象的。</p><p>那么，既然KafkaApis这么重要，现在，我们就来看看这个大名鼎鼎的入口文件吧。我会先给你介绍下它的定义以及最重要的handle方法，然后再解释一下其他的重要方法。学完这节课以后，你就能掌握，从KafkaApis类开始去寻找单个功能具体代码位置的方法了。</p><p>事实上，相比于之前更多是向你分享知识的做法，<strong>这节课我分享的是学习知识的方法</strong>。</p><h2 id="kafkaapis类定义"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/03.请求处理模块/05#kafkaapis类定义"><span class="icon icon-link"></span></a>KafkaApis类定义</h2><p>好了， 我们首先来看下KafkaApis类的定义。KafkaApis类定义在源码文件KafkaApis.scala中。该文件位于core工程的server包下，是一个将近3000行的巨型文件。好在它实现的逻辑并不复杂，绝大部分代码都是用来处理所有Kafka请求类型的，因此，代码结构整体上显得非常规整。一会儿我们在学习handle方法时，你一定会所有体会。</p><p>KafkaApis类的定义代码如下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">class KafkaApis(</span></div><div class="token-line"><span class="token plain">    	val requestChannel: RequestChannel, // 请求通道</span></div><div class="token-line"><span class="token plain">    	val replicaManager: ReplicaManager, // 副本管理器</span></div><div class="token-line"><span class="token plain">    	val adminManager: AdminManager, 	// 主题、分区、配置等方面的管理器</span></div><div class="token-line"><span class="token plain">        val groupCoordinator: GroupCoordinator,	// 消费者组协调器组件</span></div><div class="token-line"><span class="token plain">    	val txnCoordinator: TransactionCoordinator,	// 事务管理器组件</span></div><div class="token-line"><span class="token plain">    	val controller: KafkaController,	// 控制器组件</span></div><div class="token-line"><span class="token plain">    	val zkClient: KafkaZkClient,		// ZooKeeper客户端程序，Kafka依赖于该类实现与ZooKeeper交互</span></div><div class="token-line"><span class="token plain">    	val brokerId: Int,					// broker.id参数值</span></div><div class="token-line"><span class="token plain">        val config: KafkaConfig,			// Kafka配置类</span></div><div class="token-line"><span class="token plain">        val metadataCache: MetadataCache,	// 元数据缓存类</span></div><div class="token-line"><span class="token plain">        val metrics: Metrics,			</span></div><div class="token-line"><span class="token plain">    	val authorizer: Option[Authorizer],</span></div><div class="token-line"><span class="token plain">    	val quotas: QuotaManagers,          // 配额管理器组件</span></div><div class="token-line"><span class="token plain">    	val fetchManager: FetchManager,</span></div><div class="token-line"><span class="token plain">    	brokerTopicStats: BrokerTopicStats,</span></div><div class="token-line"><span class="token plain">    	val clusterId: String,</span></div><div class="token-line"><span class="token plain">    	time: Time,</span></div><div class="token-line"><span class="token plain">    	val tokenManager: DelegationTokenManager) extends Logging {</span></div><div class="token-line"><span class="token plain">      type FetchResponseStats = Map[TopicPartition, RecordConversionStats]</span></div><div class="token-line"><span class="token plain">      this.logIdent = &quot;[KafkaApi-%d] &quot;.format(brokerId)</span></div><div class="token-line"><span class="token plain">      val adminZkClient = new AdminZkClient(zkClient)</span></div><div class="token-line"><span class="token plain">      private val alterAclsPurgatory = new DelayedFuturePurgatory(purgatoryName = &quot;AlterAcls&quot;, brokerId = config.brokerId)</span></div><div class="token-line"><span class="token plain">      ......</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>我为一些重要的字段添加了注释信息。为了方便你理解，我还画了一张思维导图，罗列出了比较重要的组件：</p><p><img src="/blog-backend/static/httpsstatic001geekbangorgresourceimage4fcc4fc050472d3c81fa27564297e07d67cc.68fe6d58.jpg" alt=""/></p><p>从这张图可以看出，KafkaApis下可谓是大牌云集。放眼整个源码工程，KafkaApis关联的“大佬级”组件都是最多的！在KafkaApis中，你几乎能找到Kafka所有重量级的组件，比如，负责副本管理的ReplicaManager、维护消费者组的GroupCoordinator以及操作Controller组件的KafkaController，等等。</p><p>在处理不同类型的RPC请求时，KafkaApis会用到不同的组件，因此，在创建KafkaApis实例时，我们必须把可能用到的组件一并传给它，这也是它汇聚众多大牌组件于一身的原因。</p><p>我说KafkaApis是入口类的另一个原因也在于此。你完全可以打开KafkaApis.scala文件，然后根据它的定义一个一个地去研习这些重量级组件的实现原理。等你对这些组件的代码了然于胸了，说不定下一个写源码课的人就是你了。</p><h2 id="kafkaapis方法入口"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/03.请求处理模块/05#kafkaapis方法入口"><span class="icon icon-link"></span></a>KafkaApis方法入口</h2><p>那，作为Kafka源码的入口类，它都定义了哪些方法呢？</p><p>如果你翻开KafkaApis类的代码，你会发现，它封装了很多以handle开头的方法。每一个这样的方法都对应于一类请求类型，而它们的总方法入口就是handle方法。实际上，你完全可以在handle方法间不断跳转，去到任意一类请求被处理的实际代码中。下面这段代码就是handle方法的完整实现，我们来看一下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">def handle(request: RequestChannel.Request): Unit = {</span></div><div class="token-line"><span class="token plain">      try {</span></div><div class="token-line"><span class="token plain">        trace(s&quot;Handling request:${request.requestDesc(true)} from connection ${request.context.connectionId};&quot; +</span></div><div class="token-line"><span class="token plain">     s&quot;securityProtocol:${request.context.securityProtocol},principal:${request.context.principal}&quot;)</span></div><div class="token-line"><span class="token plain">        // 根据请求头部信息中的apiKey字段判断属于哪类请求</span></div><div class="token-line"><span class="token plain">        // 然后调用响应的handle***方法</span></div><div class="token-line"><span class="token plain">        // 如果新增RPC协议类型，则：</span></div><div class="token-line"><span class="token plain">        // 1. 添加新的apiKey标识新请求类型</span></div><div class="token-line"><span class="token plain">        // 2. 添加新的case分支</span></div><div class="token-line"><span class="token plain">        // 3. 添加对应的handle***方法   </span></div><div class="token-line"><span class="token plain">        request.header.apiKey match {</span></div><div class="token-line"><span class="token plain">          case ApiKeys.PRODUCE =&gt; handleProduceRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.FETCH =&gt; handleFetchRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.LIST_OFFSETS =&gt; handleListOffsetRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.METADATA =&gt; handleTopicMetadataRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.LEADER_AND_ISR =&gt; handleLeaderAndIsrRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.STOP_REPLICA =&gt; handleStopReplicaRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.UPDATE_METADATA =&gt; handleUpdateMetadataRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.CONTROLLED_SHUTDOWN =&gt; handleControlledShutdownRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.OFFSET_COMMIT =&gt; handleOffsetCommitRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.OFFSET_FETCH =&gt; handleOffsetFetchRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.FIND_COORDINATOR =&gt; handleFindCoordinatorRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.JOIN_GROUP =&gt; handleJoinGroupRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.HEARTBEAT =&gt; handleHeartbeatRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.LEAVE_GROUP =&gt; handleLeaveGroupRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.SYNC_GROUP =&gt; handleSyncGroupRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.DESCRIBE_GROUPS =&gt; handleDescribeGroupRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.LIST_GROUPS =&gt; handleListGroupsRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.SASL_HANDSHAKE =&gt; handleSaslHandshakeRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.API_VERSIONS =&gt; handleApiVersionsRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.CREATE_TOPICS =&gt; handleCreateTopicsRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.DELETE_TOPICS =&gt; handleDeleteTopicsRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.DELETE_RECORDS =&gt; handleDeleteRecordsRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.INIT_PRODUCER_ID =&gt; handleInitProducerIdRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.OFFSET_FOR_LEADER_EPOCH =&gt; handleOffsetForLeaderEpochRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.ADD_PARTITIONS_TO_TXN =&gt; handleAddPartitionToTxnRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.ADD_OFFSETS_TO_TXN =&gt; handleAddOffsetsToTxnRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.END_TXN =&gt; handleEndTxnRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.WRITE_TXN_MARKERS =&gt; handleWriteTxnMarkersRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.TXN_OFFSET_COMMIT =&gt; handleTxnOffsetCommitRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.DESCRIBE_ACLS =&gt; handleDescribeAcls(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.CREATE_ACLS =&gt; handleCreateAcls(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.DELETE_ACLS =&gt; handleDeleteAcls(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.ALTER_CONFIGS =&gt; handleAlterConfigsRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.DESCRIBE_CONFIGS =&gt; handleDescribeConfigsRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.ALTER_REPLICA_LOG_DIRS =&gt; handleAlterReplicaLogDirsRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.DESCRIBE_LOG_DIRS =&gt; handleDescribeLogDirsRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.SASL_AUTHENTICATE =&gt; handleSaslAuthenticateRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.CREATE_PARTITIONS =&gt; handleCreatePartitionsRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.CREATE_DELEGATION_TOKEN =&gt; handleCreateTokenRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.RENEW_DELEGATION_TOKEN =&gt; handleRenewTokenRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.EXPIRE_DELEGATION_TOKEN =&gt; handleExpireTokenRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.DESCRIBE_DELEGATION_TOKEN =&gt; handleDescribeTokensRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.DELETE_GROUPS =&gt; handleDeleteGroupsRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.ELECT_LEADERS =&gt; handleElectReplicaLeader(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.INCREMENTAL_ALTER_CONFIGS =&gt; handleIncrementalAlterConfigsRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.ALTER_PARTITION_REASSIGNMENTS =&gt; handleAlterPartitionReassignmentsRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.LIST_PARTITION_REASSIGNMENTS =&gt; handleListPartitionReassignmentsRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.OFFSET_DELETE =&gt; handleOffsetDeleteRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.DESCRIBE_CLIENT_QUOTAS =&gt; handleDescribeClientQuotasRequest(request)</span></div><div class="token-line"><span class="token plain">          case ApiKeys.ALTER_CLIENT_QUOTAS =&gt; handleAlterClientQuotasRequest(request)</span></div><div class="token-line"><span class="token plain">        }</span></div><div class="token-line"><span class="token plain">      } catch {</span></div><div class="token-line"><span class="token plain">        // 如果是严重错误，则抛出异常</span></div><div class="token-line"><span class="token plain">        case e: FatalExitError =&gt; throw e</span></div><div class="token-line"><span class="token plain">        // 普通异常的话，记录下错误日志</span></div><div class="token-line"><span class="token plain">        case e: Throwable =&gt; handleError(request, e)</span></div><div class="token-line"><span class="token plain">      } finally {</span></div><div class="token-line"><span class="token plain">        // 记录一下请求本地完成时间，即Broker处理完该请求的时间</span></div><div class="token-line"><span class="token plain">        if (request.apiLocalCompleteTimeNanos &lt; 0)</span></div><div class="token-line"><span class="token plain">          request.apiLocalCompleteTimeNanos = time.nanoseconds</span></div><div class="token-line"><span class="token plain">      }</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>如果你跟着这门课一直学习的话，你应该会发现，我很少贴某个类或方法的完整代码，因为没必要，还会浪费你的时间。但是，这个handle方法有点特殊，所以我把完整的代码展现给你。</p><p>它利用Scala语言中的模式匹配语法，完整地列出了对所有请求类型的处理逻辑。通过该方法，你能串联出Kafka处理任何请求的源码路径。我强烈推荐你在课下以几个比较重要的请求类型为学习目标，从handle方法出发，去探寻一下代码是如何为这些请求服务的，以加深你对Broker端代码的整体熟练度。这对你后续深入学习源码或解决实际问题非常有帮助。</p><p>从上面的代码中，你应该很容易就能找到其中的规律：<strong>这个方法是处理具体请求用的</strong>。处理每类请求的方法名均以handle开头，即handle×××Request。比如，处理PRODUCE请求的方法叫handleProduceRequest，处理FETCH请求的方法叫handleFetchRequest等。</p><p>如果你点开ApiKeys，你会发现，<strong>它实际上是一个枚举类型，里面封装了目前Kafka定义所有的RPC协议</strong>。值得一提的是，Kafka社区维护了一个官方文档，专门记录这些RPC协议，包括不同版本所需的Request格式和Response格式。</p><p>从这个handle方法中，我们也能得到这样的结论：每当社区添加新的RPC协议时，Broker端大致需要做三件事情。</p><ol><li>更新ApiKeys枚举，加入新的RPC ApiKey；</li><li>在KafkaApis中添加对应的handle×××Request方法，实现对该RPC请求的处理逻辑；</li><li>更新KafkaApis的handle方法，添加针对RPC协议的case分支。</li></ol><h2 id="其他重要方法"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/03.请求处理模块/05#其他重要方法"><span class="icon icon-link"></span></a>其他重要方法</h2><p>抛开KafkaApis的定义和handle方法，还有几个常用的方法也很重要，比如，用于发送Response的一组方法，以及用于鉴权的方法。特别是前者，它是任何一类请求被处理之后都要做的必要步骤。毕竟，请求被处理完成还不够，Kafka还需要把处理结果发送给请求发送方。</p><p>首先就是<strong>sendResponse系列方法</strong>。</p><p>为什么说是系列方法呢？因为源码中带有sendResponse字眼的方法有7个之多。我分别来介绍一下。</p><ul><li><strong>sendResponse</strong>（RequestChannel.Response）：最底层的Response发送方法。本质上，它调用了SocketServer组件中RequestChannel的sendResponse方法，我在前面的课程中讲到过，RequestChannel的sendResponse方法会把待发送的Response对象添加到对应Processor线程的Response队列上，然后交由Processor线程完成网络间的数据传输。</li><li><strong>sendResponse</strong>（RequestChannel.Request，responseOpt: Option[AbstractResponse]，onComplete: Option[Send =&gt; Unit]）：该方法接收的实际上是Request，而非Response，因此，它会在内部构造出Response对象之后，再调用sendResponse方法。</li><li><strong>sendNoOpResponseExemptThrottle</strong>：发送NoOpResponse类型的Response而不受请求通道上限流（throttling）的限制。所谓的NoOpResponse，是指Processor线程取出该类型的Response后，不执行真正的I/O发送操作。</li><li><strong>sendErrorResponseExemptThrottle</strong>：发送携带错误信息的Response而不受限流限制。</li><li><strong>sendResponseExemptThrottle</strong>：发送普通Response而不受限流限制。</li><li><strong>sendErrorResponseMaybeThrottle</strong>：发送携带错误信息的Response但接受限流的约束。</li><li><strong>sendResponseMaybeThrottle</strong>：发送普通Response但接受限流的约束。</li></ul><p>这组方法最关键的还是第一个sendResponse方法。大部分类型的请求被处理完成后都会使用这个方法将Response发送出去。至于上面这组方法中的其他方法，它们会在内部调用第一个sendResponse方法。当然，在调用之前，这些方法通常都拥有一些定制化的逻辑。比如sendResponseMaybeThrottle方法就会在执行sendResponse逻辑前，先尝试对请求所属的请求通道进行限流操作。因此，<strong>我们要着重掌握第一个sendResponse方法是怎么将Response对象发送出去的</strong>。</p><p>就像我前面说的，<strong>KafkaApis实际上是把处理完成的Response放回到前端Processor线程的Response队列中，而真正将Response返还给Clients或其他Broker的，其实是Processor线程，而不是执行KafkaApis逻辑的KafkaRequestHandler线程</strong>。</p><p>另一个非常重要的方法是authorize方法，咱们看看它的代码：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">private[server] def authorize(requestContext: RequestContext,</span></div><div class="token-line"><span class="token plain">      operation: AclOperation,</span></div><div class="token-line"><span class="token plain">      resourceType: ResourceType,</span></div><div class="token-line"><span class="token plain">      resourceName: String,</span></div><div class="token-line"><span class="token plain">      logIfAllowed: Boolean = true,</span></div><div class="token-line"><span class="token plain">      logIfDenied: Boolean = true,</span></div><div class="token-line"><span class="token plain">      refCount: Int = 1): Boolean = {</span></div><div class="token-line"><span class="token plain">      authorizer.forall { authZ =&gt;</span></div><div class="token-line"><span class="token plain">        // 获取待鉴权的资源类型</span></div><div class="token-line"><span class="token plain">        // 常见的资源类型如TOPIC、GROUP、CLUSTER等</span></div><div class="token-line"><span class="token plain">        val resource = new ResourcePattern(resourceType, resourceName, PatternType.LITERAL)</span></div><div class="token-line"><span class="token plain">        val actions = Collections.singletonList(new Action(operation, resource, refCount, logIfAllowed, logIfDenied))</span></div><div class="token-line"><span class="token plain">        // 返回鉴权结果，是ALLOWED还是DENIED</span></div><div class="token-line"><span class="token plain">        authZ.authorize(requestContext, actions).asScala.head == AuthorizationResult.ALLOWED</span></div><div class="token-line"><span class="token plain">      }</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>这个方法是做<strong>授权检验</strong>的。目前，Kafka所有的RPC请求都要求发送者（无论是Clients，还是其他Broker）必须具备特定的权限。</p><p>接下来，我用创建主题的代码来举个例子，说明一下authorize方法的实际应用，以下是handleCreateTopicsRequest方法的片段：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">// 是否具有CLUSTER资源的CREATE权限</span></div><div class="token-line"><span class="token plain">    val hasClusterAuthorization = authorize(request, CREATE, CLUSTER, CLUSTER_NAME, logIfDenied = false)</span></div><div class="token-line"><span class="token plain">    val topics = createTopicsRequest.data.topics.asScala.map(_.name)</span></div><div class="token-line"><span class="token plain">    // 如果具有CLUSTER CREATE权限，则允许主题创建，否则，还要查看是否具有TOPIC资源的CREATE权限</span></div><div class="token-line"><span class="token plain">    val authorizedTopics = if (hasClusterAuthorization) topics.toSet else filterAuthorized(request, CREATE, TOPIC, topics.toSeq)</span></div><div class="token-line"><span class="token plain">    // 是否具有TOPIC资源的DESCRIBE_CONFIGS权限</span></div><div class="token-line"><span class="token plain">    val authorizedForDescribeConfigs = filterAuthorized(request, DESCRIBE_CONFIGS, TOPIC, topics.toSeq, logIfDenied = false)</span></div><div class="token-line"><span class="token plain">      .map(name =&gt; name -&gt; results.find(name)).toMap</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">    results.asScala.foreach(topic =&gt; {</span></div><div class="token-line"><span class="token plain">      if (results.findAll(topic.name).size &gt; 1) {</span></div><div class="token-line"><span class="token plain">        topic.setErrorCode(Errors.INVALID_REQUEST.code)</span></div><div class="token-line"><span class="token plain">        topic.setErrorMessage(&quot;Found multiple entries for this topic.&quot;)</span></div><div class="token-line"><span class="token plain">      } else if (!authorizedTopics.contains(topic.name)) { // 如果不具备CLUSTER资源的CREATE权限或TOPIC资源的CREATE权限，认证失败！</span></div><div class="token-line"><span class="token plain">        topic.setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)</span></div><div class="token-line"><span class="token plain">        topic.setErrorMessage(&quot;Authorization failed.&quot;)</span></div><div class="token-line"><span class="token plain">      }</span></div><div class="token-line"><span class="token plain">      if (!authorizedForDescribeConfigs.contains(topic.name)) { // 如果不具备TOPIC资源的DESCRIBE_CONFIGS权限，设置主题配置错误码</span></div><div class="token-line"><span class="token plain">        topic.setTopicConfigErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)</span></div><div class="token-line"><span class="token plain">      }</span></div><div class="token-line"><span class="token plain">    })</span></div><div class="token-line"><span class="token plain">    ......</span></div></pre></div><p>这段代码调用authorize方法，来判断Clients方法是否具有创建主题的权限，如果没有，则显式标记TOPIC_AUTHORIZATION_FAILED，告知Clients端。目前，Kafka所有的权限控制均发生在KafkaApis中，即<strong>所有请求在处理前，都需要调用authorize方法做权限校验，以保证请求能够被继续执行</strong>。</p><h2 id="kafkaapis请求处理实例解析"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/03.请求处理模块/05#kafkaapis请求处理实例解析"><span class="icon icon-link"></span></a>KafkaApis请求处理实例解析</h2><p>在了解了KafkaApis的代码结构之后，我拿一段真实的代码，来说明一下该类中某个协议处理方法大致的执行流程是什么样的，以便让你更清楚地了解请求处理逻辑。</p><p>值得注意的是，这里的请求处理逻辑和之前所说的请求处理全流程是有所区别的。今天，我们关注的是<strong>功能层面上请求被处理的逻辑代码</strong>，之前的请求处理全流程主要聚焦流程方面的代码，即一个请求从被发送到Broker端到Broker端返还Response的代码路径。应该这么说，<strong>所有类型请求的被处理流程都是相同的，但是，每类请求却有不同的功能实现逻辑</strong>，而这就是KafkaApis类中的各个handle×××Request方法要做的事情。</p><p>下面，我以handleListGroupsRequest方法为例来介绍一下。顾名思义，这是处理ListGroupsRequest请求的方法。这类请求的Response应该返回集群中的消费者组信息。我们来看下它的实现：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">def handleListGroupsRequest(request: RequestChannel.Request): Unit = {</span></div><div class="token-line"><span class="token plain">        val (error, groups) = groupCoordinator.handleListGroups() // 调用GroupCoordinator的handleListGroups方法拿到所有Group信息</span></div><div class="token-line"><span class="token plain">        // 如果Clients具备CLUSTER资源的DESCRIBE权限</span></div><div class="token-line"><span class="token plain">        if (authorize(request, DESCRIBE, CLUSTER, CLUSTER_NAME))</span></div><div class="token-line"><span class="token plain">          // 直接使用刚才拿到的Group数据封装进Response然后发送</span></div><div class="token-line"><span class="token plain">          sendResponseMaybeThrottle(request, requestThrottleMs =&gt;</span></div><div class="token-line"><span class="token plain">            new ListGroupsResponse(new ListGroupsResponseData()</span></div><div class="token-line"><span class="token plain">                .setErrorCode(error.code)</span></div><div class="token-line"><span class="token plain">                .setGroups(groups.map { group =&gt; new ListGroupsResponseData.ListedGroup()</span></div><div class="token-line"><span class="token plain">                  .setGroupId(group.groupId)</span></div><div class="token-line"><span class="token plain">                  .setProtocolType(group.protocolType)}.asJava</span></div><div class="token-line"><span class="token plain">                )</span></div><div class="token-line"><span class="token plain">                .setThrottleTimeMs(requestThrottleMs)</span></div><div class="token-line"><span class="token plain">            ))</span></div><div class="token-line"><span class="token plain">        else {</span></div><div class="token-line"><span class="token plain">          // 找出Clients对哪些Group有GROUP资源的DESCRIBE权限，返回这些Group信息</span></div><div class="token-line"><span class="token plain">          val filteredGroups = groups.filter(group =&gt; authorize(request, DESCRIBE, GROUP, group.groupId))</span></div><div class="token-line"><span class="token plain">          sendResponseMaybeThrottle(request, requestThrottleMs =&gt;</span></div><div class="token-line"><span class="token plain">            new ListGroupsResponse(new ListGroupsResponseData()</span></div><div class="token-line"><span class="token plain">              .setErrorCode(error.code)</span></div><div class="token-line"><span class="token plain">              .setGroups(filteredGroups.map { group =&gt; new ListGroupsResponseData.ListedGroup()</span></div><div class="token-line"><span class="token plain">                .setGroupId(group.groupId)</span></div><div class="token-line"><span class="token plain">                .setProtocolType(group.protocolType)}.asJava</span></div><div class="token-line"><span class="token plain">              )</span></div><div class="token-line"><span class="token plain">              .setThrottleTimeMs(requestThrottleMs)</span></div><div class="token-line"><span class="token plain">            ))</span></div><div class="token-line"><span class="token plain">        }</span></div><div class="token-line"><span class="token plain">      }</span></div></pre></div><p>我用一张流程图，来说明一下这个执行逻辑：</p><p><img src="/blog-backend/static/httpsstatic001geekbangorgresourceimage75f37529b94b80cead7158be5a277e7ff4f3.037d3d0b.jpg" alt=""/></p><p>大体来看，handleListGroupsRequest方法的实现逻辑非常简单。通过GroupCoordinator组件获取到所有的消费者组信息之后，代码对这些Group进行了权限校验，并最终根据校验结果，决定给Clients返回哪些可见的消费者组。</p><h2 id="总结"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/03.请求处理模块/05#总结"><span class="icon icon-link"></span></a>总结</h2><p>好了， 我们总结一下KafkaApis类的要点。如前所述，我们重点学习了KafkaApis类的定义及其重要方法handle。下面这些关键知识点，希望你能掌握。</p><ul><li>KafkaApis是Broker端所有功能的入口，同时关联了超多的Kafka组件。它绝对是你学习源码的第一入口。面对庞大的源码工程，如果你不知道从何下手，那就先从KafkaApis.scala这个文件开始吧。</li><li>handle方法封装了所有RPC请求的具体处理逻辑。每当社区新增RPC协议时，增加对应的handle×××Request方法和case分支都是首要的。</li><li>sendResponse系列方法负责发送Response给请求发送方。发送Response的逻辑是将Response对象放置在Processor线程的Response队列中，然后交由Processor线程实现网络发送。</li><li>authorize方法是请求处理前权限校验层的主要逻辑实现。你可以查看一下<a target="_blank" rel="noopener noreferrer" href="https://docs.confluent.io/current/kafka/authorization.html">官方文档<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>，了解一下当前都有哪些权限，然后对照着具体的方法，找出每类RPC协议都要求Clients端具备什么权限。</li></ul><p><img src="/blog-backend/static/httpsstatic001geekbangorgresourceimage9e4c9ebd3f25518e387a7a60200a8b62114c.e7b3977b.jpg" alt=""/></p><p>至此，关于Kafka请求处理模块的内容，我们就全部学完了。在这个模块中，我们先从RequestChannel入手，探讨了Kafka中请求队列的实现原理，之后，我花了两节课的时间，重点介绍了SocketServer组件，包括Acceptor线程、Processor线程等子组件的源码以及请求被处理的全流程。今天，我们重点研究了KafkaApis类这个顶层的请求功能处理逻辑入口，补齐了请求处理的最后一块“拼图”。我希望你能够把这个模块的课程多看几遍，认真思考一下这里面的关键实现要点，彻底搞明白Kafka网络通信的核心机制。</p><p>从下节课开始，我们将进入鼎鼎有名的控制器（Controller）组件的源码学习。我会花5节课的时间，带你深入学习Controller的方方面面，敬请期待。</p><h2 id="课后讨论"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/03.请求处理模块/05#课后讨论"><span class="icon icon-link"></span></a>课后讨论</h2><p>最后，请思考这样一个问题：如果一个Consumer要向Broker提交位移，它应该具备什么权限？你能说出KafkaApis中的哪段代码说明了所需的权限要求吗？</p><p>欢迎你在留言区写下你的思考和答案，跟我交流讨论，也欢迎你把今天的内容分享给你的朋友。</p></div><div class="__dumi-default-layout-footer-meta"><a target="_blank" rel="noopener noreferrer" href="https://github.com/GGwujun/blog/edit/master/ssrc/kafka核心源码解读/03.请求处理模块/05.md">在 GitHub 上编辑此页<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a><span data-updated-text="最后更新时间：">2023/9/27 11:15:40</span></div></div></div></div>
	<script>
  window.g_useSSR = true;
  window.g_initialProps = {};
	</script>

    <script>
      (function () {
        if (!location.port) {
          (function (i, s, o, g, r, a, m) {
            i["GoogleAnalyticsObject"] = r;
            (i[r] =
              i[r] ||
              function () {
                (i[r].q = i[r].q || []).push(arguments);
              }),
              (i[r].l = 1 * new Date());
            (a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m);
          })(
            window,
            document,
            "script",
            "//www.google-analytics.com/analytics.js",
            "ga"
          );
          ga("create", "UA-149864185-1", "auto");
          ga("send", "pageview");
        }
      })();
    </script>
    <script src="/blog-backend/umi.e14e5a14.js"></script>
  </body>
</html>
