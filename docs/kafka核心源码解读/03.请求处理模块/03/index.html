<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no"
    />
    <link rel="shortcut icon" type="image/x-icon" href="/logo.png" />
    <link rel="stylesheet" href="/blog-backend/umi.3ec1f225.css" />
    <script>
      window.routerBase = "/blog-backend";
    </script>
    <script>
      //! umi version: 3.5.41
    </script>
    <script>
      !(function () {
        var e =
            navigator.cookieEnabled && void 0 !== window.localStorage
              ? localStorage.getItem("dumi:prefers-color")
              : "auto",
          o = window.matchMedia("(prefers-color-scheme: dark)").matches,
          t = ["light", "dark", "auto"];
        document.documentElement.setAttribute(
          "data-prefers-color",
          e === t[2] ? (o ? t[1] : t[0]) : t.indexOf(e) > -1 ? e : t[0]
        );
      })();
    </script>
    <title>08 | SocketServer（中）：请求还要区分优先级？ - 大师兄</title>
  </head>
  <body>
    <div id="root"><div class="__dumi-default-layout" data-route="/kafka核心源码解读/03.请求处理模块/03" data-show-sidemenu="true" data-show-slugs="true" data-site-mode="true" data-gapless="false"><div class="__dumi-default-navbar" data-mode="site"><button class="__dumi-default-navbar-toggle"></button><a class="__dumi-default-navbar-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-backend/">大师兄</a><nav><div class="__dumi-default-search"><input type="search" class="__dumi-default-search-input" value=""/><ul></ul></div><span>后端开发<ul><li><a href="/blog-backend/go语言核心36讲">go语言核心36讲</a></li><li><a href="/blog-backend/go并发编程实战">go并发编程实战</a></li><li><a href="/blog-backend/go语言项目开发实战">go语言项目开发实战</a></li><li><a href="/blog-backend/kafka核心技术与实战">kafka核心技术与实战</a></li><li><a aria-current="page" class="active" href="/blog-backend/kafka核心源码解读">kafka核心源码解读</a></li><li><a href="/blog-backend/零基础学python">零基础学python</a></li><li><a href="/blog-backend/python核心技术与实战">python核心技术与实战</a></li><li><a href="/blog-backend/redis核心技术与实战">redis核心技术与实战</a></li><li><a href="/blog-backend/redis源码剖析与实战">redis源码剖析与实战</a></li><li><a href="/blog-backend/陈天rust编程第一课">陈天rust编程第一课</a></li><li><a href="/blog-backend/tonybaigo语言第一课">tonybaigo语言第一课</a></li><li><a href="/blog-backend/后端存储实战课">后端存储实战课</a></li><li><a href="/blog-backend/后端技术面试38讲">后端技术面试38讲</a></li><li><a href="/blog-backend/深入c语言和程序运行原理">深入c语言和程序运行原理</a></li><li><a href="/blog-backend/现代c编程实战">现代c编程实战</a></li><li><a href="/blog-backend/罗剑锋的c实战笔记">罗剑锋的c实战笔记</a></li><li><a href="/blog-backend/零基础入门spark">零基础入门spark</a></li></ul></span><span>架构师<ul><li><a href="/blog-backend/mysql实战45讲">mysql实战45讲</a></li><li><a href="/blog-backend/数据中台实战课">数据中台实战课</a></li></ul></span><div class="__dumi-default-navbar-tool"><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "></div></div></div></nav></div><div class="__dumi-default-menu" data-mode="site"><div class="__dumi-default-menu-inner"><div class="__dumi-default-menu-header"><a class="__dumi-default-menu-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-backend/"></a><h1>大师兄</h1><p></p></div><div class="__dumi-default-menu-mobile-area"><ul class="__dumi-default-menu-nav-list"><li>后端开发<ul><li><a href="/blog-backend/go语言核心36讲">go语言核心36讲</a></li><li><a href="/blog-backend/go并发编程实战">go并发编程实战</a></li><li><a href="/blog-backend/go语言项目开发实战">go语言项目开发实战</a></li><li><a href="/blog-backend/kafka核心技术与实战">kafka核心技术与实战</a></li><li><a aria-current="page" class="active" href="/blog-backend/kafka核心源码解读">kafka核心源码解读</a></li><li><a href="/blog-backend/零基础学python">零基础学python</a></li><li><a href="/blog-backend/python核心技术与实战">python核心技术与实战</a></li><li><a href="/blog-backend/redis核心技术与实战">redis核心技术与实战</a></li><li><a href="/blog-backend/redis源码剖析与实战">redis源码剖析与实战</a></li><li><a href="/blog-backend/陈天rust编程第一课">陈天rust编程第一课</a></li><li><a href="/blog-backend/tonybaigo语言第一课">tonybaigo语言第一课</a></li><li><a href="/blog-backend/后端存储实战课">后端存储实战课</a></li><li><a href="/blog-backend/后端技术面试38讲">后端技术面试38讲</a></li><li><a href="/blog-backend/深入c语言和程序运行原理">深入c语言和程序运行原理</a></li><li><a href="/blog-backend/现代c编程实战">现代c编程实战</a></li><li><a href="/blog-backend/罗剑锋的c实战笔记">罗剑锋的c实战笔记</a></li><li><a href="/blog-backend/零基础入门spark">零基础入门spark</a></li></ul></li><li>架构师<ul><li><a href="/blog-backend/mysql实战45讲">mysql实战45讲</a></li><li><a href="/blog-backend/数据中台实战课">数据中台实战课</a></li></ul></li></ul><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "><button title="Dark theme" class="__dumi-default-dark-moon "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3854" width="22" height="22"><path d="M991.816611 674.909091a69.166545 69.166545 0 0 0-51.665455-23.272727 70.795636 70.795636 0 0 0-27.438545 5.585454A415.674182 415.674182 0 0 1 754.993338 698.181818c-209.594182 0-393.472-184.785455-393.472-395.636363 0-52.363636 38.539636-119.621818 69.515637-173.614546 4.887273-8.610909 9.634909-16.756364 14.103272-24.901818A69.818182 69.818182 0 0 0 384.631156 0a70.842182 70.842182 0 0 0-27.438545 5.585455C161.678429 90.298182 14.362065 307.898182 14.362065 512c0 282.298182 238.824727 512 532.38691 512a522.286545 522.286545 0 0 0 453.957818-268.334545A69.818182 69.818182 0 0 0 991.816611 674.909091zM546.679156 954.181818c-248.785455 0-462.941091-192-462.941091-442.181818 0-186.647273 140.637091-372.829091 300.939637-442.181818-36.817455 65.629091-92.578909 151.970909-92.578909 232.727273 0 250.181818 214.109091 465.454545 462.917818 465.454545a488.331636 488.331636 0 0 0 185.181091-46.545455 453.003636 453.003636 0 0 1-393.565091 232.727273z m103.656728-669.323636l-14.266182 83.781818a34.909091 34.909091 0 0 0 50.362182 36.770909l74.775272-39.563636 74.752 39.563636a36.142545 36.142545 0 0 0 16.174546 3.956364 34.909091 34.909091 0 0 0 34.210909-40.727273l-14.289455-83.781818 60.509091-59.345455a35.025455 35.025455 0 0 0-19.223272-59.578182l-83.61891-12.101818-37.376-76.101818a34.56 34.56 0 0 0-62.254545 0l-37.376 76.101818-83.618909 12.101818a34.909091 34.909091 0 0 0-19.246546 59.578182z m70.423272-64.698182a34.280727 34.280727 0 0 0 26.135273-19.083636l14.312727-29.090909 14.336 29.090909a34.257455 34.257455 0 0 0 26.135273 19.083636l32.046546 4.887273-23.272728 22.574545a35.234909 35.234909 0 0 0-10.007272 30.952727l5.46909 32.116364-28.625454-15.127273a34.490182 34.490182 0 0 0-32.302546 0l-28.695272 15.127273 5.469091-32.116364a35.141818 35.141818 0 0 0-9.984-30.952727l-23.272728-22.574545z" p-id="3855"></path></svg></button><button title="Light theme" class="__dumi-default-dark-sun "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4026" width="22" height="22"><path d="M915.2 476.16h-43.968c-24.704 0-44.736 16-44.736 35.84s20.032 35.904 44.736 35.904H915.2c24.768 0 44.8-16.064 44.8-35.904s-20.032-35.84-44.8-35.84zM512 265.6c-136.704 0-246.464 109.824-246.464 246.4 0 136.704 109.76 246.464 246.464 246.464S758.4 648.704 758.4 512c0-136.576-109.696-246.4-246.4-246.4z m0 425.6c-99.008 0-179.2-80.128-179.2-179.2 0-98.944 80.192-179.2 179.2-179.2S691.2 413.056 691.2 512c0 99.072-80.192 179.2-179.2 179.2zM197.44 512c0-19.84-19.136-35.84-43.904-35.84H108.8c-24.768 0-44.8 16-44.8 35.84s20.032 35.904 44.8 35.904h44.736c24.768 0 43.904-16.064 43.904-35.904zM512 198.464c19.776 0 35.84-20.032 35.84-44.8v-44.8C547.84 84.032 531.84 64 512 64s-35.904 20.032-35.904 44.8v44.8c0 24.768 16.128 44.864 35.904 44.864z m0 627.136c-19.776 0-35.904 20.032-35.904 44.8v44.736C476.096 940.032 492.16 960 512 960s35.84-20.032 35.84-44.8v-44.736c0-24.768-16.064-44.864-35.84-44.864z m329.92-592.832c17.472-17.536 20.288-43.072 6.4-57.024-14.016-14.016-39.488-11.2-57.024 6.336-4.736 4.864-26.496 26.496-31.36 31.36-17.472 17.472-20.288 43.008-6.336 57.024 13.952 14.016 39.488 11.2 57.024-6.336 4.8-4.864 26.496-26.56 31.296-31.36zM213.376 759.936c-4.864 4.8-26.56 26.624-31.36 31.36-17.472 17.472-20.288 42.944-6.4 56.96 14.016 13.952 39.552 11.2 57.024-6.336 4.8-4.736 26.56-26.496 31.36-31.36 17.472-17.472 20.288-43.008 6.336-56.96-14.016-13.952-39.552-11.072-56.96 6.336z m19.328-577.92c-17.536-17.536-43.008-20.352-57.024-6.336-14.08 14.016-11.136 39.488 6.336 57.024 4.864 4.864 26.496 26.56 31.36 31.424 17.536 17.408 43.008 20.288 56.96 6.336 14.016-14.016 11.264-39.488-6.336-57.024-4.736-4.864-26.496-26.56-31.296-31.424z m527.168 628.608c4.864 4.864 26.624 26.624 31.36 31.424 17.536 17.408 43.072 20.224 57.088 6.336 13.952-14.016 11.072-39.552-6.4-57.024-4.864-4.8-26.56-26.496-31.36-31.36-17.472-17.408-43.072-20.288-57.024-6.336-13.952 14.016-11.008 39.488 6.336 56.96z" p-id="4027"></path></svg></button><button title="Default to system" class="__dumi-default-dark-auto "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="11002" width="22" height="22"><path d="M127.658667 492.885333c0-51.882667 10.24-101.717333 30.378666-149.162666s47.786667-88.064 81.92-122.538667 75.093333-61.781333 122.538667-81.92 96.938667-30.378667 149.162667-30.378667 101.717333 10.24 149.162666 30.378667 88.405333 47.786667 122.88 81.92 61.781333 75.093333 81.92 122.538667 30.378667 96.938667 30.378667 149.162666-10.24 101.717333-30.378667 149.162667-47.786667 88.405333-81.92 122.88-75.093333 61.781333-122.88 81.92-97.28 30.378667-149.162666 30.378667-101.717333-10.24-149.162667-30.378667-88.064-47.786667-122.538667-81.92-61.781333-75.093333-81.92-122.88-30.378667-96.938667-30.378666-149.162667z m329.045333 0c0 130.048 13.994667 244.394667 41.984 343.381334h12.970667c46.762667 0 91.136-9.216 133.461333-27.306667s78.848-42.666667 109.568-73.386667 54.954667-67.242667 73.386667-109.568 27.306667-86.698667 27.306666-133.461333c0-46.421333-9.216-90.794667-27.306666-133.12s-42.666667-78.848-73.386667-109.568-67.242667-54.954667-109.568-73.386667-86.698667-27.306667-133.461333-27.306666h-11.605334c-28.672 123.562667-43.349333 237.909333-43.349333 343.722666z" p-id="11003"></path></svg></button></div></div></div><ul class="__dumi-default-menu-list"><li><a href="/blog-backend/kafka核心源码解读">kafka核心源码解读</a></li><li><a href="/blog-backend/kafka核心源码解读/01.课前必学">01.课前必学</a><ul><li><a href="/blog-backend/kafka核心源码解读/01.课前必学/01"><span>开篇词 |  阅读源码，逐渐成了职业进阶道路上的“必选项”</span></a></li><li><a href="/blog-backend/kafka核心源码解读/01.课前必学/02"><span>导读 | 构建Kafka工程和源码阅读环境、Scala语言热身</span></a></li><li><a href="/blog-backend/kafka核心源码解读/01.课前必学/03"><span>重磅加餐 | 带你快速入门Scala语言</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/02.日志模块">02.日志模块</a><ul><li><a href="/blog-backend/kafka核心源码解读/02.日志模块/01"><span>01 | 日志段：保存消息文件的对象是怎么实现的？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/02.日志模块/02"><span>02 | 日志（上）：日志究竟是如何加载日志段的？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/02.日志模块/03"><span>03 | 日志（下）：彻底搞懂Log对象的常见操作</span></a></li><li><a href="/blog-backend/kafka核心源码解读/02.日志模块/04"><span>04 | 索引（上）：改进的二分查找算法在Kafka索引的应用</span></a></li><li><a href="/blog-backend/kafka核心源码解读/02.日志模块/05"><span>05 | 索引（下）：位移索引和时间戳索引的区别是什么？</span></a></li></ul></li><li><a aria-current="page" class="active" href="/blog-backend/kafka核心源码解读/03.请求处理模块">03.请求处理模块</a><ul><li><a href="/blog-backend/kafka核心源码解读/03.请求处理模块/01"><span>06 | 请求通道：如何实现Kafka请求队列？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/03.请求处理模块/02"><span>07 | SocketServer（上）：Kafka到底是怎么应用NIO实现网络通信的？</span></a></li><li><a aria-current="page" class="active" href="/blog-backend/kafka核心源码解读/03.请求处理模块/03"><span>08 | SocketServer（中）：请求还要区分优先级？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/03.请求处理模块/04"><span>09 | SocketServer（下）：请求处理全流程源码分析</span></a></li><li><a href="/blog-backend/kafka核心源码解读/03.请求处理模块/05"><span>10 | KafkaApis：Kafka最重要的源码入口，没有之一</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/04.controller模块">04.Controller模块</a><ul><li><a href="/blog-backend/kafka核心源码解读/04.controller模块/01"><span>11 | Controller元数据：Controller都保存有哪些东西？有几种状态？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/04.controller模块/02"><span>12 | ControllerChannelManager：Controller如何管理请求发送？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/04.controller模块/03"><span>13 | ControllerEventManager：变身单线程后的Controller如何处理事件？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/04.controller模块/04"><span>14 | Controller选举是怎么实现的？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/04.controller模块/05"><span>15 | 如何理解Controller在Kafka集群中的作用？</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/05.状态机模块">05.状态机模块</a><ul><li><a href="/blog-backend/kafka核心源码解读/05.状态机模块/01"><span>16 | TopicDeletionManager： Topic是怎么被删除的？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/05.状态机模块/02"><span>17 | ReplicaStateMachine：揭秘副本状态机实现原理</span></a></li><li><a href="/blog-backend/kafka核心源码解读/05.状态机模块/03"><span>18 | PartitionStateMachine：分区状态转换如何实现？</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/06.延迟操作模块">06.延迟操作模块</a><ul><li><a href="/blog-backend/kafka核心源码解读/06.延迟操作模块/01"><span>19 | TimingWheel：探究Kafka定时器背后的高效时间轮算法</span></a></li><li><a href="/blog-backend/kafka核心源码解读/06.延迟操作模块/02"><span>20 | DelayedOperation：Broker是怎么延时处理请求的？</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/07.副本管理模块">07.副本管理模块</a><ul><li><a href="/blog-backend/kafka核心源码解读/07.副本管理模块/01"><span>21 | AbstractFetcherThread：拉取消息分几步？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/07.副本管理模块/02"><span>22 | ReplicaFetcherThread：Follower如何拉取Leader消息？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/07.副本管理模块/03"><span>23 | ReplicaManager（上）：必须要掌握的副本管理类定义和核心字段</span></a></li><li><a href="/blog-backend/kafka核心源码解读/07.副本管理模块/04"><span>24 | ReplicaManager（中）：副本管理器是如何读写副本的？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/07.副本管理模块/05"><span>25 | ReplicaManager（下）：副本管理器是如何管理副本的？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/07.副本管理模块/06"><span>26 | MetadataCache：Broker是怎么异步更新元数据缓存的？</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块">08.消费者组管理模块</a><ul><li><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/01"><span>27 | 消费者组元数据（上）：消费者组都有哪些元数据？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/02"><span>28 | 消费者组元数据（下）：Kafka如何管理这些元数据？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/03"><span>29 | GroupMetadataManager：组元数据管理器是个什么东西？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/04"><span>30 | GroupMetadataManager：位移主题保存的只是位移吗？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/05"><span>31 | GroupMetadataManager：查询位移时，不用读取位移主题？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/06"><span>32 | GroupCoordinator：在Rebalance中，Coordinator如何处理成员入组？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/08.消费者组管理模块/07"><span>33 | GroupCoordinator：在Rebalance中，如何进行组同步？</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/09.特别放送">09.特别放送</a><ul><li><a href="/blog-backend/kafka核心源码解读/09.特别放送/01"><span>特别放送（一）| 经典的Kafka学习资料有哪些？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/09.特别放送/02"><span>特别放送（二）| 一篇文章带你了解参与开源社区的全部流程</span></a></li><li><a href="/blog-backend/kafka核心源码解读/09.特别放送/03"><span>特别放送（三）| 我是怎么度过日常一天的？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/09.特别放送/04"><span>特别放送（四）| 20道经典的Kafka面试题详解</span></a></li><li><a href="/blog-backend/kafka核心源码解读/09.特别放送/05"><span>特别放送（五） | Kafka 社区的重磅功能：移除 ZooKeeper 依赖</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/10.测试题">10.测试题</a><ul><li><a href="/blog-backend/kafka核心源码解读/10.测试题/01"><span>期中测试 | 这些源码知识，你都掌握了吗？</span></a></li><li><a href="/blog-backend/kafka核心源码解读/10.测试题/02"><span>期末测试 | 一套习题，测试你的掌握程度</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/11.结束语">11.结束语</a><ul><li><a href="/blog-backend/kafka核心源码解读/11.结束语/01"><span>结束语 | 源码学习，我们才刚上路呢</span></a></li></ul></li><li><a href="/blog-backend/kafka核心源码解读/summary">kafka核心源码解读</a></li></ul></div></div><ul role="slug-list" class="__dumi-default-layout-toc"><li title="案例分享" data-depth="2"><a href="/blog-backend/kafka核心源码解读/03.请求处理模块/03#案例分享"><span>案例分享</span></a></li><li title="必要术语和概念" data-depth="2"><a href="/blog-backend/kafka核心源码解读/03.请求处理模块/03#必要术语和概念"><span>必要术语和概念</span></a></li><li title="SocketServer定义" data-depth="2"><a href="/blog-backend/kafka核心源码解读/03.请求处理模块/03#socketserver定义"><span>SocketServer定义</span></a></li><li title="创建Data plane所需资源" data-depth="2"><a href="/blog-backend/kafka核心源码解读/03.请求处理模块/03#创建data-plane所需资源"><span>创建Data plane所需资源</span></a></li><li title="创建Control plane所需资源" data-depth="2"><a href="/blog-backend/kafka核心源码解读/03.请求处理模块/03#创建control-plane所需资源"><span>创建Control plane所需资源</span></a></li><li title="总结" data-depth="2"><a href="/blog-backend/kafka核心源码解读/03.请求处理模块/03#总结"><span>总结</span></a></li><li title="课后讨论" data-depth="2"><a href="/blog-backend/kafka核心源码解读/03.请求处理模块/03#课后讨论"><span>课后讨论</span></a></li></ul><div class="__dumi-default-layout-content"><div class="markdown"><h1 id="08--socketserver中请求还要区分优先级"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/03.请求处理模块/03#08--socketserver中请求还要区分优先级"><span class="icon icon-link"></span></a>08 | SocketServer（中）：请求还要区分优先级？</h1><p>你好，我是胡夕。</p><p>在上节课，我给你详细地介绍了Kafka网络层的架构，以及SocketServer组件中的Acceptor线程和Processor线程是如何利用Java NIO实现网络通信的，还简单提到了请求队列和响应队列。</p><p>今天，我们接着说SocketServer源码，重点学习下社区是如何对不同类型的请求进行优先级划分的。</p><h2 id="案例分享"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/03.请求处理模块/03#案例分享"><span class="icon icon-link"></span></a>案例分享</h2><p>在Kafka中，处理请求是不区分优先级的，Kafka对待所有请求都一视同仁。<strong>这种绝对公平的策略有时候是有问题的</strong>。我跟你分享一个真实的案例，你就明白了。我敢保证，你在真实的线上系统中一定遇到过类似的问题。</p><p>曾经，我们在生产环境中创建过一个单分区双副本的主题，当时，集群中的Broker A机器保存了分区的Leader副本，Broker B保存了Follower副本。某天，外部业务量激增，导致Broker A瞬间积压了大量的未处理PRODUCE请求。更糟的是，运维人员“不凑巧”地执行了一次Preferred Leader选举，将Broker B显式地调整成了Leader。</p><p>这个时候，问题就来了：如果Producer程序把acks设置为all，那么，在LeaderAndIsr请求（它是负责调整副本角色的，比如Follower和Leader角色转换等）之前积压的那些PRODUCE请求就无法正常完成了，因为这些请求要一直等待ISR中所有Follower副本同步完成。</p><p>但是，此时，Broker B成为了Leader，它上面的副本停止了拉取消息，这就可能出现一种结果：这些未完成的PRODUCE请求会一直保存在Broker A上的Purgatory缓存中。Leader/Follower的角色转换，导致无法完成副本间同步，所以这些请求无法被成功处理，最终Broker A抛出超时异常，返回给Producer程序。</p><p>值得一提的是，Purgatory缓存是Broker端暂存延时请求的地方。课程后面我会详细介绍这个组件。</p><p>这个问题就是对请求不区分优先级造成的，后来，我们在SocketServer源码中确认了此事。同时，结合阅读源码得到的知识，我在Jira官网搜到了对应的<a target="_blank" rel="noopener noreferrer" href="https://issues.apache.org/jira/browse/KAFKA-4453">Jira ticket<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>，进而完整地了解了社区是如何解决该问题的。</p><p>其实，这也是我非常推荐你深入学习Kafka的一个方法：<strong>根据实际环境中碰到的问题找到对应的源码，仔细阅读它，形成自己的解决思路，然后去社区印证自己方案的优劣</strong>。在不断地循环这个过程的同时，你会发现，你对Kafka的代码越来越了解了，而且能够很轻松地解决线上环境的各种问题。</p><p>说了这么多，相信你已经迫不及待地想要跟我一起阅读这部分源码了，那我们就正式开始吧。</p><h2 id="必要术语和概念"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/03.请求处理模块/03#必要术语和概念"><span class="icon icon-link"></span></a>必要术语和概念</h2><p>在阅读SocketServer代码、深入学习请求优先级实现机制之前，我们要先掌握一些基本概念，这是我们理解后面内容的基础。</p><p><strong>1.Data plane和Control plane</strong></p><p>社区将Kafka请求类型划分为两大类：<strong>数据类请求和控制类请求</strong>。Data plane和Control plane的字面意思是数据面和控制面，各自对应数据类请求和控制类请求，也就是说Data plane负责处理数据类请求，Control plane负责处理控制类请求。</p><p>目前，Controller与Broker交互的请求类型有3种：<strong>LeaderAndIsrRequest</strong>、<strong>StopReplicaRequest</strong>和<strong>UpdateMetadataRequest</strong>。这3类请求属于控制类请求，通常应该被赋予高优先级。像我们熟知的PRODUCE和FETCH请求，就是典型的数据类请求。</p><p><strong>对这两大类请求区分处理，是SocketServer源码实现的核心逻辑</strong>。</p><p><strong>2.监听器（Listener）</strong></p><p>目前，<strong>源码区分数据类请求和控制类请求不同处理方式的主要途径，就是通过监听器</strong>。也就是说，创建多组监听器分别来执行数据类和控制类请求的处理代码。</p><p>在Kafka中，Broker端参数<strong>listeners</strong>和<strong>advertised.listeners</strong>就是用来配置监听器的。在源码中，监听器使用EndPoint类来定义，如下面代码所示：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">case class EndPoint(host: String, port: Int, listenerName: ListenerName, securityProtocol: SecurityProtocol) {</span></div><div class="token-line"><span class="token plain">      // 构造完整的监听器连接字符串</span></div><div class="token-line"><span class="token plain">      // 格式为：监听器名称://主机名：端口</span></div><div class="token-line"><span class="token plain">      // 比如：PLAINTEXT://kafka-host:9092</span></div><div class="token-line"><span class="token plain">      def connectionString: String = {</span></div><div class="token-line"><span class="token plain">        val hostport =</span></div><div class="token-line"><span class="token plain">          if (host == null)</span></div><div class="token-line"><span class="token plain">            &quot;:&quot;+port</span></div><div class="token-line"><span class="token plain">          else</span></div><div class="token-line"><span class="token plain">            Utils.formatAddress(host, port)</span></div><div class="token-line"><span class="token plain">        listenerName.value + &quot;://&quot; + hostport</span></div><div class="token-line"><span class="token plain">      }</span></div><div class="token-line"><span class="token plain">      // clients工程下有一个Java版本的Endpoint类供clients端代码使用</span></div><div class="token-line"><span class="token plain">      // 此方法是构造Java版本的Endpoint类实例</span></div><div class="token-line"><span class="token plain">      def toJava: JEndpoint = {</span></div><div class="token-line"><span class="token plain">        new JEndpoint(listenerName.value, securityProtocol, host, port)</span></div><div class="token-line"><span class="token plain">      }</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>每个EndPoint对象定义了4个属性，我们分别来看下。</p><ul><li>host：Broker主机名。</li><li>port：Broker端口号。</li><li>listenerName：监听器名字。目前预定义的名称包括PLAINTEXT、SSL、SASL_PLAINTEXT和SASL_SSL。Kafka允许你自定义其他监听器名称，比如CONTROLLER、INTERNAL等。</li><li>securityProtocol：监听器使用的安全协议。Kafka支持4种安全协议，分别是<strong>PLAINTEXT</strong>、<strong>SSL</strong>、<strong>SASL_PLAINTEXT</strong>和<strong>SASL_SSL</strong>。</li></ul><p>这里简单提一下，<strong>Broker端参数listener.security.protocol.map用于指定不同名字的监听器都使用哪种安全协议</strong>。</p><p>我举个例子，如果Broker端相应参数配置如下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">listener.security.protocol.map=CONTROLLER:PLAINTEXT,INTERNAL:PLAINTEXT,EXTERNAL:SSL</span></div><div class="token-line"><span class="token plain">    listeners=CONTROLLER://192.1.1.8:9091,INTERNAL://192.1.1.8:9092,EXTERNAL://10.1.1.5:9093</span></div></pre></div><p>那么，这就表示，Kafka配置了3套监听器，名字分别是CONTROLLER、INTERNAL和EXTERNAL，使用的安全协议分别是PLAINTEXT、PLAINTEXT和SSL。</p><p>有了这些基础知识，接下来，我们就可以看一下SocketServer是如何实现Data plane与Control plane的分离的。</p><p>当然，在此之前，我们要先了解下SocketServer的定义。</p><h2 id="socketserver定义"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/03.请求处理模块/03#socketserver定义"><span class="icon icon-link"></span></a>SocketServer定义</h2><p>首先，我们来看下SocketServer类有哪些基础属性。我使用思维导图给你展示一下跟实现请求优先级相关的字段或属性：</p><p><img src="/blog-backend/static/httpsstatic001geekbangorgresourceimage95e595e4a958d84263e4606ab096d5695be5.9276e7bf.jpg" alt=""/></p><p>这些字段都是啥意思呢？我们结合代码来看下。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">class SocketServer(val config: KafkaConfig, </span></div><div class="token-line"><span class="token plain">      val metrics: Metrics,</span></div><div class="token-line"><span class="token plain">      val time: Time,  </span></div><div class="token-line"><span class="token plain">      val credentialProvider: CredentialProvider) </span></div><div class="token-line"><span class="token plain">      extends Logging with KafkaMetricsGroup with BrokerReconfigurable {</span></div><div class="token-line"><span class="token plain">      // SocketServer实现BrokerReconfigurable trait表明SocketServer的一些参数配置是允许动态修改的</span></div><div class="token-line"><span class="token plain">      // 即在Broker不停机的情况下修改它们</span></div><div class="token-line"><span class="token plain">      // SocketServer的请求队列长度，由Broker端参数queued.max.requests值而定，默认值是500</span></div><div class="token-line"><span class="token plain">      private val maxQueuedRequests = config.queuedMaxRequests</span></div><div class="token-line"><span class="token plain">      ......</span></div><div class="token-line"><span class="token plain">      // data-plane</span></div><div class="token-line"><span class="token plain">      private val dataPlaneProcessors = new ConcurrentHashMap[Int, Processor]() // 处理数据类请求的Processor线程池</span></div><div class="token-line"><span class="token plain">      // 处理数据类请求的Acceptor线程池，每套监听器对应一个Acceptor线程</span></div><div class="token-line"><span class="token plain">      private[network] val dataPlaneAcceptors = new ConcurrentHashMap[EndPoint, Acceptor]()</span></div><div class="token-line"><span class="token plain">      // 处理数据类请求专属的RequestChannel对象</span></div><div class="token-line"><span class="token plain">      val dataPlaneRequestChannel = new RequestChannel(maxQueuedRequests, DataPlaneMetricPrefix)</span></div><div class="token-line"><span class="token plain">      // control-plane</span></div><div class="token-line"><span class="token plain">      // 用于处理控制类请求的Processor线程</span></div><div class="token-line"><span class="token plain">      // 注意：目前定义了专属的Processor线程而非线程池处理控制类请求</span></div><div class="token-line"><span class="token plain">      private var controlPlaneProcessorOpt : Option[Processor] = None</span></div><div class="token-line"><span class="token plain">      private[network] var controlPlaneAcceptorOpt : Option[Acceptor] = None</span></div><div class="token-line"><span class="token plain">      // 处理控制类请求专属的RequestChannel对象</span></div><div class="token-line"><span class="token plain">      val controlPlaneRequestChannelOpt: Option[RequestChannel] = config.controlPlaneListenerName.map(_ =&gt; new RequestChannel(20, ControlPlaneMetricPrefix))</span></div><div class="token-line"><span class="token plain">      ......</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>首先，SocketServer类定义了一个maxQueuedRequests字段，它定义了请求队列的最大长度。默认值是Broker端queued.max.requests参数值。</p><p>其次，在上面的代码中，你一定看到了SocketServer实现了BrokerReconfigurable接口（在Scala中是trait）。这就说明，SocketServer中的某些配置，是允许动态修改值的。如果查看SocketServer伴生对象类的定义的话，你能找到下面这些代码：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">object SocketServer {</span></div><div class="token-line"><span class="token plain">      ......</span></div><div class="token-line"><span class="token plain">      val ReconfigurableConfigs = Set(</span></div><div class="token-line"><span class="token plain">        KafkaConfig.MaxConnectionsPerIpProp,</span></div><div class="token-line"><span class="token plain">        KafkaConfig.MaxConnectionsPerIpOverridesProp,</span></div><div class="token-line"><span class="token plain">        KafkaConfig.MaxConnectionsProp)</span></div><div class="token-line"><span class="token plain">      ......</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>根据这段代码，我们可以知道，Broker端参数max.connections.per.ip、max.connections.per.ip.overrides和max.connections是可以动态修改的。</p><p>另外，在我们刚刚看的SocketServer定义的那段代码中，Data plane和Control plane注释下面分别定义了一组变量，即<strong>Processor线程池</strong>、<strong>Acceptor线程池</strong>和<strong>RequestChannel</strong>实例。</p><ul><li>Processor线程池：即上节课提到的网络线程池，负责将请求高速地放入到请求队列中。</li><li>Acceptor线程池：保存了SocketServer为每个监听器定义的Acceptor线程，此线程负责分发该监听器上的入站连接建立请求。</li><li>RequestChannel：承载请求队列的请求处理通道。</li></ul><p>严格地说，对于Data plane来说，线程池的说法是没有问题的，因为Processor线程确实有很多个，而Acceptor也可能有多个，因为SocketServer会为每个EndPoint（即每套监听器）创建一个对应的Acceptor线程。</p><p>但是，对于Control plane而言，情况就不一样了。</p><p>细心的你一定发现了，Control plane那组属性变量都是以Opt结尾的，即它们都是Option类型。这说明了一个重要的事实：你完全可以不使用Control plane套装，即你可以让Kafka不区分请求类型，就像2.2.0之前设计的那样。</p><p>但是，一旦你开启了Control plane设置，其Processor线程就只有1个，Acceptor线程也是1个。另外，你要注意，它对应的RequestChannel里面的请求队列长度被硬编码成了20，而不是一个可配置的值。这揭示了社区在这里所做的一个假设：即<strong>控制类请求的数量应该远远小于数据类请求，因而不需要为它创建线程池和较深的请求队列</strong>。</p><h2 id="创建data-plane所需资源"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/03.请求处理模块/03#创建data-plane所需资源"><span class="icon icon-link"></span></a>创建Data plane所需资源</h2><p>知道了SocketServer类的定义之后，我们就可以开始学习SocketServer是如何为Data plane和Control plane创建所需资源的操作了。我们先来看为Data plane创建资源。</p><p>SocketServer的<strong>createDataPlaneAcceptorsAndProcessors方法</strong>负责为Data plane创建所需资源。我们看下它的实现：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">private def createDataPlaneAcceptorsAndProcessors(</span></div><div class="token-line"><span class="token plain">      dataProcessorsPerListener: Int, endpoints: Seq[EndPoint]): Unit = {</span></div><div class="token-line"><span class="token plain">      // 遍历监听器集合</span></div><div class="token-line"><span class="token plain">      endpoints.foreach { endpoint =&gt;</span></div><div class="token-line"><span class="token plain">        // 将监听器纳入到连接配额管理之下</span></div><div class="token-line"><span class="token plain">        connectionQuotas.addListener(config, endpoint.listenerName)</span></div><div class="token-line"><span class="token plain">        // 为监听器创建对应的Acceptor线程</span></div><div class="token-line"><span class="token plain">        val dataPlaneAcceptor = createAcceptor(endpoint, DataPlaneMetricPrefix)</span></div><div class="token-line"><span class="token plain">        // 为监听器创建多个Processor线程。具体数目由num.network.threads决定</span></div><div class="token-line"><span class="token plain">        addDataPlaneProcessors(dataPlaneAcceptor, endpoint, dataProcessorsPerListener)</span></div><div class="token-line"><span class="token plain">        // 将&lt;监听器，Acceptor线程&gt;对保存起来统一管理</span></div><div class="token-line"><span class="token plain">        dataPlaneAcceptors.put(endpoint, dataPlaneAcceptor)</span></div><div class="token-line"><span class="token plain">        info(s&quot;Created data-plane acceptor and processors for endpoint : ${endpoint.listenerName}&quot;)</span></div><div class="token-line"><span class="token plain">      }</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>这段代码的逻辑非常清晰，我用一张图来解释说明下：</p><p><img src="/blog-backend/static/httpsstatic001geekbangorgresourceimageb660b6952e86566cdfe92d69e9d96a031560.053bb8c6.jpg" alt=""/></p><p>createDataPlaneAcceptorsAndProcessors方法会遍历你配置的所有监听器，然后为每个监听器执行下面的逻辑。</p><ol><li>初始化该监听器对应的最大连接数计数器。后续这些计数器将被用来确保没有配额超限的情形发生。</li><li>为该监听器创建Acceptor线程，也就是调用Acceptor类的构造函数，生成对应的Acceptor线程实例。</li><li>创建Processor线程池。对于Data plane而言，线程池的数量由Broker端参数num.network.threads决定。</li><li>将&lt;监听器，Acceptor线程&gt;对加入到Acceptor线程池统一管理。</li></ol><p>切记，源码会为每套用于Data plane的监听器执行以上这4步。</p><p>举个例子，假设你配置listeners=PLAINTEXT://localhost:9092, SSL://localhost:9093，那么在默认情况下，源码会为PLAINTEXT和SSL这两套监听器分别创建一个Acceptor线程和一个Processor线程池。</p><p>需要注意的是，具体为哪几套监听器创建是依据配置而定的，最重要的是，<strong>Kafka只会为Data plane所使的监听器创建这些资源</strong>。至于如何指定监听器到底是为Data plane所用，还是归Control plane，我会再详细说明。</p><h2 id="创建control-plane所需资源"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/03.请求处理模块/03#创建control-plane所需资源"><span class="icon icon-link"></span></a>创建Control plane所需资源</h2><p>前面说过了，基于控制类请求的负载远远小于数据类请求负载的假设，Control plane的配套资源只有1个Acceptor线程 + 1个Processor线程 + 1个深度是20的请求队列而已。和Data plane相比，这些配置稍显寒酸，不过在大部分情况下，应该是够用了。</p><p>SocketServer提供了createControlPlaneAcceptorAndProcessor方法，用于为Control plane创建所需资源，源码如下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">private def createControlPlaneAcceptorAndProcessor(</span></div><div class="token-line"><span class="token plain">      endpointOpt: Option[EndPoint]): Unit = {</span></div><div class="token-line"><span class="token plain">      // 如果为Control plane配置了监听器</span></div><div class="token-line"><span class="token plain">      endpointOpt.foreach { endpoint =&gt;</span></div><div class="token-line"><span class="token plain">        // 将监听器纳入到连接配额管理之下</span></div><div class="token-line"><span class="token plain">        connectionQuotas.addListener(config, endpoint.listenerName)</span></div><div class="token-line"><span class="token plain">        // 为监听器创建对应的Acceptor线程</span></div><div class="token-line"><span class="token plain">        val controlPlaneAcceptor = createAcceptor(endpoint, ControlPlaneMetricPrefix)</span></div><div class="token-line"><span class="token plain">        // 为监听器创建对应的Processor线程</span></div><div class="token-line"><span class="token plain">        val controlPlaneProcessor = newProcessor(nextProcessorId, controlPlaneRequestChannelOpt.get, connectionQuotas, endpoint.listenerName, endpoint.securityProtocol, memoryPool)</span></div><div class="token-line"><span class="token plain">        controlPlaneAcceptorOpt = Some(controlPlaneAcceptor)</span></div><div class="token-line"><span class="token plain">        controlPlaneProcessorOpt = Some(controlPlaneProcessor)</span></div><div class="token-line"><span class="token plain">        val listenerProcessors = new ArrayBuffer[Processor]()</span></div><div class="token-line"><span class="token plain">        listenerProcessors += controlPlaneProcessor</span></div><div class="token-line"><span class="token plain">        // 将Processor线程添加到控制类请求专属RequestChannel中</span></div><div class="token-line"><span class="token plain">        // 即添加到RequestChannel实例保存的Processor线程池中</span></div><div class="token-line"><span class="token plain">        controlPlaneRequestChannelOpt.foreach(</span></div><div class="token-line"><span class="token plain">          _.addProcessor(controlPlaneProcessor))</span></div><div class="token-line"><span class="token plain">        nextProcessorId += 1</span></div><div class="token-line"><span class="token plain">        // 把Processor对象也添加到Acceptor线程管理的Processor线程池中</span></div><div class="token-line"><span class="token plain">        controlPlaneAcceptor.addProcessors(listenerProcessors, ControlPlaneThreadPrefix)</span></div><div class="token-line"><span class="token plain">        info(s&quot;Created control-plane acceptor and processor for endpoint : ${endpoint.listenerName}&quot;)</span></div><div class="token-line"><span class="token plain">      }</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>我同样使用一张流程图来说明：</p><p><img src="/blog-backend/static/httpsstatic001geekbangorgresourceimage691d69ba01a158bcf63be4e7606feb95521d.43ddf0dc.jpg" alt=""/></p><p>总体流程和createDataPlaneAcceptorsAndProcessors非常类似，只是方法开头需要判断是否配置了用于Control plane的监听器。目前，Kafka规定只能有1套监听器用于Control plane，而不能像Data plane那样可以配置多套监听器。</p><p>如果认真看的话，你会发现，上面两张图中都没有提到启动Acceptor和Processor线程。那这些线程到底是在什么时候启动呢？</p><p>实际上，Processor和Acceptor线程是在启动SocketServer组件之后启动的，具体代码在KafkaServer.scala文件的startup方法中，如下所示：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">// KafkaServer.scala</span></div><div class="token-line"><span class="token plain">    def startup(): Unit = {</span></div><div class="token-line"><span class="token plain">        try {</span></div><div class="token-line"><span class="token plain">          info(&quot;starting&quot;)</span></div><div class="token-line"><span class="token plain">          ......</span></div><div class="token-line"><span class="token plain">          // 创建SocketServer组件</span></div><div class="token-line"><span class="token plain">          socketServer = new SocketServer(config, metrics, time, credentialProvider)</span></div><div class="token-line"><span class="token plain">          // 启动SocketServer，但不启动Processor线程</span></div><div class="token-line"><span class="token plain">          socketServer.startup(startProcessingRequests = false)</span></div><div class="token-line"><span class="token plain">          ......</span></div><div class="token-line"><span class="token plain">          // 启动Data plane和Control plane的所有线程</span></div><div class="token-line"><span class="token plain">          socketServer.startProcessingRequests(authorizerFutures)</span></div><div class="token-line"><span class="token plain">          ......</span></div><div class="token-line"><span class="token plain">        } catch {</span></div><div class="token-line"><span class="token plain">          ......</span></div><div class="token-line"><span class="token plain">        }</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>咦？还是没看到启动Acceptor和Processor线程的代码啊？实际上，SocketServer的startProcessingRequests方法就是启动这些线程的方法。我们看下这个方法的逻辑：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">def startProcessingRequests(authorizerFutures: Map[Endpoint, CompletableFuture[Void]] = Map.empty): Unit = {</span></div><div class="token-line"><span class="token plain">      info(&quot;Starting socket server acceptors and processors&quot;)</span></div><div class="token-line"><span class="token plain">      this.synchronized {</span></div><div class="token-line"><span class="token plain">        if (!startedProcessingRequests) {</span></div><div class="token-line"><span class="token plain">          // 启动处理控制类请求的Processor和Acceptor线程</span></div><div class="token-line"><span class="token plain">          startControlPlaneProcessorAndAcceptor(authorizerFutures)</span></div><div class="token-line"><span class="token plain">          // 启动处理数据类请求的Processor和Acceptor线程</span></div><div class="token-line"><span class="token plain">          startDataPlaneProcessorsAndAcceptors(authorizerFutures)</span></div><div class="token-line"><span class="token plain">          startedProcessingRequests = true</span></div><div class="token-line"><span class="token plain">        } else {</span></div><div class="token-line"><span class="token plain">          info(&quot;Socket server acceptors and processors already started&quot;)</span></div><div class="token-line"><span class="token plain">        }</span></div><div class="token-line"><span class="token plain">      }</span></div><div class="token-line"><span class="token plain">      info(&quot;Started socket server acceptors and processors&quot;)</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>如果在你的环境中，你看不到startProcessingRequests方法，不用感到惊慌。这是今年4月16日刚刚添加的方法。你需要使用git命令去拉取最新的Trunk分支代码就能看到这个方法了。</p><p>这个方法又进一步调用了startDataPlaneProcessorsAndAcceptors和startControlPlaneProcessorAndAcceptor方法分别启动Data plane的Control plane的线程。鉴于这两个方法的逻辑类似，我们重点学习下startDataPlaneProcessorsAndAcceptors方法的实现。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">private def startDataPlaneProcessorsAndAcceptors(</span></div><div class="token-line"><span class="token plain">      authorizerFutures: Map[Endpoint, CompletableFuture[Void]]): Unit = {</span></div><div class="token-line"><span class="token plain">      // 获取Broker间通讯所用的监听器，默认是PLAINTEXT</span></div><div class="token-line"><span class="token plain">      val interBrokerListener = dataPlaneAcceptors.asScala.keySet</span></div><div class="token-line"><span class="token plain">        .find(_.listenerName == config.interBrokerListenerName)</span></div><div class="token-line"><span class="token plain">        .getOrElse(throw new IllegalStateException(s&quot;Inter-broker listener ${config.interBrokerListenerName} not found, endpoints=${dataPlaneAcceptors.keySet}&quot;))</span></div><div class="token-line"><span class="token plain">      val orderedAcceptors = List(dataPlaneAcceptors.get(interBrokerListener)) ++</span></div><div class="token-line"><span class="token plain">        dataPlaneAcceptors.asScala.filter { case (k, _) =&gt; k != interBrokerListener }.values</span></div><div class="token-line"><span class="token plain">      orderedAcceptors.foreach { acceptor =&gt;</span></div><div class="token-line"><span class="token plain">        val endpoint = acceptor.endPoint</span></div><div class="token-line"><span class="token plain">        // 启动Processor和Acceptor线程</span></div><div class="token-line"><span class="token plain">        startAcceptorAndProcessors(DataPlaneThreadPrefix, endpoint, acceptor, authorizerFutures)</span></div><div class="token-line"><span class="token plain">      }</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>该方法主要的逻辑是调用startAcceptorAndProcessors方法启动Acceptor和Processor线程。当然在此之前，代码要获取Broker间通讯所用的监听器，并找出该监听器对应的Acceptor线程以及它维护的Processor线程池。</p><p>好了，现在我要告诉你，到底是在哪里设置用于Control plane的监听器了。Broker端参数control.plane.listener.name，就是用于设置Control plane所用的监听器的地方。</p><p>在默认情况下，这个参数的值是空（Null）。Null的意思就是告诉Kafka不要启用请求优先级区分机制，但如果你设置了这个参数，Kafka就会利用它去listeners中寻找对应的监听器了。</p><p>我举个例子说明下。假设你的Broker端相应配置如下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">listener.security.protocol.map=CONTROLLER:PLAINTEXT,INTERNAL:PLAINTEXT,EXTERNAL:SSL</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">    listeners=CONTROLLER://192.1.1.8:9091,INTERNAL://192.1.1.8:9092,EXTERNAL://10.1.1.5:9093</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">    control.plane.listener.name=CONTROLLER</span></div></pre></div><p>那么，名字是CONTROLLER的那套监听器将被用于Control plane。换句话说，名字是INTERNAL和EXTERNAL的这两组监听器用于Data plane。在代码中，Kafka是如何知道CONTROLLER这套监听器是给Control plane使用的呢？简单来说，这是通过KafkaConfig中的3个方法完成的。KafkaConfig类封装了Broker端所有参数的信息，同时还定义了很多实用的工具方法。</p><p>现在，我结合上面的配置例子，用一张图的方式来说明这些代码方法的调用关系，以及主要方法的实现逻辑。</p><p><img src="/blog-backend/static/httpsstatic001geekbangorgresourceimagef29cf28bb3b2fc5c32fb05b3e585f7889e9c.b6d2adc2.jpg" alt=""/></p><p>图中涉及3个方法，它们的调用关系是自底向上，即最下面的方法调用中间的方法，中间的方法调用最上面的方法。现在，我来具体解释下代码是怎么找到Control plane对应的监听器的。</p><p>首先，代码要去获取Broker端参数control.plane.listener.name的值。在这个例子中，该值是CONTROLLER字符串，</p><p>之后，读取Broker端参数listener.security.protocol.map值，并找出CONTROLLER对应的安全认证协议。在这个例子中，CONTROLLER对应的安全认证协议是PLAINTEXT。controlPlaneListenerName方法的作用是拿到这组值，即&lt;CONTROLLER，PLAINTEXT&gt;对。</p><p>最后，controlPlaneListener方法拿到这组值后，取出监听器名称CONTROLLER去寻找Broker端参数listeners中对应的监听器。在这里，这个监听器就是CONTROLLER://192.1.1.8:9091。这就是确认Control plane监听器完整的查找逻辑。</p><p>你可以打开KafkaConfig.scala文件依次找到这3个方法的实现代码。这里我们重点查看下getControlPlaneListenerNameAndSecurityProtocol方法的代码实现：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">private def getControlPlaneListenerNameAndSecurityProtocol: Option[(ListenerName, SecurityProtocol)] = {</span></div><div class="token-line"><span class="token plain">      // 查看Broker端参数control.plane.listener.name值</span></div><div class="token-line"><span class="token plain">      // 即是否启用了control plane监听器</span></div><div class="token-line"><span class="token plain">      Option(getString(KafkaConfig.ControlPlaneListenerNameProp)) match {</span></div><div class="token-line"><span class="token plain">        // 如果启用了</span></div><div class="token-line"><span class="token plain">        case Some(name) =&gt; </span></div><div class="token-line"><span class="token plain">          val listenerName = ListenerName.normalised(name)</span></div><div class="token-line"><span class="token plain">          // 必须同时设置Broker端参数listener.security.protocol.map</span></div><div class="token-line"><span class="token plain">          // 并从该参数值中提取出该监听器对应的安全认证协议</span></div><div class="token-line"><span class="token plain">          val securityProtocol = listenerSecurityProtocolMap.getOrElse(listenerName,</span></div><div class="token-line"><span class="token plain">            throw new ConfigException(s&quot;Listener with ${listenerName.value} defined in &quot; +</span></div><div class="token-line"><span class="token plain">              s&quot;${KafkaConfig.ControlPlaneListenerNameProp} not found in ${KafkaConfig.ListenerSecurityProtocolMapProp}.&quot;))</span></div><div class="token-line"><span class="token plain">          // 返回&lt;监听器名称，安全认证协议&gt;对</span></div><div class="token-line"><span class="token plain">          Some(listenerName, securityProtocol)</span></div><div class="token-line"><span class="token plain">        // 如果没有设置该参数值，直接返回None，说明没有启用control plane监听器</span></div><div class="token-line"><span class="token plain">        case None =&gt; None  </span></div><div class="token-line"><span class="token plain">     }</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>这段代码的核心就是getString那一行，即Kafka会提取名为ControlPlaneListenerNameProp参数的值，而它就是control.plane.listener.name参数值。</p><p>拿到了这个参数值之后，controlPlaneListener方法会记录下这个值，然后把它传入到SocketServer的createControlPlaneAcceptorAndProcessor方法中。这样，SocketServer就能知道你到底有没有为Control plane设置专属监听器了。</p><p>讲到这里，Data plane和Control plane的内容我就说完了。现在我再来具体解释下它们和请求优先级之间的关系。</p><p>严格来说，Kafka没有为请求设置数值型的优先级，因此，我们并不能把所有请求按照所谓的优先级进行排序。到目前为止，Kafka仅仅实现了粗粒度的优先级处理，即整体上把请求分为数据类请求和控制类请求两类，而且没有为这两类定义可相互比较的优先级。那我们应该如何把刚刚说的所有东西和这里的优先级进行关联呢？</p><p>通过刚刚的学习，我们知道，社区定义了多套监听器以及底层处理线程的方式来区分这两大类请求。虽然我们很难直接比较这两大类请求的优先级，但在实际应用中，由于数据类请求的数量要远多于控制类请求，因此，为控制类请求单独定义处理资源的做法，实际上就等同于拔高了控制类请求的优先处理权。从这个角度上来说，这套做法间接实现了优先级的区别对待。</p><h2 id="总结"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/03.请求处理模块/03#总结"><span class="icon icon-link"></span></a>总结</h2><p>好了，我们来小结一下。今天，我们重点学习了社区实现不同类型请求优先级的方法。结合监听器的概念，我们深入到SocketServer的源码中，分析了Data plane和Control plane的实现原理。我们来回顾一下这节课的重点。</p><ul><li>Data plane：负责处理数据类请求，这类请求通常不需要高优先级处理。</li><li>Control plane：负责处理控制类请求，这类请求需要高优先级处理。</li><li>监听器：Kafka允许Broker定义多套监听器，每套监听器可用于Data plane或Control plane。</li><li>优先级实现原理：你要知道的是，社区设计了两套资源分别处理Data plane和Control plane请求。</li></ul><p><img src="/blog-backend/static/httpsstatic001geekbangorgresourceimageee8ceec8d1027bf77384d8d2fb8116af948c.8be0e425.jpg" alt=""/></p><p>下节课，我会带你串联起网络I/O层的所有组件，并且结合源码，带你深入理解一个请求在Kafka中是如何被处理的。敬请期待。</p><h2 id="课后讨论"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心源码解读/03.请求处理模块/03#课后讨论"><span class="icon icon-link"></span></a>课后讨论</h2><p>最后，我们来思考一个问题：如果不使用多套资源的方案，而是在请求队列这个层面进行改进，你觉得能够实现不同请求不同优先级的需求吗？比如说，将请求队列改造成支持抢占式的优先级队列方案，你可以说出这两个方案的优劣吗？</p><p>欢迎你在留言区畅所欲言，跟我交流讨论，也欢迎你把今天的内容分享给你的朋友。</p></div><div class="__dumi-default-layout-footer-meta"><a target="_blank" rel="noopener noreferrer" href="https://github.com/GGwujun/blog/edit/master/ssrc/kafka核心源码解读/03.请求处理模块/03.md">在 GitHub 上编辑此页<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a><span data-updated-text="最后更新时间：">2023/9/27 11:15:40</span></div></div></div></div>
	<script>
  window.g_useSSR = true;
  window.g_initialProps = {};
	</script>

    <script>
      (function () {
        if (!location.port) {
          (function (i, s, o, g, r, a, m) {
            i["GoogleAnalyticsObject"] = r;
            (i[r] =
              i[r] ||
              function () {
                (i[r].q = i[r].q || []).push(arguments);
              }),
              (i[r].l = 1 * new Date());
            (a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m);
          })(
            window,
            document,
            "script",
            "//www.google-analytics.com/analytics.js",
            "ga"
          );
          ga("create", "UA-149864185-1", "auto");
          ga("send", "pageview");
        }
      })();
    </script>
    <script src="/blog-backend/umi.e14e5a14.js"></script>
  </body>
</html>
