<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no"
    />
    <link rel="shortcut icon" type="image/x-icon" href="/logo.png" />
    <link rel="stylesheet" href="/blog-backend/umi.3ec1f225.css" />
    <script>
      window.routerBase = "/blog-backend";
    </script>
    <script>
      //! umi version: 3.5.41
    </script>
    <script>
      !(function () {
        var e =
            navigator.cookieEnabled && void 0 !== window.localStorage
              ? localStorage.getItem("dumi:prefers-color")
              : "auto",
          o = window.matchMedia("(prefers-color-scheme: dark)").matches,
          t = ["light", "dark", "auto"];
        document.documentElement.setAttribute(
          "data-prefers-color",
          e === t[2] ? (o ? t[1] : t[0]) : t.indexOf(e) > -1 ? e : t[0]
        );
      })();
    </script>
    <title>42 | Kafka Streams在金融领域的应用 - 大师兄</title>
  </head>
  <body>
    <div id="root"><div class="__dumi-default-layout" data-route="/kafka核心技术与实战/07.高级kafka应用之流处理/03" data-show-sidemenu="true" data-show-slugs="true" data-site-mode="true" data-gapless="false"><div class="__dumi-default-navbar" data-mode="site"><button class="__dumi-default-navbar-toggle"></button><a class="__dumi-default-navbar-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-backend/">大师兄</a><nav><div class="__dumi-default-search"><input type="search" class="__dumi-default-search-input" value=""/><ul></ul></div><span>后端开发<ul><li><a href="/blog-backend/go语言核心36讲">go语言核心36讲</a></li><li><a href="/blog-backend/go并发编程实战">go并发编程实战</a></li><li><a href="/blog-backend/go语言项目开发实战">go语言项目开发实战</a></li><li><a aria-current="page" class="active" href="/blog-backend/kafka核心技术与实战">kafka核心技术与实战</a></li><li><a href="/blog-backend/kafka核心源码解读">kafka核心源码解读</a></li><li><a href="/blog-backend/零基础学python">零基础学python</a></li><li><a href="/blog-backend/python核心技术与实战">python核心技术与实战</a></li><li><a href="/blog-backend/redis核心技术与实战">redis核心技术与实战</a></li><li><a href="/blog-backend/redis源码剖析与实战">redis源码剖析与实战</a></li><li><a href="/blog-backend/陈天rust编程第一课">陈天rust编程第一课</a></li><li><a href="/blog-backend/tonybaigo语言第一课">tonybaigo语言第一课</a></li><li><a href="/blog-backend/后端存储实战课">后端存储实战课</a></li><li><a href="/blog-backend/后端技术面试38讲">后端技术面试38讲</a></li><li><a href="/blog-backend/深入c语言和程序运行原理">深入c语言和程序运行原理</a></li><li><a href="/blog-backend/现代c编程实战">现代c编程实战</a></li><li><a href="/blog-backend/罗剑锋的c实战笔记">罗剑锋的c实战笔记</a></li><li><a href="/blog-backend/零基础入门spark">零基础入门spark</a></li></ul></span><span>架构师<ul><li><a href="/blog-backend/mysql实战45讲">mysql实战45讲</a></li><li><a href="/blog-backend/数据中台实战课">数据中台实战课</a></li></ul></span><div class="__dumi-default-navbar-tool"><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "></div></div></div></nav></div><div class="__dumi-default-menu" data-mode="site"><div class="__dumi-default-menu-inner"><div class="__dumi-default-menu-header"><a class="__dumi-default-menu-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-backend/"></a><h1>大师兄</h1><p></p></div><div class="__dumi-default-menu-mobile-area"><ul class="__dumi-default-menu-nav-list"><li>后端开发<ul><li><a href="/blog-backend/go语言核心36讲">go语言核心36讲</a></li><li><a href="/blog-backend/go并发编程实战">go并发编程实战</a></li><li><a href="/blog-backend/go语言项目开发实战">go语言项目开发实战</a></li><li><a aria-current="page" class="active" href="/blog-backend/kafka核心技术与实战">kafka核心技术与实战</a></li><li><a href="/blog-backend/kafka核心源码解读">kafka核心源码解读</a></li><li><a href="/blog-backend/零基础学python">零基础学python</a></li><li><a href="/blog-backend/python核心技术与实战">python核心技术与实战</a></li><li><a href="/blog-backend/redis核心技术与实战">redis核心技术与实战</a></li><li><a href="/blog-backend/redis源码剖析与实战">redis源码剖析与实战</a></li><li><a href="/blog-backend/陈天rust编程第一课">陈天rust编程第一课</a></li><li><a href="/blog-backend/tonybaigo语言第一课">tonybaigo语言第一课</a></li><li><a href="/blog-backend/后端存储实战课">后端存储实战课</a></li><li><a href="/blog-backend/后端技术面试38讲">后端技术面试38讲</a></li><li><a href="/blog-backend/深入c语言和程序运行原理">深入c语言和程序运行原理</a></li><li><a href="/blog-backend/现代c编程实战">现代c编程实战</a></li><li><a href="/blog-backend/罗剑锋的c实战笔记">罗剑锋的c实战笔记</a></li><li><a href="/blog-backend/零基础入门spark">零基础入门spark</a></li></ul></li><li>架构师<ul><li><a href="/blog-backend/mysql实战45讲">mysql实战45讲</a></li><li><a href="/blog-backend/数据中台实战课">数据中台实战课</a></li></ul></li></ul><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "><button title="Dark theme" class="__dumi-default-dark-moon "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3854" width="22" height="22"><path d="M991.816611 674.909091a69.166545 69.166545 0 0 0-51.665455-23.272727 70.795636 70.795636 0 0 0-27.438545 5.585454A415.674182 415.674182 0 0 1 754.993338 698.181818c-209.594182 0-393.472-184.785455-393.472-395.636363 0-52.363636 38.539636-119.621818 69.515637-173.614546 4.887273-8.610909 9.634909-16.756364 14.103272-24.901818A69.818182 69.818182 0 0 0 384.631156 0a70.842182 70.842182 0 0 0-27.438545 5.585455C161.678429 90.298182 14.362065 307.898182 14.362065 512c0 282.298182 238.824727 512 532.38691 512a522.286545 522.286545 0 0 0 453.957818-268.334545A69.818182 69.818182 0 0 0 991.816611 674.909091zM546.679156 954.181818c-248.785455 0-462.941091-192-462.941091-442.181818 0-186.647273 140.637091-372.829091 300.939637-442.181818-36.817455 65.629091-92.578909 151.970909-92.578909 232.727273 0 250.181818 214.109091 465.454545 462.917818 465.454545a488.331636 488.331636 0 0 0 185.181091-46.545455 453.003636 453.003636 0 0 1-393.565091 232.727273z m103.656728-669.323636l-14.266182 83.781818a34.909091 34.909091 0 0 0 50.362182 36.770909l74.775272-39.563636 74.752 39.563636a36.142545 36.142545 0 0 0 16.174546 3.956364 34.909091 34.909091 0 0 0 34.210909-40.727273l-14.289455-83.781818 60.509091-59.345455a35.025455 35.025455 0 0 0-19.223272-59.578182l-83.61891-12.101818-37.376-76.101818a34.56 34.56 0 0 0-62.254545 0l-37.376 76.101818-83.618909 12.101818a34.909091 34.909091 0 0 0-19.246546 59.578182z m70.423272-64.698182a34.280727 34.280727 0 0 0 26.135273-19.083636l14.312727-29.090909 14.336 29.090909a34.257455 34.257455 0 0 0 26.135273 19.083636l32.046546 4.887273-23.272728 22.574545a35.234909 35.234909 0 0 0-10.007272 30.952727l5.46909 32.116364-28.625454-15.127273a34.490182 34.490182 0 0 0-32.302546 0l-28.695272 15.127273 5.469091-32.116364a35.141818 35.141818 0 0 0-9.984-30.952727l-23.272728-22.574545z" p-id="3855"></path></svg></button><button title="Light theme" class="__dumi-default-dark-sun "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4026" width="22" height="22"><path d="M915.2 476.16h-43.968c-24.704 0-44.736 16-44.736 35.84s20.032 35.904 44.736 35.904H915.2c24.768 0 44.8-16.064 44.8-35.904s-20.032-35.84-44.8-35.84zM512 265.6c-136.704 0-246.464 109.824-246.464 246.4 0 136.704 109.76 246.464 246.464 246.464S758.4 648.704 758.4 512c0-136.576-109.696-246.4-246.4-246.4z m0 425.6c-99.008 0-179.2-80.128-179.2-179.2 0-98.944 80.192-179.2 179.2-179.2S691.2 413.056 691.2 512c0 99.072-80.192 179.2-179.2 179.2zM197.44 512c0-19.84-19.136-35.84-43.904-35.84H108.8c-24.768 0-44.8 16-44.8 35.84s20.032 35.904 44.8 35.904h44.736c24.768 0 43.904-16.064 43.904-35.904zM512 198.464c19.776 0 35.84-20.032 35.84-44.8v-44.8C547.84 84.032 531.84 64 512 64s-35.904 20.032-35.904 44.8v44.8c0 24.768 16.128 44.864 35.904 44.864z m0 627.136c-19.776 0-35.904 20.032-35.904 44.8v44.736C476.096 940.032 492.16 960 512 960s35.84-20.032 35.84-44.8v-44.736c0-24.768-16.064-44.864-35.84-44.864z m329.92-592.832c17.472-17.536 20.288-43.072 6.4-57.024-14.016-14.016-39.488-11.2-57.024 6.336-4.736 4.864-26.496 26.496-31.36 31.36-17.472 17.472-20.288 43.008-6.336 57.024 13.952 14.016 39.488 11.2 57.024-6.336 4.8-4.864 26.496-26.56 31.296-31.36zM213.376 759.936c-4.864 4.8-26.56 26.624-31.36 31.36-17.472 17.472-20.288 42.944-6.4 56.96 14.016 13.952 39.552 11.2 57.024-6.336 4.8-4.736 26.56-26.496 31.36-31.36 17.472-17.472 20.288-43.008 6.336-56.96-14.016-13.952-39.552-11.072-56.96 6.336z m19.328-577.92c-17.536-17.536-43.008-20.352-57.024-6.336-14.08 14.016-11.136 39.488 6.336 57.024 4.864 4.864 26.496 26.56 31.36 31.424 17.536 17.408 43.008 20.288 56.96 6.336 14.016-14.016 11.264-39.488-6.336-57.024-4.736-4.864-26.496-26.56-31.296-31.424z m527.168 628.608c4.864 4.864 26.624 26.624 31.36 31.424 17.536 17.408 43.072 20.224 57.088 6.336 13.952-14.016 11.072-39.552-6.4-57.024-4.864-4.8-26.56-26.496-31.36-31.36-17.472-17.408-43.072-20.288-57.024-6.336-13.952 14.016-11.008 39.488 6.336 56.96z" p-id="4027"></path></svg></button><button title="Default to system" class="__dumi-default-dark-auto "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="11002" width="22" height="22"><path d="M127.658667 492.885333c0-51.882667 10.24-101.717333 30.378666-149.162666s47.786667-88.064 81.92-122.538667 75.093333-61.781333 122.538667-81.92 96.938667-30.378667 149.162667-30.378667 101.717333 10.24 149.162666 30.378667 88.405333 47.786667 122.88 81.92 61.781333 75.093333 81.92 122.538667 30.378667 96.938667 30.378667 149.162666-10.24 101.717333-30.378667 149.162667-47.786667 88.405333-81.92 122.88-75.093333 61.781333-122.88 81.92-97.28 30.378667-149.162666 30.378667-101.717333-10.24-149.162667-30.378667-88.064-47.786667-122.538667-81.92-61.781333-75.093333-81.92-122.88-30.378667-96.938667-30.378666-149.162667z m329.045333 0c0 130.048 13.994667 244.394667 41.984 343.381334h12.970667c46.762667 0 91.136-9.216 133.461333-27.306667s78.848-42.666667 109.568-73.386667 54.954667-67.242667 73.386667-109.568 27.306667-86.698667 27.306666-133.461333c0-46.421333-9.216-90.794667-27.306666-133.12s-42.666667-78.848-73.386667-109.568-67.242667-54.954667-109.568-73.386667-86.698667-27.306667-133.461333-27.306666h-11.605334c-28.672 123.562667-43.349333 237.909333-43.349333 343.722666z" p-id="11003"></path></svg></button></div></div></div><ul class="__dumi-default-menu-list"><li><a href="/blog-backend/kafka核心技术与实战">kafka核心技术与实战</a></li><li><a href="/blog-backend/kafka核心技术与实战/01.开篇词">01.开篇词</a><ul><li><a href="/blog-backend/kafka核心技术与实战/01.开篇词/01"><span>开篇词 | 为什么要学习Kafka？</span></a></li></ul></li><li><a href="/blog-backend/kafka核心技术与实战/02.kafka入门">02.Kafka入门</a><ul><li><a href="/blog-backend/kafka核心技术与实战/02.kafka入门/01"><span>01 |  消息引擎系统ABC</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/02.kafka入门/02"><span>02 | 一篇文章带你快速搞定Kafka术语</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/02.kafka入门/03"><span>03 | Kafka只是消息引擎系统吗？</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/02.kafka入门/04"><span>04 | 我应该选择哪种Kafka？</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/02.kafka入门/05"><span>05 | 聊聊Kafka的版本号</span></a></li></ul></li><li><a href="/blog-backend/kafka核心技术与实战/03.kafka的基本使用">03.Kafka的基本使用</a><ul><li><a href="/blog-backend/kafka核心技术与实战/03.kafka的基本使用/01"><span>06 | Kafka线上集群部署方案怎么做？</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/03.kafka的基本使用/02"><span>07 | 最最最重要的集群参数配置（上）</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/03.kafka的基本使用/03"><span>08 | 最最最重要的集群参数配置（下）</span></a></li></ul></li><li><a href="/blog-backend/kafka核心技术与实战/04.客户端实践及原理剖析">04.客户端实践及原理剖析</a><ul><li><a href="/blog-backend/kafka核心技术与实战/04.客户端实践及原理剖析/01"><span>09 |  生产者消息分区机制原理剖析</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/04.客户端实践及原理剖析/02"><span>10 | 生产者压缩算法面面观</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/04.客户端实践及原理剖析/03"><span>11 | 无消息丢失配置怎么实现？</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/04.客户端实践及原理剖析/04"><span>12 | 客户端都有哪些不常见但是很高级的功能？</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/04.客户端实践及原理剖析/05"><span>13 |  Java生产者是如何管理TCP连接的？</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/04.客户端实践及原理剖析/06"><span>14 | 幂等生产者和事务生产者是一回事吗？</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/04.客户端实践及原理剖析/07"><span>15 | 消费者组到底是什么？</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/04.客户端实践及原理剖析/08"><span>16 | 揭开神秘的“位移主题”面纱</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/04.客户端实践及原理剖析/09"><span>17 | 消费者组重平衡能避免吗？</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/04.客户端实践及原理剖析/10"><span>18 | Kafka中位移提交那些事儿</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/04.客户端实践及原理剖析/11"><span>19 | CommitFailedException异常怎么处理？</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/04.客户端实践及原理剖析/12"><span>20 | 多线程开发消费者实例</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/04.客户端实践及原理剖析/13"><span>21 | Java 消费者是如何管理TCP连接的?</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/04.客户端实践及原理剖析/14"><span>22 | 消费者组消费进度监控都怎么实现？</span></a></li></ul></li><li><a href="/blog-backend/kafka核心技术与实战/05.深入kafka内核">05.深入Kafka内核</a><ul><li><a href="/blog-backend/kafka核心技术与实战/05.深入kafka内核/01"><span>23 | Kafka副本机制详解</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/05.深入kafka内核/02"><span>24 | 请求是怎么被处理的？</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/05.深入kafka内核/03"><span>25 | 消费者组重平衡全流程解析</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/05.深入kafka内核/04"><span>26 | 你一定不能错过的Kafka控制器</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/05.深入kafka内核/05"><span>27 | 关于高水位和Leader Epoch的讨论</span></a></li></ul></li><li><a href="/blog-backend/kafka核心技术与实战/06.管理与监控">06.管理与监控</a><ul><li><a href="/blog-backend/kafka核心技术与实战/06.管理与监控/01"><span>28 | 主题管理知多少?</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/06.管理与监控/02"><span>29 | Kafka动态配置了解下？</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/06.管理与监控/03"><span>30 | 怎么重设消费者组位移？</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/06.管理与监控/04"><span>31 | 常见工具脚本大汇总</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/06.管理与监控/05"><span>32 | KafkaAdminClient：Kafka的运维利器</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/06.管理与监控/06"><span>33 | Kafka认证机制用哪家？</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/06.管理与监控/07"><span>34 | 云环境下的授权该怎么做？</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/06.管理与监控/08"><span>35 | 跨集群备份解决方案MirrorMaker</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/06.管理与监控/09"><span>36 | 你应该怎么监控Kafka？</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/06.管理与监控/10"><span>37 | 主流的Kafka监控框架</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/06.管理与监控/11"><span>38 | 调优Kafka，你做到了吗？</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/06.管理与监控/12"><span>39 | 从0搭建基于Kafka的企业级实时日志流处理平台</span></a></li></ul></li><li><a aria-current="page" class="active" href="/blog-backend/kafka核心技术与实战/07.高级kafka应用之流处理">07.高级Kafka应用之流处理</a><ul><li><a href="/blog-backend/kafka核心技术与实战/07.高级kafka应用之流处理/01"><span>40 | Kafka Streams与其他流处理平台的差异在哪里？</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/07.高级kafka应用之流处理/02"><span>41 | Kafka Streams DSL开发实例</span></a></li><li><a aria-current="page" class="active" href="/blog-backend/kafka核心技术与实战/07.高级kafka应用之流处理/03"><span>42 | Kafka Streams在金融领域的应用</span></a></li></ul></li><li><a href="/blog-backend/kafka核心技术与实战/08.特别放送">08.特别放送</a><ul><li><a href="/blog-backend/kafka核心技术与实战/08.特别放送/01"><span>加餐 | 搭建开发环境、阅读源码方法、经典学习资料大揭秘</span></a></li><li><a href="/blog-backend/kafka核心技术与实战/08.特别放送/02"><span>用户故事 | 黄云：行百里者半九十</span></a></li></ul></li><li><a href="/blog-backend/kafka核心技术与实战/09.结束语">09.结束语</a><ul><li><a href="/blog-backend/kafka核心技术与实战/09.结束语/01"><span>结束语 | 以梦为马，莫负韶华！</span></a></li></ul></li><li><a href="/blog-backend/kafka核心技术与实战/10.结课测试">10.结课测试</a><ul><li><a href="/blog-backend/kafka核心技术与实战/10.结课测试/01"><span>期末测试 | 这些Kafka核心要点，你都掌握了吗？</span></a></li></ul></li><li><a href="/blog-backend/kafka核心技术与实战/summary">kafka核心技术与实战</a></li></ul></div></div><ul role="slug-list" class="__dumi-default-layout-toc"><li title="背景" data-depth="2"><a href="/blog-backend/kafka核心技术与实战/07.高级kafka应用之流处理/03#背景"><span>背景</span></a></li><li title="用户画像" data-depth="2"><a href="/blog-backend/kafka核心技术与实战/07.高级kafka应用之流处理/03#用户画像"><span>用户画像</span></a></li><li title="ID映射（ID Mapping）" data-depth="2"><a href="/blog-backend/kafka核心技术与实战/07.高级kafka应用之流处理/03#id映射id-mapping"><span>ID映射（ID Mapping）</span></a></li><li title="实时ID Mapping" data-depth="2"><a href="/blog-backend/kafka核心技术与实战/07.高级kafka应用之流处理/03#实时id-mapping"><span>实时ID Mapping</span></a></li><li title="Kafka Streams实现" data-depth="2"><a href="/blog-backend/kafka核心技术与实战/07.高级kafka应用之流处理/03#kafka-streams实现"><span>Kafka Streams实现</span></a></li><li title="小结" data-depth="2"><a href="/blog-backend/kafka核心技术与实战/07.高级kafka应用之流处理/03#小结"><span>小结</span></a></li><li title="开放讨论" data-depth="2"><a href="/blog-backend/kafka核心技术与实战/07.高级kafka应用之流处理/03#开放讨论"><span>开放讨论</span></a></li></ul><div class="__dumi-default-layout-content"><div class="markdown"><h1 id="42--kafka-streams在金融领域的应用"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心技术与实战/07.高级kafka应用之流处理/03#42--kafka-streams在金融领域的应用"><span class="icon icon-link"></span></a>42 | Kafka Streams在金融领域的应用</h1><p>你好，我是胡夕。今天我要和你分享的主题是：Kafka Streams在金融领域的应用。</p><h2 id="背景"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心技术与实战/07.高级kafka应用之流处理/03#背景"><span class="icon icon-link"></span></a>背景</h2><p>金融领域囊括的内容有很多，我今天分享的主要是，如何利用大数据技术，特别是Kafka Streams实时计算框架，来帮助我们更好地做企业用户洞察。</p><p>众所周知，金融领域内的获客成本是相当高的，一线城市高净值白领的获客成本通常可达上千元。面对如此巨大的成本压力，金融企业一方面要降低广告投放的获客成本，另一方面要做好精细化运营，实现客户生命周期内价值（Custom Lifecycle Value, CLV）的最大化。</p><p><strong>实现价值最大化的一个重要途径就是做好用户洞察，而用户洞察要求你要更深度地了解你的客户</strong>，即所谓的Know Your Customer（KYC），真正做到以客户为中心，不断地满足客户需求。</p><p>为了实现KYC，传统的做法是花费大量的时间与客户见面，做面对面的沟通以了解客户的情况。但是，用这种方式得到的数据往往是不真实的，毕竟客户内心是有潜在的自我保护意识的，短时间内的面对面交流很难真正洞察到客户的真实诉求。</p><p>相反地，渗透到每个人日常生活方方面面的大数据信息则代表了客户的实际需求。比如客户经常浏览哪些网站、都买过什么东西、最喜欢的视频类型是什么。这些数据看似很随意，但都表征了客户最真实的想法。将这些数据汇总在一起，我们就能完整地构造出客户的画像，这就是所谓的用户画像（User Profile）技术。</p><h2 id="用户画像"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心技术与实战/07.高级kafka应用之流处理/03#用户画像"><span class="icon icon-link"></span></a>用户画像</h2><p>用户画像听起来很玄妙，但实际上你应该是很熟悉的。你的很多基本信息，比如性别、年龄、所属行业、工资收入和爱好等，都是用户画像的一部分。举个例子，我们可以这样描述一个人：某某某，男性，28岁，未婚，工资水平大致在15000到20000元之间，是一名大数据开发工程师，居住在北京天通苑小区，平时加班很多，喜欢动漫或游戏。</p><p>其实，这一连串的描述就是典型的用户画像。通俗点来说，构建用户画像的核心工作就是给客户或用户打标签（Tagging）。刚刚那一连串的描述就是用户系统中的典型标签。用户画像系统通过打标签的形式，把客户提供给业务人员，从而实现精准营销。</p><h2 id="id映射id-mapping"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心技术与实战/07.高级kafka应用之流处理/03#id映射id-mapping"><span class="icon icon-link"></span></a>ID映射（ID Mapping）</h2><p>用户画像的好处不言而喻，而且标签打得越多越丰富，就越能精确地表征一个人的方方面面。不过，在打一个个具体的标签之前，弄清楚“你是谁”是所有用户画像系统首要考虑的问题，这个问题也被称为ID识别问题。</p><p>所谓的ID即Identification，表示用户身份。在网络上，能够标识用户身份信息的常见ID有5种。</p><ul><li>身份证号：这是最能表征身份的ID信息，每个身份证号只会对应一个人。</li><li>手机号：手机号通常能较好地表征身份。虽然会出现同一个人有多个手机号或一个手机号在不同时期被多个人使用的情形，但大部分互联网应用使用手机号表征用户身份的做法是很流行的。</li><li>设备ID：在移动互联网时代，这主要是指手机的设备ID或Mac、iPad等移动终端设备的设备ID。特别是手机的设备ID，在很多场景下具备定位和识别用户的功能。常见的设备ID有iOS端的IDFA和Android端的IMEI。</li><li>应用注册账号：这属于比较弱的一类ID。每个人在不同的应用上可能会注册不同的账号，但依然有很多人使用通用的注册账号名称，因此具有一定的关联性和识别性。</li><li>Cookie：在PC时代，浏览器端的Cookie信息是很重要的数据，它是网络上表征用户信息的重要手段之一。只不过随着移动互联网时代的来临，Cookie早已江河日下，如今作为ID数据的价值也越来越小了。我个人甚至认为，在构建基于移动互联网的新一代用户画像时，Cookie可能要被抛弃了。</li></ul><p>在构建用户画像系统时，我们会从多个数据源上源源不断地收集各种个人用户数据。通常情况下，这些数据不会全部携带以上这些ID信息。比如在读取浏览器的浏览历史时，你获取的是Cookie数据，而读取用户在某个App上的访问行为数据时，你拿到的是用户的设备ID和注册账号信息。</p><p>倘若这些数据表征的都是一个用户的信息，我们的用户画像系统如何识别出来呢？换句话说，你需要一种手段或技术帮你做各个ID的打通或映射。这就是用户画像领域的ID映射问题。</p><h2 id="实时id-mapping"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心技术与实战/07.高级kafka应用之流处理/03#实时id-mapping"><span class="icon icon-link"></span></a>实时ID Mapping</h2><p>我举个简单的例子。假设有一个金融理财用户张三，他首先在苹果手机上访问了某理财产品，然后在安卓手机上注册了该理财产品的账号，最后在电脑上登录该账号，并购买了该理财产品。ID Mapping 就是要将这些不同端或设备上的用户信息聚合起来，然后找出并打通用户所关联的所有ID信息。</p><p>实时ID Mapping的要求就更高了，它要求我们能够实时地分析从各个设备收集来的数据，并在很短的时间内完成ID Mapping。打通用户ID身份的时间越短，我们就能越快地为其打上更多的标签，从而让用户画像发挥更大的价值。</p><p>从实时计算或流处理的角度来看，实时ID Mapping能够转换成一个<strong>流-表连接问题</strong>（Stream-Table Join），即我们实时地将一个流和一个表进行连接。</p><p>消息流中的每个事件或每条消息包含的是一个未知用户的某种信息，它可以是用户在页面的访问记录数据，也可以是用户的购买行为数据。这些消息中可能会包含我们刚才提到的若干种ID信息，比如页面访问信息中可能包含设备ID，也可能包含注册账号，而购买行为信息中可能包含身份证信息和手机号等。</p><p>连接的另一方表保存的是<strong>用户所有的ID信息</strong>，随着连接的不断深入，表中保存的ID品类会越来越丰富，也就是说，流中的数据会被不断地补充进表中，最终实现对用户所有ID的打通。</p><h2 id="kafka-streams实现"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心技术与实战/07.高级kafka应用之流处理/03#kafka-streams实现"><span class="icon icon-link"></span></a>Kafka Streams实现</h2><p>好了，现在我们就来看看如何使用Kafka Streams来实现一个特定场景下的实时ID Mapping。为了方便理解，我们假设ID Mapping只关心身份证号、手机号以及设备ID。下面是用Avro写成的Schema格式：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">{</span></div><div class="token-line"><span class="token plain">      &quot;namespace&quot;: &quot;kafkalearn.userprofile.idmapping&quot;,</span></div><div class="token-line"><span class="token plain">      &quot;type&quot;: &quot;record&quot;,</span></div><div class="token-line"><span class="token plain">      &quot;name&quot;: &quot;IDMapping&quot;,</span></div><div class="token-line"><span class="token plain">      &quot;fields&quot;: [</span></div><div class="token-line"><span class="token plain">        {&quot;name&quot;: &quot;deviceId&quot;, &quot;type&quot;: &quot;string&quot;},</span></div><div class="token-line"><span class="token plain">        {&quot;name&quot;: &quot;idCard&quot;, &quot;type&quot;: &quot;string&quot;},</span></div><div class="token-line"><span class="token plain">        {&quot;name&quot;: &quot;phone&quot;, &quot;type&quot;: &quot;string&quot;}</span></div><div class="token-line"><span class="token plain">      ]</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>顺便说一下，<strong>Avro是Java或大数据生态圈常用的序列化编码机制</strong>，比如直接使用JSON或XML保存对象。Avro能极大地节省磁盘占用空间或网络I/O传输量，因此普遍应用于大数据量下的数据传输。</p><p>在这个场景下，我们需要两个Kafka主题，一个用于构造表，另一个用于构建流。这两个主题的消息格式都是上面的IDMapping对象。</p><p>新用户在填写手机号注册App时，会向第一个主题发送一条消息，该用户后续在App上的所有访问记录，也都会以消息的形式发送到第二个主题。值得注意的是，发送到第二个主题上的消息有可能携带其他的ID信息，比如手机号或设备ID等。就像我刚刚所说的，这是一个典型的流-表实时连接场景，连接之后，我们就能够将用户的所有数据补齐，实现ID Mapping的打通。</p><p>基于这个设计思路，我先给出完整的Kafka Streams代码，稍后我会对重点部分进行详细解释：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">package kafkalearn.userprofile.idmapping;</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">    // omit imports……</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">    public class IDMappingStreams {</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">        public static void main(String[] args) throws Exception {</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">            if (args.length &lt; 1) {</span></div><div class="token-line"><span class="token plain">                throw new IllegalArgumentException(&quot;Must specify the path for a configuration file.&quot;);</span></div><div class="token-line"><span class="token plain">            }</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">            IDMappingStreams instance = new IDMappingStreams();</span></div><div class="token-line"><span class="token plain">            Properties envProps = instance.loadProperties(args[0]);</span></div><div class="token-line"><span class="token plain">            Properties streamProps = instance.buildStreamsProperties(envProps);</span></div><div class="token-line"><span class="token plain">            Topology topology = instance.buildTopology(envProps);</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">            instance.createTopics(envProps);</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">            final KafkaStreams streams = new KafkaStreams(topology, streamProps);</span></div><div class="token-line"><span class="token plain">            final CountDownLatch latch = new CountDownLatch(1);</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">            // Attach shutdown handler to catch Control-C.</span></div><div class="token-line"><span class="token plain">            Runtime.getRuntime().addShutdownHook(new Thread(&quot;streams-shutdown-hook&quot;) {</span></div><div class="token-line"><span class="token plain">                @Override</span></div><div class="token-line"><span class="token plain">                public void run() {</span></div><div class="token-line"><span class="token plain">                    streams.close();</span></div><div class="token-line"><span class="token plain">                    latch.countDown();</span></div><div class="token-line"><span class="token plain">                }</span></div><div class="token-line"><span class="token plain">            });</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">            try {</span></div><div class="token-line"><span class="token plain">                streams.start();</span></div><div class="token-line"><span class="token plain">                latch.await();</span></div><div class="token-line"><span class="token plain">            } catch (Throwable e) {</span></div><div class="token-line"><span class="token plain">                System.exit(1);</span></div><div class="token-line"><span class="token plain">            }</span></div><div class="token-line"><span class="token plain">            System.exit(0);</span></div><div class="token-line"><span class="token plain">        }</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">        private Properties loadProperties(String propertyFilePath) throws IOException {</span></div><div class="token-line"><span class="token plain">            Properties envProps = new Properties();</span></div><div class="token-line"><span class="token plain">            try (FileInputStream input = new FileInputStream(propertyFilePath)) {</span></div><div class="token-line"><span class="token plain">                envProps.load(input);</span></div><div class="token-line"><span class="token plain">                return envProps;</span></div><div class="token-line"><span class="token plain">            }</span></div><div class="token-line"><span class="token plain">        }</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">        private Properties buildStreamsProperties(Properties envProps) {</span></div><div class="token-line"><span class="token plain">            Properties props = new Properties();</span></div><div class="token-line"><span class="token plain">            props.put(StreamsConfig.APPLICATION_ID_CONFIG, envProps.getProperty(&quot;application.id&quot;));</span></div><div class="token-line"><span class="token plain">            props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, envProps.getProperty(&quot;bootstrap.servers&quot;));</span></div><div class="token-line"><span class="token plain">            props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());</span></div><div class="token-line"><span class="token plain">            props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());</span></div><div class="token-line"><span class="token plain">            return props;</span></div><div class="token-line"><span class="token plain">        }</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">        private void createTopics(Properties envProps) {</span></div><div class="token-line"><span class="token plain">            Map&lt;String, Object&gt; config = new HashMap&lt;&gt;();</span></div><div class="token-line"><span class="token plain">            config.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, envProps.getProperty(&quot;bootstrap.servers&quot;));</span></div><div class="token-line"><span class="token plain">            try (AdminClient client = AdminClient.create(config)) {</span></div><div class="token-line"><span class="token plain">                List&lt;NewTopic&gt; topics = new ArrayList&lt;&gt;();</span></div><div class="token-line"><span class="token plain">                topics.add(new NewTopic(</span></div><div class="token-line"><span class="token plain">                        envProps.getProperty(&quot;stream.topic.name&quot;),</span></div><div class="token-line"><span class="token plain">                        Integer.parseInt(envProps.getProperty(&quot;stream.topic.partitions&quot;)),</span></div><div class="token-line"><span class="token plain">                        Short.parseShort(envProps.getProperty(&quot;stream.topic.replication.factor&quot;))));</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">                topics.add(new NewTopic(</span></div><div class="token-line"><span class="token plain">                        envProps.getProperty(&quot;table.topic.name&quot;),</span></div><div class="token-line"><span class="token plain">                        Integer.parseInt(envProps.getProperty(&quot;table.topic.partitions&quot;)),</span></div><div class="token-line"><span class="token plain">                        Short.parseShort(envProps.getProperty(&quot;table.topic.replication.factor&quot;))));</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">                client.createTopics(topics);</span></div><div class="token-line"><span class="token plain">            }</span></div><div class="token-line"><span class="token plain">        }</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">        private Topology buildTopology(Properties envProps) {</span></div><div class="token-line"><span class="token plain">            final StreamsBuilder builder = new StreamsBuilder();</span></div><div class="token-line"><span class="token plain">            final String streamTopic = envProps.getProperty(&quot;stream.topic.name&quot;);</span></div><div class="token-line"><span class="token plain">            final String rekeyedTopic = envProps.getProperty(&quot;rekeyed.topic.name&quot;);</span></div><div class="token-line"><span class="token plain">            final String tableTopic = envProps.getProperty(&quot;table.topic.name&quot;);</span></div><div class="token-line"><span class="token plain">            final String outputTopic = envProps.getProperty(&quot;output.topic.name&quot;);</span></div><div class="token-line"><span class="token plain">            final Gson gson = new Gson();</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">            // 1. 构造表</span></div><div class="token-line"><span class="token plain">            KStream&lt;String, IDMapping&gt; rekeyed = builder.&lt;String, String&gt;stream(tableTopic)</span></div><div class="token-line"><span class="token plain">                    .mapValues(json -&gt; gson.fromJson(json, IDMapping.class))</span></div><div class="token-line"><span class="token plain">                    .filter((noKey, idMapping) -&gt; !Objects.isNull(idMapping.getPhone()))</span></div><div class="token-line"><span class="token plain">                    .map((noKey, idMapping) -&gt; new KeyValue&lt;&gt;(idMapping.getPhone(), idMapping));</span></div><div class="token-line"><span class="token plain">            rekeyed.to(rekeyedTopic);</span></div><div class="token-line"><span class="token plain">            KTable&lt;String, IDMapping&gt; table = builder.table(rekeyedTopic);</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">            // 2. 流-表连接</span></div><div class="token-line"><span class="token plain">            KStream&lt;String, String&gt; joinedStream = builder.&lt;String, String&gt;stream(streamTopic)</span></div><div class="token-line"><span class="token plain">                    .mapValues(json -&gt; gson.fromJson(json, IDMapping.class))</span></div><div class="token-line"><span class="token plain">                    .map((noKey, idMapping) -&gt; new KeyValue&lt;&gt;(idMapping.getPhone(), idMapping))</span></div><div class="token-line"><span class="token plain">                    .leftJoin(table, (value1, value2) -&gt; IDMapping.newBuilder()</span></div><div class="token-line"><span class="token plain">                            .setPhone(value2.getPhone() == null ? value1.getPhone() : value2.getPhone())</span></div><div class="token-line"><span class="token plain">                            .setDeviceId(value2.getDeviceId() == null ? value1.getDeviceId() : value2.getDeviceId())</span></div><div class="token-line"><span class="token plain">                            .setIdCard(value2.getIdCard() == null ? value1.getIdCard() : value2.getIdCard())</span></div><div class="token-line"><span class="token plain">                            .build())</span></div><div class="token-line"><span class="token plain">                    .mapValues(v -&gt; gson.toJson(v));</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">            joinedStream.to(outputTopic);</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">            return builder.build();</span></div><div class="token-line"><span class="token plain">        }</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>这个Java类代码中最重要的方法是<strong>buildTopology函数</strong>，它构造了我们打通ID Mapping的所有逻辑。</p><p>在该方法中，我们首先构造了StreamsBuilder对象实例，这是构造任何Kafka Streams应用的第一步。之后我们读取配置文件，获取了要读写的所有Kafka主题名。在这个例子中，我们需要用到4个主题，它们的作用如下：</p><ul><li>streamTopic：保存用户登录App后发生的各种行为数据，格式是IDMapping对象的JSON串。你可能会问，前面不是都创建Avro Schema文件了吗，怎么这里又用回JSON了呢？原因是这样的：社区版的Kafka没有提供Avro的序列化/反序列化类支持，如果我要使用Avro，必须改用Confluent公司提供的Kafka，但这会偏离我们专栏想要介绍Apache Kafka的初衷。所以，我还是使用JSON进行说明。这里我只是用了Avro Code Generator帮我们提供IDMapping对象各个字段的set/get方法，你使用Lombok也是可以的。</li><li>rekeyedTopic：这个主题是一个中间主题，它将streamTopic中的手机号提取出来作为消息的Key，同时维持消息体不变。</li><li>tableTopic：保存用户注册App时填写的手机号。我们要使用这个主题构造连接时要用到的表数据。</li><li>outputTopic：保存连接后的输出信息，即打通了用户所有ID数据的IDMapping对象，将其转换成JSON后输出。</li></ul><p>buildTopology的第一步是构造表，即KTable对象。我们修改初始的消息流，以用户注册的手机号作为Key，构造了一个中间流，之后将这个流写入到rekeyedTopic，最后直接使用builder.table方法构造出KTable。这样每当有新用户注册时，该KTable都会新增一条数据。</p><p>有了表之后，我们继续构造消息流来封装用户登录App之后的行为数据，我们同样提取出手机号作为要连接的Key，之后使用KStream的<strong>leftJoin方法</strong>将其与上一步的KTable对象进行关联。</p><p>在关联的过程中，我们同时提取两边的信息，尽可能地补充到最后生成的IDMapping对象中，然后将这个生成的IDMapping实例返回到新生成的流中。最后，我们将它写入到outputTopic中保存。</p><p>至此，我们使用了不到200行的Java代码，就简单实现了一个真实场景下的实时ID Mapping任务。理论上，你可以将这个例子继续扩充，扩展到任意多个ID Mapping，甚至是含有其他标签的数据，连接原理是相通的。在我自己的项目中，我借助于Kafka Streams帮助我实现了用户画像系统的部分功能，而ID Mapping就是其中的一个。</p><h2 id="小结"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心技术与实战/07.高级kafka应用之流处理/03#小结"><span class="icon icon-link"></span></a>小结</h2><p>好了，我们小结一下。今天，我展示了Kafka Streams在金融领域的一个应用案例，重点演示了如何利用连接函数来实时关联流和表。其实，Kafka Streams提供的功能远不止这些，我推荐你阅读一下<a target="_blank" rel="noopener noreferrer" href="https://kafka.apache.org/23/documentation/streams/developer-guide/">官网<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>的教程，然后把自己的一些轻量级的实时计算线上任务改为使用Kafka Streams来实现。</p><p><img src="/blog-backend/static/httpsstatic001geekbangorgresourceimage75e775df06c2b75c3886ca3496a774730de7.cf70f29a.jpg" alt=""/></p><h2 id="开放讨论"><a aria-hidden="true" tabindex="-1" href="/blog-backend/kafka核心技术与实战/07.高级kafka应用之流处理/03#开放讨论"><span class="icon icon-link"></span></a>开放讨论</h2><p>最后，我们来讨论一个问题。在刚刚的这个例子中，你觉得我为什么使用leftJoin方法而不是join方法呢？（小提示：可以对比一下SQL中的left join和inner join。）</p><p>欢迎写下你的思考和答案，我们一起讨论。如果你觉得有所收获，也欢迎把文章分享给你的朋友。</p></div><div class="__dumi-default-layout-footer-meta"><a target="_blank" rel="noopener noreferrer" href="https://github.com/GGwujun/blog/edit/master/ssrc/kafka核心技术与实战/07.高级Kafka应用之流处理/03.md">在 GitHub 上编辑此页<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a><span data-updated-text="最后更新时间：">2023/9/27 11:15:40</span></div></div></div></div>
	<script>
  window.g_useSSR = true;
  window.g_initialProps = {};
	</script>

    <script>
      (function () {
        if (!location.port) {
          (function (i, s, o, g, r, a, m) {
            i["GoogleAnalyticsObject"] = r;
            (i[r] =
              i[r] ||
              function () {
                (i[r].q = i[r].q || []).push(arguments);
              }),
              (i[r].l = 1 * new Date());
            (a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m);
          })(
            window,
            document,
            "script",
            "//www.google-analytics.com/analytics.js",
            "ga"
          );
          ga("create", "UA-149864185-1", "auto");
          ga("send", "pageview");
        }
      })();
    </script>
    <script src="/blog-backend/umi.e14e5a14.js"></script>
  </body>
</html>
